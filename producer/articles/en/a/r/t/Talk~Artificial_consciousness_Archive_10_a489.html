<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    		<meta name="keywords" content="Talk:Artificial consciousness/Archive 10,AI,Artificial consciousness,Artificial intelligence,Church-Turing thesis,Connectionism,Copernican principle,Cynthia Breazeal,Daniel Dennett,Douglas Hofstadter,Finite state machine" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="../../../COPYING.html" />
    <title>Talk:Artificial consciousness/Archive 10 - Wikipedia, the free encyclopedia</title>
    <style type="text/css">/*<![CDATA[*/ @import "../../../skins/htmldump/main.css"; /*]]>*/</style>
    <link rel="stylesheet" type="text/css" media="print" href="../../../skins/common/commonPrint.css" />
    <!--[if lt IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE50Fixes.css";</style><![endif]-->
    <!--[if IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE55Fixes.css";</style><![endif]-->
    <!--[if IE 6]><style type="text/css">@import "../../../skins/monobook/IE60Fixes.css";</style><![endif]-->
    <!--[if IE]><script type="text/javascript" src="../../../skins/common/IEFixes.js"></script>
    <meta http-equiv="imagetoolbar" content="no" /><![endif]-->
    <script type="text/javascript" src="../../../skins/common/wikibits.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/md5.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/utf8.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/lookup.js"></script>
    <script type="text/javascript" src="../../../raw/gen.js"></script>        <style type="text/css">/*<![CDATA[*/
@import "../../../raw/MediaWiki%7ECommon.css";
@import "../../../raw/MediaWiki%7EMonobook.css";
@import "../../../raw/gen.css";
/*]]>*/</style>          </head>
  <body
    class="ns-1">
    <div id="globalWrapper">
      <div id="column-content">
	<div id="content">
	  <a name="top" id="contentTop"></a>
	        <h1 class="firstHeading">Talk:Artificial consciousness/Archive 10</h1>
	  <div id="bodyContent">
	    <h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
	    <div id="contentSub"><span class="subpages">&lt; <a href="../../../a/r/t/Talk%7EArtificial_consciousness_9bc5.html" title="Talk:Artificial consciousness">Talk:Artificial consciousness</a></span></div>
	    	    	    <!-- start content -->
	    <table class="messagebox standard-talk">
<tr>
<td><a href="../../../v/i/s/Image%7EVista-file-manager.png_cc3f.html" class="image" title="Archive"><img src="../../../upload/thumb/c/c2/Vista-file-manager.png/50px-Vista-file-manager.png" alt="Archive" width="50" height="50" longdesc="../../../v/i/s/Image%7EVista-file-manager.png_cc3f.html" /></a></td>
<td>This is an <b><a href="../../../h/o/w/Wikipedia%7EHow_to_archive_a_talk_page_629d.html" title="Wikipedia:How to archive a talk page">archive</a></b> of past discussions. <b>Do not edit the contents of this page.</b> If you wish to start a new discussion or revive an old one, please do so on the <span class="plainlinks"><a href="http://en.wikipedia.org../../../a/r/t/Talk%7EArtificial_consciousness_9bc5.html" class="external text" title="http://en.wikipedia.org../../../a/r/t/Talk%7EArtificial_consciousness_9bc5.html" rel="nofollow">current talk page</a></span>.</td>
</tr>
</table>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Comment"><span class="tocnumber">1</span> <span class="toctext">Comment</span></a></li>
<li class="toclevel-1"><a href="#.22Supposed_Experts.22_in_Artificial_Consciousness"><span class="tocnumber">2</span> <span class="toctext">"Supposed Experts" in Artificial Consciousness</span></a></li>
<li class="toclevel-1"><a href="#AC_and_Strong_AI"><span class="tocnumber">3</span> <span class="toctext">AC and Strong AI</span></a></li>
<li class="toclevel-1"><a href="#The_concept_of_machine"><span class="tocnumber">4</span> <span class="toctext">The concept of machine</span></a>
<ul>
<li class="toclevel-2"><a href="#Counter-example"><span class="tocnumber">4.1</span> <span class="toctext">Counter-example</span></a></li>
<li class="toclevel-2"><a href="#Brain_size"><span class="tocnumber">4.2</span> <span class="toctext">Brain size</span></a></li>
</ul>
</li>
</ul>
</td>
</tr>
</table>
<p><script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script><a name="Comment" id="Comment"></a></p>
<h2><span class="mw-headline">Comment</span></h2>
<p>The link to the <a href="../../../a/r/t/Artificial_consciousness.html#External_links" title="Artificial consciousness">Enticy Institute</a> on the article page is a link to a patent nonsense site. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 14:09, 2 May 2004 (UTC)</p>
<dl>
<dd>Yep, don't appreciate it either. Is it really institute? <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 16:22, 2 May 2004 (UTC)</dd>
</dl>
<p><br /></p>
<p><a name=".22Supposed_Experts.22_in_Artificial_Consciousness"></a></p>
<h2><span class="mw-headline">"Supposed Experts" in Artificial Consciousness</span></h2>
<p>Let us attempt to reach consensus on who are the leading proponents of <i>artificial consciousness</i> and its relation to <i>artificial intelligence</i>. OK? <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 08:44, 26 Apr 2004 (UTC)</p>
<p>Various suggestions (please add to list):</p>
<ul>
<li><a href="../../../d/o/u/Douglas_Hofstadter_9e14.html" title="Douglas Hofstadter">Douglas Hofstadter</a> - consciousness is a central interest as is AC</li>
<li><a href="../../../d/a/n/Daniel_Dennett_375e.html" title="Daniel Dennett">Daniel Dennett</a> - wrote <i>Consciousness Explained</i> and deals with AC</li>
<li><a href="../../../r/o/g/Roger_Penrose_86ab.html" title="Roger Penrose">Roger Penrose</a> - denies AC though most scientists dismiss his reasoning</li>
<li><a href="../../../t/h/o/Thomas_Nagel_73f8.html" title="Thomas Nagel">Thomas Nagel</a> - subjective experience</li>
<li><b>Igor Aleksander</b> - AC</li>
<li><b>Owen Holland</b> - AC</li>
<li><b>Rod Goodman</b> - AC</li>
<li><b>Sam S. Adams</b> - AC - Joshua Blue project, IBM Research</li>
<li><a href="../../../g/e/r/Gerald_Edelman_ed99.html" title="Gerald Edelman">Gerald Edelman</a> - Nobel prize winner, respected ideas on the theory of mind</li>
<li><a href="../../../c/y/n/Cynthia_Breazeal_f895.html" title="Cynthia Breazeal">Cynthia Breazeal</a></li>
<li><a href="../../../s/t/e/Stephen_Jones_04f9.html" title="Stephen Jones">Stephen Jones</a> <a href="http://www.adelaidebiennial.com/cocoon/adelaidebiennial/jones_stephen.xml" class="external autonumber" title="http://www.adelaidebiennial.com/cocoon/adelaidebiennial/jones_stephen.xml" rel="nofollow">[1]</a> <a href="http://www.culture.com.au/brain_proj/CONTENT/NEWPAPRS.HTM" class="external autonumber" title="http://www.culture.com.au/brain_proj/CONTENT/NEWPAPRS.HTM" rel="nofollow">[2]</a></li>
</ul>
<hr />
<dl>
<dd>But Hofstadter, Dennett, Penrose, and Nagel are philosophers of AI or philosophers of mind. They use the term "AI" or "consciousness", but not "artificial consciousness". I don't really have information on the others. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 16:05, 26 Apr 2004 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>AC can perhaps be seen as a part of AI or as a part of Consciousness. Interestingly Wikipedia's article on Hofstadter says he is interested in consciousness not intelligence. Readers of his work will know, of course, that he is interested in both. But in his case it may be wrong to say that he is interested in AC only as a part of AI. I believe the same comments apply to Dennett who wrote a book entitled <i>Consciousness Explained</i>, not a book called <i>Intelligence Explained</i>. Penrose is a celebrated mathematical physicist, but a philosopher of dubious importance. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 22:16, 26 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I included Nagel only because his subjective experience concept has importance for AC. Dennett talked about of what should be considered AC, but the same thing (AC) is unfortunately often referred to under different names, what may not be proper. The only importance of Penrose is that he denies AC (but not all subfields of AI), Hofstadter writes a general philosophy similar to Dennett, what also touches AC. At present Igor Aleksander, Owen Holland and Rod Goodman work on big project to create a conscious robot <a href="http://www.guardian.co.uk/uk_news/story/0,3604,1028776,00.html" class="external free" title="http://www.guardian.co.uk/uk_news/story/0,3604,1028776,00.html" rel="nofollow">http://www.guardian.co.uk/uk_news/story/0,3604,1028776,00.html</a> <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 19:13, 26 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<p><a name="AC_and_Strong_AI" id="AC_and_Strong_AI"></a></p>
<h2><span class="mw-headline">AC and Strong AI</span></h2>
<dl>
<dd>How about moving 'artificial consciousness' over to <a href="../../../s/t/r/Strong_AI_efb5.html" title="Strong AI">strong AI</a> instead? <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 16:19, 26 Apr 2004 (UTC)</dd>
</dl>
<p>I disagree, strong AI is a limited proposition about information processors (digital computers/Turing machines) artificial consciousness is about any type of machine, including those based on a 20,000 gene set of DNA strands.</p>
<p><br /></p>
<dl>
<dd>
<dl>
<dd>There is no <b>strong AI</b> article, the link refers to AI article where strong AI is also mentioned. And there is no strong AI theory, also there are no strong AI projects, there are no strong AI programs, it is usually only mentioned in comparison to weak AI. As much as I know, so far only AC is something what supposed to theoretically perform of what strong AI supposed to, but it is not the same as strong AI, and likely more genuine compared to consciousness than strong AI. There is no place in AI article where information about AC can be written, also why this approach cannot be separate article when the subfields of AI are? If there was enough to say about strong AI, then it could be a separate article as well, the reason why it was not a separate article was just that probably nobody knew what to write about it, it is not determined at all what strong AI is. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 19:30, 26 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Another tiresome set of assertions wrongly presented as hard fact. There <b>is</b> a strong AI theory, there <b>are</b> strong AI projects, the field of AI is vehemently split between believers of the weak and strong AI theories, strong AI is <b>not</b> only mentioned in contrast to weak AI. No one who has read widely could believe otherwise. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 22:16, 26 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Then say one strong AI theory, or one strong AI project, or even one good strong AI definition. I read AI forums and followed AI for a long time, and saw that it's not clear for almost anybody what it is. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 01:10, 27 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Now you deny even a definition! If I provide an example will you admit you are wrong? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 11:23, 27 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I think the science is plain: AC can be real/genuine/true consciousness. This is a minority opinion on this talk page but is nevertheless a popular view among computer scientists and philosophers of mind. As such I think AC fits into the <b>Strong AI</b> section of the <a href="../../../a/r/t/Artificial_intelligence.html" title="Artificial intelligence">artificial intelligence</a> article rather well but I think a separate article is a better idea. Those here who (in defiance of the <a href="../../../c/o/p/Copernican_principle.html" title="Copernican principle">Copernican principle</a> and <a href="../../../o/c/c/Occam%27s_razor.html" title="Occam's razor">Occam's razor</a> and the <a href="../../../c/h/u/Church-Turing_thesis_c156.html" title="Church-Turing thesis">Church-Turing thesis</a>) think that AC can only ever be a simulation of real/genuine/true consciousness can not, in my opinion, be happy with including AC into Strong AI because Strong AI is real/genuine/true intelligence - not a simulation of it. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 22:16, 26 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>It may be plain for you, but at least it's not that plain for <a href="../../../t/h/o/Thomas_Nagel_73f8.html" title="Thomas Nagel">Thomas Nagel</a>, it's also that without understanding or considering everything, things look like much more simple. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 01:24, 27 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Even if AC does turn out to be a branch of AI, I think there is still room for an article to clarify that point - separate from the AI article. If it does turn out that AC can be developed as an end in its own right, as I had always assumed, then even more point in it having a separate article. I have no great learning in this field, and I come here primarily to learn. Can we have summaries of the main proponents' arguments about consciousness (as distinct from intelligence) in the main article, please? My offerings, for what they are worth are as follows:</dd>
<dd>1) There isn't, from what I have gleaned, a project to pursue the development solely of a machine implementation of consciousness for its own sake, or even as part of some other purposeful endeavour;</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>I think for many researchers AC is the holy grail. <i>Growing up with Lucy</i> by Steve Grand is perhaps not an example with much promise but that is surely his goal? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:45, 30 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>"Non-disciplinary" philosophy of "general purpose building blocks," no software "yet". Like building a house from bricks. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 15:25, 30 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>2) I do not agree that there should necessarily be a strict dichotomy between weak and strong <i>consciousness</i> - the distinction certainly doesn't arise with natural forms of consciousness, and therefore a coherent definition of AC <i>per se</i> is required before we can perhaps make distinctions that were developed for the AI Topic;</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>If by <i>strong</i> and <i>weak</i> you mean <i>genuine/real/true</i> and <i>non-genuine/simulated/pretend</i> then, of course, the distinction does not arise in natural consciousness. Except when we pretend to be asleep! <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:45, 30 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>3) I can imagine implementations of AC in various contexts that might be considered just as art - if they have no obvious function - or as entertainment. Though I agree about Wikipedia not being primary research, it does have the propensity to make connections (links) between subject-matter that doesn't occur anywhere else. An article that bridges the gap between what SF writers imagine in their stories and what is both theoretically and practically possible from an engineering perspective is a useful endeavour and doesn't, I rhink, conflict with what Wikipedia is about. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 00:41, 27 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Yes! You can buy solar powered (non-flying) decorative butterflies using muscles wires on some robotics sites. I reckon with a bit of tweaking they could have a genuine consciousness in excess of the most advanced thermostat. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:45, 30 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>As much as I know no scientist ever argued that thermostat is conscious.Thermostat is a Chalmers example what he didn't provide because he himself thinks that thermostat is conscious, but for reductio ad absurdum the Lloyd's argument that the connectionist models might shed light to subjective aspects of consciousness described by Nagel. "On the face of it, this approach is put forward as a way of dealing with Nagel's worries about consciousness, where the central mystery is: why is there something it is like to be us at all? There is a huge prima facie mystery about how any sort of physical system could possess conscious experience. Lloyd holds out the promise that connectionist models might shed light on this question, but at the end of the day the models seem to leave the key explanatory question unanswered. Even if we were to go out on a limb and suppose that these simple systems are conscious, the question of explanation would still remain untouched." <a href="http://jamaica.u.arizona.edu/~chalmers/notes/lloyd-comments.html" class="external free" title="http://jamaica.u.arizona.edu/~chalmers/notes/lloyd-comments.html" rel="nofollow">http://jamaica.u.arizona.edu/~chalmers/notes/lloyd-comments.html</a> (article by Chalmers). <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 16:33, 1 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Even this selective quote does not say quite what Tkorrovi seems to think. See below discussion in Thermostat section. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 12:15, 3 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>The reason why there is no "strong AI project" in the way you think of it is because the real work done in "strong AI" is in <b>philosophy</b>. You can be an engineer and say, "Since no one is creating strong AI, I will do it!" But how do you start? What makes your project not weak AI? Obviously, we haven't figured out what is necessary or sufficient for consciousness.</p>
<p>Weak AI is important for strong AI because it serves as inductive evidence for consciousness/intelligence. That is, if we can make something that <i>seems</i> conscious/intelligent, there is a possibility that it is truly conscious. If we can't even make something that exhibits intelligent/conscious <i>behaviour</i>, then that it is <i>truly</i> conscious is out of the question. Hence, the idea behind the Turing Test is worth mentioning.</p>
<p>Lastly, Dennett, Nagel, etc. are not "experts" of AC/strong AI in that what they say must be true. Philosophy of mind and AI is an ongoing debate, and what they say is only one side of the picture. Characteristic of philosophy, there are many competing theories that exist.</p>
<p>--<a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 10:33, 27 Apr 2004 (UTC)</p>
<dl>
<dd>Whilst AI seems to have been dominated by philosphers and its theories disappearing up their own arse (i.e. not leading to particular progress in the engineering field), research into consciousness is focused in <a href="../../../p/s/y/Psychoneurology.html" title="Psychoneurology">psychoneurology</a>, in particular using scanners to correlate perceptual and cognitive activity with neural activity. There may one day be (if there isn't already) a mental map based on this research that equates to the human genome project (already completed). My suggestion is that artificial implementations that attempt to simulate the operation of conscious processes, as evinced from such neurological research, is the path towards AC actualisation. This will leave philosophy way behind. I am not concerned with the philosophers' views on what constitutes consciousness or not - they'll never reach a consensus, just as they've never reached consensus even on logic or ethics. However if I can produce and sell a machine whose advertising claims that that machine is conscious, or even artificially conscious -- and that claim isn't disallowed by the Advertising Standards Authority -- then I'll be able to claim strongly that my AC is <i>real</i> AC. Some implementations that I've considered as candidate <i>AC products</i> are:
<dl>
<dd>
<ul>
<li>A <i>conscious</i> <b>bus stop</b> that recognises the people who regularly stand next to it, welcomes them, tells then when their bus is due, introduces them to each other, shares in their complaints about the bus service, answers questions by sending voice-recognised text to Google, plays music, replays horrifying images of muggings that have taken place near it, etc, etc.</li>
<li>(Related to the previous) A <i>conscious</i> <b>policeman on the beat</b> that collects evidence, helps the public in simple ways like answering questions about the way to the nearest bus stop, and never wants promotion</li>
<li>A <i>conscious</i> <b>sexual partner</b> that never thinks, never complains, and whose heuristic is designed to ensure increasing satisfaction the more it is used. This is perhaps the most promising idea in that there is already a well-established market for sex toys</li>
<li>A <i>conscious</i> (and articulated) <b>computer screen</b> combined with webcam, upon which appears an animated representation of a human (which a camera on this or on other instances had previously <i>observed</i> and which uses morphing software to drive its images), which proactively interacts with its <i>user</i> (partner?) and takes on personae which are effectively caricatures of people with whom it has interacted previously. (Of course one could buy characters, much like people buy mobile phone ring tones, and people who had used the product to the extent required for the machine to build virtual representations of them could sell their characters. A useful pastime and money-spinner perhaps for old celebrities)</li>
<li>A <i>conscious</i> <b>driving assistant</b> (already marketed by BMW on its latest model) that keeps your car going in the right speed and direction even when the actual driver becomes inattentive</li>
<li>A <i>conscious</i> <b>dinner party host</b> that ensures quests' glasses are filled, coordinates the timing of the cooking, makes trivial conversation (AI component required here, perhaps), and interrogates bus stops across the internet to trace late-comers</li>
</ul>
</dd>
<dd>If any of these ideas were freshly patentable then they aren't now! They are in the public domain on wikipedia. And I don't think you need a philosopher to tell you whether they are implementable. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 08:06, 1 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>As I said before, the results of scanning the neural activity <a href="http://www-inst.eecs.berkeley.edu/~cs182/readings/ns/article.html" class="external free" title="http://www-inst.eecs.berkeley.edu/~cs182/readings/ns/article.html" rel="nofollow">http://www-inst.eecs.berkeley.edu/~cs182/readings/ns/article.html</a> suggest that awareness is awareness of processes. Human genome project is completed only in the sense that the DNA sequences are mapped, but only a function of a very few fragments of DNA are known. The complexity of that problem is so huge, that it's not feasible to understand everything that way. Neither probably by scanning the whole neural activity. In addition to that, such scanning only shows when neurons fire, but nothing about what happens inside the neuron, but neuron may be as complex as a computer. And even if we could do that, again just having a map would not by itself explain anything. There is also by far not enough information in DNA for all brain activity what even a child has, what shows again that the brain activity is not pre-programmed, but is a result of learning. What we must understand is how that happens, not what *exactly* is in the brain. AC is useful for providing an experimental method to test philosophy. I thought just about a regulator at first, what could model the processes based on the input and predict how they would develop. A natural processes, such as friction of the tyres of your car, what depends on so many things, and cannot be uniformly modelled. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 15:54, 1 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>"What makes your project not weak AI?" "Objective Less Genuine AC" should do that. Well, "Genuine AC" should do that as well. Not sure though how Paul interprets it, and why he said that thermostat can considered to be "Genuine AC", concerning that you should ask him, I don't support "Genuine AC" because I don't think that it would be ever possible to model consciosness completely. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 09:40, 28 Apr 2004 (UTC)</dd>
</dl>
<p>You use <i>project</i> and <i>expert</i> in a restrictive way which suits your argument. Given that I agree with what you say. Please do not misunderstand me: I never said the problems are solved and now all we need is enough <a href="../../../m/e/c/Meccano.html" title="Meccano">Meccano</a> to construct Sentient Expert Mk 1. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 11:13, 27 Apr 2004 (UTC)</p>
<dl>
<dd>The 'you' in my first paragraph was directed at Tk, and my comments about <i>projects</i> and <i>experts</i> was directed more at him as well. I mostly agree with you (PB) when you said that there <i>are</i> strong AI projects, etc., but I was addressing the restrictive sense of <i>project</i> as in an engineering project, which was what I took Tk to mean. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 00:35, 28 Apr 2004 (UTC)</dd>
</dl>
<p>Obviously there isn't a Strong AI project like the Boeing 7E7 <i>engineering</i> project. How many research grants, how many funded scientists does there have to be before a <b>project</b> is admitted? There are, of course, many Strong AI research projects. And each computer scientist / philosopher of mind engaged in Strong AI has a <b>theory</b>, or pretends to have one, to get his/her funding. The theory is not established like, for example, Special Relativity but to say there is no theory (or rather no set of candidate theories) is just to redefine the word. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 11:40, 27 Apr 2004 (UTC)</p>
<dl>
<dd>Yes, there are engineering projects that are created for a purpose other than making something useful for humans. But calling them 'strong AI' projects makes it sound like there are conscious robots out there. However, people have created robots that act like insects that can move around autonomously, etc. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 00:35, 28 Apr 2004 (UTC)</dd>
</dl>
<p>Upon reconsideration, I agree that AC should remain a separate article and should not be merged with AI nor moved to Strong AI. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 03:20, 28 Apr 2004 (UTC)</p>
<p><a name="The_concept_of_machine" id="The_concept_of_machine"></a></p>
<h2><span class="mw-headline">The concept of machine</span></h2>
<p>Daniel Dennett compared mind to a machine, but the problem is that he never said what he means by machine (if you find where he did that, then please say). Machine is usually interpreted as something human-made or something what humans can make. Then there are virtual machines, like Turing machine, what are theoretical concepts, what cannot always be made, like Turing machine with endless tape. or we cannot implement them because it's impossible to obtain all necessary information to implement them. So machine and virtual machine are not the same. We can say that mind is equivalent to certain virtual machine what satisfies Church-Turing thesis, what it certainly is, but this is not the same as to say that mind is a machine. We may call such theoretical machine a Church-Turing machine, to name it somehow. Then we may say that mind is some kind of Church-Turing machine. We cannot follow the logic of Dennett until we don't know what Dennett meant by machine, especially when the question is <b>exactly</b> in the difference of consciousness and a machine. So this is a theoretical problem, I hope it's understood. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 11:41, 28 Apr 2004 (UTC)</p>
<hr />
<p>Fortunately for Dennett the Church-Turing thesis says that all machines are equivalent in computing ability except for speed and memory capacity. So Dennett does not have to say what type of machine he is talking about. One idealised computing machine, the Turing machine, is shown by Turing to be equal or superior in capability to other computing machines. A Turing machine is of course implementable (and there are examples on the web) except for the infinite memory size. But any program which runs in finite time can only access a finite amount of tape. The human being has a finite life time and so doesn't need an infinite tape. According to the Church-Turing thesis, any computer can mimic any other. The unavoidable conclusion is: If your Sinclair ZX-80 cannot mimic the human being replace the C30 cassette tape with a C60. Of course, there is also the problem of writing the software. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 12:02, 28 Apr 2004 (UTC)</p>
<p>So, are you saying that humans are not machines? That there is something spiritual about them: a soul or a magic spark? Or are you questioning the Church-Turing thesis? Or are you questioning it's applicability to humans on the basis of new physics? Or are you saying that the software cannot be written? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 11:46, 28 Apr 2004 (UTC)</p>
<dl>
<dd>Are you saying that humans <i>are</i> machines? The argument for strong <a href="../../../a/i/_/AI_0a40.html" title="AI">AI</a> goes:
<dl>
<dd>(1) Given that the mind is the software/hardware brain, and</dd>
<dd>(2) Given the <a href="../../../c/h/u/Church-Turing_thesis_c156.html" title="Church-Turing thesis">Church-Turing thesis</a>,</dd>
<dd>(3) The possibility of Strong AI must be accepted.</dd>
</dl>
</dd>
<dd>I do not disagree with (2), but (1) is questionable. --<a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 02:37, 5 May 2004 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Yes, that humans are but machines is a very common view amongst many/most scientists and many/most philosophers. Even Penrose agrees with (1) but he disagrees with (2). See <a href="../../../f/u/n/Functionalism.html" title="Functionalism">functionalism</a>. But the point is not whether you or I agree with either (1) or (2) and of course you can logically disagree with either but that <b>if</b> you accept them both <b>then</b> the conclusion (3) is unavoidable. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 02:48, 5 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Many/most scientists and philosophers believe in some form of materialism, but I don't think many/most believe that the mind is a machine qua <b>symbol manipulation</b>. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 04:03, 5 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>If I change "many/most" into "many" then the point is incontrovertible: Many scientists and philosophers do believe that the hardware/software brain is a computing machine.</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>My point is that the mind is not necessarily a virtual machine. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 04:08, 5 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>If by "virtual" you mean not-real then I agree with you. But I think we disagree because many do believe the mind is really the software/hardware machine. That I strongly believe so is hardly pertinent! Your position is, of course, not an unusual one: Most religions are on your side. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 11:43, 5 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>What??! By virtual machine I mean a <a href="../../../f/i/n/Finite_state_machine.html" title="Finite state machine">finite state machine</a> or <a href="../../../t/u/r/Turing_machine.html" title="Turing machine">Turing machine</a>. The mind may not be analogous to concepts of software/hardware, because it is controversial that cognition consists of merely symbol manipulation—symbol manipulation as in the reading and writing of discrete tokens such as 0 and 1. In the <a href="../../../c/o/n/Connectionism.html" title="Connectionism">connectionist</a> framework, cognition isn't transformation of discrete symbols, but rather patterns of activity. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 14:02, 5 May 2004 (UTC)</p>
<p>I think you may be redefining "<a href="../../../v/i/r/Virtual_machine.html" title="Virtual machine">virtual machine</a>". The view you express, if backed up by appropriate citings, should go in the article. But others think (and I reckon I can find references to back this up) that "patterns of activity" is just like the flashing of lights on the panel of a 1970's computer. What is going on, underneath the patterns, is symbol manipulation. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 22:22, 5 May 2004 (UTC)</p>
<dl>
<dd>"Virtual machine" I took from Tkorrovi's post, the first one in this section. Connectionist nets are modelled after <a href="../../../n/e/u/Neuron.html" title="Neuron">neurons</a> in the brain. The firing of one node activates certain other nodes in its vicinity, depending on the connection strength between it and a neighboring node, which is supposed to simulate how neurons work. In <a href="../../../n/e/u/Neural_net.html" title="Neural net">neural nets</a>, I believe connections are given numerical weightings, e.g. 0.55. I think the numbers aren't supposed to be discrete, but are theoretically supposed be <a href="../../../r/e/a/Real_number.html" title="Real number">real numbers</a> (i.e. continuous). If you accept this model, cognition cannot be symbol manipulation, because there are no discrete <a href="../../../t/o/k/Token.html" title="Token">tokens</a> like either 0 or 1, but rather, it uses the set of real numbers (of which there are infinite, and have no discrete divisions). Hence, if you accept this model, the mind cannot be a Turing machine. <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 00:12, 6 May 2004 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I think the use of "virtual" in this context is a red herring. As a software professional, I have always understood a virtual machine to be an implementation of a machine within another machine, e.g. the Java Virtual Machine within the Windows operating system (machine). Now whilst it might be worthwhile to think of "mind" as a virtual machine machine within the "body" machine, I do not think that is the intention here and I don't think that analogy holds anyway. It is more likely, I think, that Tkorrovi looked up "virtual" in the dictionary and thought that it would be useful to describe mind as "a bit like a machine", or "virtually a machine", which is of course misleading anyway, as we are aiming to indicate whether mind is a machine at all, and as Wikwikifast points out, from a scientific materialist perspective, it is. The salient question, as Wikiwikifast again correctly identifies, is to ask what sort of machine the mind is, because that will throw light on whether it can be emulated using the methods available to us. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 06:49, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>"Virtual machine" is another of those compound nouns the meaning of which can be perfectly well understood from each of the constituent words. It also has its own <a href="../../../v/i/r/Virtual_machine.html" title="Virtual machine">article</a>. The first usage of that term in this section is incorrect. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:39, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p><br />
Do real numbers exist in nature? This is an interesting philosophical question. Even distance, we are told by the quantum theorists, is discrete. Maybe only rational numbers exist. Certainly our vision is digital and discrete. The pixels are close together and we do not see pixellation - there must be smoothing happening in software - but the retina consists of discrete rods and cones. In the connectionist nets the values assigned to the nodes are not chosen from the whole set of real numbers but from a subset of the rationals: This is a proven limitation of all computers. As the firing of a neuron in the brain must involve an integer number of electrons we also know that not all real numbers can be represented at the synapse junctions. The neuron cannot be set to fire after the transfer of a fractional number of electrons. The brain does not process real numbers. Brain processing is chemical and electrical. Everything is a multiple of a number of molecules or a multiple of a number of electrons. Brain processing is discrete. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 01:17, 6 May 2004 (UTC)</p>
<p>See <a href="../../../c/h/u/Church-Turing_thesis_c156.html#Philosophical_implications" title="Church-Turing thesis">philosophical implications of the Church-Turing thesis</a>. Is the Universe computable? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 01:35, 6 May 2004 (UTC)</p>
<dl>
<dd>You have a good point. However, I just wanted to point out that not everyone believes in symbolicism.
<dl>
<dd><i><b><a href="http://www.artsci.wustl.edu/~philos/MindDict/symbolicism.html" class="external text" title="http://www.artsci.wustl.edu/~philos/MindDict/symbolicism.html" rel="nofollow">symbolicism</a></b> - An approach to understanding human cognition that is committed to language like symbolic processing as the best method of explanation. ... The commitments of symbolicism have been challenged by <a href="http://www.artsci.wustl.edu/~philos/MindDict/connectionism.html" class="external text" title="http://www.artsci.wustl.edu/~philos/MindDict/connectionism.html" rel="nofollow">connectionist</a> research and most recently the <a href="http://www.artsci.wustl.edu/~philos/MindDict/dynamicsystems.html" class="external text" title="http://www.artsci.wustl.edu/~philos/MindDict/dynamicsystems.html" rel="nofollow">dynamical systems theory</a> approach to cognition.</i> - <a href="http://www.artsci.wustl.edu/~philos/MindDict/symbolicism.html" class="external text" title="http://www.artsci.wustl.edu/~philos/MindDict/symbolicism.html" rel="nofollow">Dictionary of Philosophy of Mind</a></dd>
</dl>
</dd>
<dd>See also <a href="../../../j/o/h/John_Lucas_%28philosopher%29_1d87.html" title="John Lucas (philosopher)">John Lucas</a>' <i><a href="../../../m/i/n/Minds%2C_Machines_and_G%C3%B6del_5d48.html" title="Minds, Machines and Gödel">Minds, Machines and Gödel</a></i> for an argument against the claim that the mind is a Turing machine. Instead of debating incessantly over talk pages, I should probably use my time constructively by contributing to the AI and cognitive science articles... <a href="../../../w/i/k/User%7EWikiwikifast_7e82.html" title="User:Wikiwikifast">Wikiwikifast</a> 02:38, 6 May 2004 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>As to what type of machine the brain is, this is settled for most scientists. Turing showed that anything which does symbol manipulation is no more powerful than the Turing machine. And anything passing about discreet lumps of stuff (e.g. electrons and molecules) is doing symbol manipulation in the computer science sense. It is a finite state machine. All finite state machines are no more powerful that the Turing machines. Proven computer science result. It's maths. No argument. The onus is on the dissenters to explain what is wrong with any of this reasoning. Penrose understands this and attempts to do so, but established science finds serious flaws in his arguments. But Penrose understands what it is he has to show, most other dissenters ignore the <a href="../../../s/c/i/Scientific_method.html" title="Scientific method">scientific method</a>. That is what is happening here. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:39, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p><br /></p>
<dl>
<dd>
<dl>
<dd>Cognitive science article would indeed be a better place for that. This is not necessary for AC considering the Thomas Nagel argument that subjective experience cannot be reduced (modelled), and this is included in the article. Considering that, it doesn't matter whether subjective experience is physical. I think it's physical and Nagel thinks that it's physical, but this doesn't matter for AC. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 08:59, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>If the mind is no more powerful than the Turing machine then what accounts for subjective experience? A magic spark? The soul? Penrose quantum quackery? Maybe Nagel is wrong. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:45, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>It (that the mind is a machine) does matter for genuine/true/real/strong AC. Obviously. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:39, 6 May 2004 (UTC)</p>
<hr />
<p>All machines are equivalent in computing ability except for speed and memory, but there is a difference between virtual (theoretical) machine and man-made machine also in that it may not be possible to obtain all necessary information to make the machine, in spite that theoretically some type of virtual machine can implement it. Please read Thomas Nagel "What is it like to be a bat" <a href="http://members.aol.com/NeoNoetics/Nagel_Bat.html" class="external autonumber" title="http://members.aol.com/NeoNoetics/Nagel_Bat.html" rel="nofollow">[3]</a> to get an idea. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 12:19, 28 Apr 2004 (UTC)</p>
<p>I have read the book*. I have demonstrated the equivalence of the Sinclair ZX-80 and the human being (except for speed and memory capacity). Neither of these are theoretical machines. Trying my best to interpret what you have said I think you have chosen the last of the presented alternatives: You think the software cannot be written. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 12:28, 28 Apr 2004 (UTC)</p>
<dl>
<dd>(*)I have read the book "The Mind's I" in which Nagel's ideas are quoted at length and the bat essay may appear in it's entirety. The critique of those ideas which appears in that book and especially how they are contrasted with other ideas is interesting and entertaining. But, I suggest, not entirely relevant to the narrow point we are trying to resolve here. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 12:43, 28 Apr 2004 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Yes it may be not entirely relevant. It is said in the article <a href="../../../t/h/o/Thomas_Nagel_73f8.html" title="Thomas Nagel">Thomas Nagel</a> that "While many philosophers of mind and cognitive neuroscientists accept the fundamental distinction between the subjective and the objective, they often have not accepted Nagel's dismal conclusions." This is almost that what is relevant for AC. But concerning dismal conclusions, maybe Nagel is not so well understood, he doesn't deny the reduction of that what is objective. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 12:56, 28 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<p>Whether written or taught, we cannot make sure that it can be developed so that it implements consciousness <b>completely</b>, but we can develop it so that it implements consciousness <b>partly</b> when we don't omit anything, except that what is not objective. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 12:39, 28 Apr 2004 (UTC)</p>
<p>OK, I cannot deny that view but that is just one way things might work out. At some point the built-consciousness might reach a critical mass, transfer itself to a local super-computer cluster of 100,000 Trituim 86666MHz processors running MacOS XII, attach several Terabytes of NAS memory and, changing gear, evolve a consciousness which is a superset of human consciousness. But, please, neglect this flight of fancy for the moment. I return to your view: Will your partially implemented consciousness be a genuine manifestation of consciousness or not? And, if not, why not? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 12:52, 28 Apr 2004 (UTC)</p>
<dl>
<dd>The problem is that whether it is genuine consciousness or not can never be found out. Because of that, as science must be objective, in scientific terms we must say no. But there is a possibility that it may seem one day very genuine, especially if maybe implemented on quantum computer, maybe even exceed some human abilities, in theory there seems to be nothing what restricts such system. And then one day we may believe that this is genuine consciousness, but there would be no scientific way to find out, all what we can test even in that case would be that it is artificial consciousness. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 13:13, 28 Apr 2004 (UTC)</dd>
</dl>
<p><br /></p>
<dl>
<dd>
<dl>
<dd>But, as an aside, and this is another fact to trip up Penrose, the Church-Turing thesis still applies to the <a href="../../../q/u/a/Quantum_computer.html" title="Quantum computer">quantum computer</a>. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 13:47, 28 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Sure, I also think that Church-Turing thesis apply, and I think it's not Gödel's theorem what is wrong, but rather the way how Penrose uses it. This question has been discussed endlessly in the Internet. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 20:59, 28 Apr 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>Dennett deals with this issue well in both <i>The Intentional Stance</i> and <i>Consciousness Explained</i>. Essentially, he denies the human any special place in the universe, he says we allow another human consciousness because he says he is, and says it is mere arrogance to deny something else consciousness if it acts as if it is conscious and if it claims it is conscious. He makes the point better than I do, doubtless. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 13:24, 28 Apr 2004 (UTC)</p>
<p>As I understand it he is saying your use of subjective and objective you fail to apply to humans themselves. Subjectively you say you are conscious. Objectively, how do I know? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 13:26, 28 Apr 2004 (UTC)</p>
<p>Yes, the only reason why we can say that we are conscious is that we are humans, and capable humans are considered to be conscious when they don't happen to be in coma. We cannot even completely compare our consciousness to that of somebody else. This doesn't mean that we are better, this is just how we determine consciousness. Maybe dolphins are better than we are, but we can never know. <a href="../../../t/k/o/User%7ETkorrovi_0c02.html" title="User:Tkorrovi">Tkorrovi</a> 13:40, 28 Apr 2004 (UTC)</p>
<p>Except that dolphins act as if they are conscious, they do all but <i>say</i> they are conscious. I have seen a conscious dolphin, I am sure. Neither you nor I can be sure that the other is conscious: Indeed, for all you know I have tapped this out on a panel in my tank. [[User:Flipper|Flipper]] <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 13:47, 28 Apr 2004 (UTC).</p>
<p><a name="Counter-example" id="Counter-example"></a></p>
<h3><span class="mw-headline">Counter-example</span></h3>
<p><a href="../../../o/l/i/Oliver_Sacks_b9ec.html" title="Oliver Sacks">Oliver Sacks</a> describes in his book <i>The Man Who Mistook His Wife For A Hat</i> the case of autistic-savant identical twins who were able to compute large prime numbers within a timescale that was several orders of magnitude less than what would be required by the most powerful computer to perform the same feat <a href="http://www.maths.ex.ac.uk/~mwatkins/zeta/twins.htm" class="external autonumber" title="http://www.maths.ex.ac.uk/~mwatkins/zeta/twins.htm" rel="nofollow">[4]</a>. These twins were not articulate enough to describe the methods they used, and I think their ability remains a mystery twenty years later. They certianly did not have the mathematical ability to compute prime numbers using any standard algorithm such as the sieve of Erastothenes - they could not even do simple multiplication. Such pathologies as Sacks describes raise questions about the operation of the brain that could possibily be used to counter the Church-Turing thesis, or at least to question it until a viable explanation had been found. The twins in Sacks' story seemed to have a particular <i>consciousness</i> of primeness (and not much else besides) and savoured each new prime number they encountered as one might savour a newly discovered vintage wine. Sacks mentions a number of examples of enhanced and deficient mental abilities that surely throw some light on our conception of consciousness, and which perhaps should be taken into account in our discussions here. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 07:13, 6 May 2004 (UTC)</p>
<p><br />
But you invent magic. We do not know how we remember the spelling of "Erastothenes" but we do not invent magic to explain it. The scientific method does not say "invent science to support your prejudices". <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 09:34, 6 May 2004 (UTC)</p>
<p>Experiments on primates have shown that there is an area of the brain concerned with visual cognition that does pattern-matching and which, interestingly, operates at a level of resolution (topological complexity, to be more precise)commensurate with alphabetic and other writing system symbols (e.g. Chinese). This is used to show that our brains were not designed for reading, but that we have innate capabilities (shared with other primates) that lend themselves to be able to interpret writing. So our spelling ability is capable of being understood at an elementary level. However the recognition of prime numbers is held to be a difficult feat to perform algorithmically, and is indeed the basis of modern cryptography. Therefore if we cannot explain how certain individuals' brains can <i>divine</i> prime numbers, surely that is a good argument to suggest that the Church-Turing thesis may not hold in all circumstances when it comes to understanding consciousness, as I suggest above. If we <i>could</i> explain it then there is the possibility that cryptography would founder. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 09:52, 6 May 2004 (UTC)</p>
<p>Firstly, you overstate the ability of the idiots savant. They could not do <b>any</b> prime number problem. Related problems, e.g., which a mathematician would be able to work out if they knew what the twins knew, stumped the twins completetly. You have managed to remember and store away a large vocab, to store away a fairly detailed map of London, to remember many facts about scores of people. These idiots savant did none of that. The storage capacity of the brain is known to be enormous. Yet I can store a lot of prime numbers on my laptop. No one is saying that the brain is not remarkable. But no new science should be invented until necessary. It is difficult for people to appreciate they are not God's chosen ones. We <b>feel</b> special. A more plausible explanation than the brain not being finite state sub-Turing is that it's drugs in the water that make you think this way. No new science required for that. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 10:03, 6 May 2004 (UTC)</p>
<p>A much better counterexample is the finite state machine known as Beethoven. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 10:06, 6 May 2004 (UTC)</p>
<dl>
<dd>
<dl>
<dd>Please would you provide a reference to Beethoven in this context, unless you mean the composer. If the latter, why should the ability to produce musical patterns be cited as a counter-example for the Church-Turing thesis in relation to mind? <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 10:38, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>I agree with you! Beethoven, even though he was much more impressive than Sacks's twins, is no evidence for humans being more than FSMs. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 10:47, 6 May 2004 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>In the story that Oliver Sacks tells (and he was a neurologist invited to examine the twins), at first no one was aware that the twins were savouring prime numbers. He listened to them, noted down the numbers they mentioned, and took his notes to a mathematician who indicated that they were all primes. Sacks then wrote down some more primes - bigger ones - and re-joined the twins. He mentioned his primes and the twins paused to consider them. They had never encountered such large primes and were delighted with the new player (Sacks) in their game. I forget how large they went in terms of the numbers mentioned, (and the twins did take longer to recognise larger primes) but I think it's fair to say that it's unlikely they had memorised a list previously presented to them. They also, incidentally, had the ability correctly to state (without delay) the day of the week of any date in the previous or next 10,000 years. I doubt whether they'd had the chance to memorise such a large number of calendars. Whatever the explanation, I don't think it's one of them having an eidetic memory, though some idiot savants do have this. I also don't think their ability was learned - the fact that they were identical twins being important here. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 10:30, 6 May 2004 (UTC)</p>
<dl>
<dd>Identical twins important? Did you forget to provide this <a href="../../../t/e/l/Telepathy.html" title="Telepathy">link</a>? My point being that even a cluster of computing machines is no more capable except in speed and memory capacity than any other computing machine. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 12:00, 6 May 2004 (UTC)</dd>
</dl>
<p>If you know all the prime numbers to 1000, say, then it is not super-humanly difficult to test numbers to 1000000 for primeness. Not magic. The calendars might have impressed Oliver Sacks the mystic, but it would not have impressed Oliver Sacks the mathematician. You only have to learn 14 calendars to know them all. The magic feat is simply one of dividing modulo 14 and applying an offset correction for Pope Gregory. I can tell you whether any number of any size is divisible by 11. But then I am not like you machines. I take Super Unleaded. <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 10:45, 6 May 2004 (UTC)</p>
<p>Perhaps I am digressing, but it occurs to me, from reading Sacks and others that part of our <i>normal</i> humanness consists of constraints (attenuators) on our consciousness. See <a href="../../../h/r/a/Hrair_limit.html" title="Hrair limit">hrair limit</a> (also relevant in the autistic savant context), and remember Sacks' example of the man who smelt like a dog (i.e he could smell water at a distance) temporarily after experimenting with drugs. I am primarily concerned here, though, with the example of primeness. It is not easy to test a number for primeness in your head, even with relatively small numbers. See <a href="http://primes.utm.edu/prove/" class="external free" title="http://primes.utm.edu/prove/" rel="nofollow">http://primes.utm.edu/prove/</a> for the known methods of proving primeness, and bear in mind that the twins couldn't do simple arithmetic. What I think they demonstrate is that there <i>was</i> some mysterious method of determining primeness (perhaps by means of some form of pattern matching and/or symbol manipulation) which was not learnt (the only reason why the twins are <i>important</i> is that they had the same genotype which gave them each the same mysterious capability) and was not explainable by them - they didn't know how they did it, i.e. they didn't do it by any known mathematical/algorithmic process, and it couldn't be fathomed by anyone else, and still can't, as far as I am aware. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 18:38, 6 May 2004 (UTC)</p>
<p><a name="Brain_size" id="Brain_size"></a></p>
<h3><span class="mw-headline">Brain size</span></h3>
<p>In terms of learning ability, I am reminded of Richard Feynman's calculation that if you were to encode alphabetic symbols at the atomic level, using 100 atoms per character, and build a block of material encoded in such a way, then the entire content of all the world's reference libraries could be stored in a piece of matter (I think he said metal, actually) as small as a grain of sand. I don't know what the volumetric storage requirements of biological memory are, but assuming they are not more than an order of magnitude different from Feynman's model, then one could theoretically perhaps store the entire contents of the Internet in a small corner of one's brain. What this makes me wonder is whether there might be some kind of critical mass of grey matter below which consciousness is impossible, and that therefore there are physical constraints on artificial implementations using current technology. If this could be demonstrated then one might come up with a calculation that one would need a disk platter as large as the rings of Saturn, or perhaps as large as the orbit of Pluto round the sun, to store enough data to make consciousness possible. How many neurons are there in a typical brain? I think we should be told. <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matt Stan</a> 18:38, 6 May 2004 (UTC)</p>
<p>The unit of biological memory has to be the <a href="../../../n/e/u/Neuron.html" title="Neuron">neuron</a> or the synapse because the reading and writing of material within the cell cannot be done in seconds. A neuron is huge when measured in numbers of atoms: 25 microns = 2.5*10^(-5)m. Feyman's info density packing will be based on the size of an atom: 2.5*10^(-11)m. 10^6 difference in linear dimension. But to your question: The volume of a <a href="../../../h/u/m/Human_brain.html" title="Human brain">human brain</a> is 1600cc or 1.6litres or 0.0016m^3. Linear dimension of a neuron is 2.5*10^(-5)m. Volume is 1.6*10^(-14)m^3. At maximum packing density there are 1.6*10^11 neurons in the brain. The <a href="../../../n/e/u/Neuron.html#Neurons_of_the_brain" title="Neuron">easy way</a> tells us 100bn neurons. 100*10^9 = 10^11. I was spot on: super unleaded! Is that 100Terabits = 10Terabytes? <a href="../../../p/s/b/User%7EPsb777_ac47.html" title="User:Psb777">Paul Beardsell</a> 23:45, 6 May 2004 (UTC)</p>

<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org../../../a/r/t/Talk%7EArtificial_consciousness_Archive_10_a489.html">http://en.wikipedia.org../../../a/r/t/Talk%7EArtificial_consciousness_Archive_10_a489.html</a>"</div>
	    <div id="catlinks"><p class='catlinks'><a href="../../../c/a/t/Special%7ECategories_101d.html" title="Special:Categories">Category</a>: <span dir='ltr'><a href="../../../t/a/l/Category%7ETalk_archives_8451.html" title="Category:Talk archives">Talk archives</a></span></p></div>	    <!-- end content -->
	    <div class="visualClear"></div>
	  </div>
	</div>
      </div>
      <div id="column-one">
	<div id="p-cactions" class="portlet">
	  <h5>Views</h5>
	  <ul>
	    <li id="ca-nstab-main"
	       	       ><a href="../../../a/r/t/Artificial_consciousness_Archive_10_2f59.html">Article</a></li><li id="ca-talk"
	       class="selected"	       ><a href="../../../a/r/t/Talk%7EArtificial_consciousness_Archive_10_a489.html">Discussion</a></li><li id="ca-current"
	       	       ><a href="http://en.wikipedia.org/wiki/Talk:Artificial_consciousness/Archive_10">Current revision</a></li>	  </ul>
	</div>
	<div class="portlet" id="p-logo">
	  <a style="background-image: url(../../../images/wiki-en.png);"
	    href="../../../index.html"
	    title="Main Page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
	  <h5>Navigation</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-Main-page"><a href="../../../index.html">Main page</a></li>
	     	      <li id="n-Contents"><a href="../../../c/o/n/Wikipedia%7EContents_3181.html">Contents</a></li>
	     	      <li id="n-Featured-content"><a href="../../../f/e/a/Wikipedia%7EFeatured_content_24ba.html">Featured content</a></li>
	     	      <li id="n-currentevents"><a href="../../../c/u/r/Portal%7ECurrent_events_bb60.html">Current events</a></li>
	     	    </ul>
	  </div>
	</div>
		<div class='portlet' id='p-interaction'>
	  <h5>interaction</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-About-Wikipedia"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html">About Wikipedia</a></li>
	     	      <li id="n-portal"><a href="../../../c/o/m/Wikipedia%7ECommunity_Portal_6a3c.html">Community portal</a></li>
	     	      <li id="n-contact"><a href="../../../c/o/n/Wikipedia%7EContact_us_afd6.html">Contact us</a></li>
	     	      <li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising">Make a donation</a></li>
	     	      <li id="n-help"><a href="../../../c/o/n/Help%7EContents_22de.html">Help</a></li>
	     	    </ul>
	  </div>
	</div>
		<div id="p-search" class="portlet">
	  <h5><label for="searchInput">Search</label></h5>
	  <div id="searchBody" class="pBody">
	    <form action="javascript:goToStatic(3)" id="searchform"><div>
	      <input id="searchInput" name="search" type="text"
	        accesskey="f" value="" />
	      <input type='submit' name="go" class="searchButton" id="searchGoButton"
	        value="Go" />
	    </div></form>
	  </div>
	</div>
	      </div><!-- end of the left (by default at least) column -->
      <div class="visualClear"></div>
      <div id="footer">
    <div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../../../skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>	<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="../../../images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>	<ul id="f-list">
	  	  	  <li id="f-credits">This page was last modified 21:05, 7 July 2006 by Wikipedia user <a href="../../../g/u/r/User%7EGurch_e84c.html" title="User:Gurch">Gurch</a>. Based on work by Wikipedia user(s) <a href="../../../m/a/t/User%7EMatthew_Stannard_9e17.html" title="User:Matthew Stannard">Matthew Stannard</a>.</li>	  <li id="f-copyright">All text is available under the terms of the <a class='internal' href="../../../t/e/x/Wikipedia%7EText_of_the_GNU_Free_Documentation_License_702a.html" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="../../../c/o/p/Wikipedia%7ECopyrights_92c4.html" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a US-registered <a class='internal' href="../../../5/0/1/501%28c%29.html#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="../../../n/o/n/Non-profit_organization.html" title="Non-profit organization">nonprofit</a> <a href="../../../c/h/a/Charitable_organization.html" title="Charitable organization">charity</a>.<br /></li>	  <li id="f-about"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html" title="Wikipedia:About">About Wikipedia</a></li>	  <li id="f-disclaimer"><a href="../../../g/e/n/Wikipedia%7EGeneral_disclaimer_3e44.html" title="Wikipedia:General disclaimer">Disclaimers</a></li>	  	</ul>
      </div>
    </div>
  </body>
</html>
