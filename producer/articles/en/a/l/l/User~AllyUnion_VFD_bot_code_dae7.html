<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    		<meta name="keywords" content="User:AllyUnion/VFD bot code,Creative Commons,GNU Free Documentation License,AllyUnion,VFD Bot,AllyUnion" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="../../../COPYING.html" />
    <title>User:AllyUnion/VFD bot code - Wikipedia, the free encyclopedia</title>
    <style type="text/css">/*<![CDATA[*/ @import "../../../skins/htmldump/main.css"; /*]]>*/</style>
    <link rel="stylesheet" type="text/css" media="print" href="../../../skins/common/commonPrint.css" />
    <!--[if lt IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE50Fixes.css";</style><![endif]-->
    <!--[if IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE55Fixes.css";</style><![endif]-->
    <!--[if IE 6]><style type="text/css">@import "../../../skins/monobook/IE60Fixes.css";</style><![endif]-->
    <!--[if IE]><script type="text/javascript" src="../../../skins/common/IEFixes.js"></script>
    <meta http-equiv="imagetoolbar" content="no" /><![endif]-->
    <script type="text/javascript" src="../../../skins/common/wikibits.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/md5.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/utf8.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/lookup.js"></script>
    <script type="text/javascript" src="../../../raw/gen.js"></script>        <style type="text/css">/*<![CDATA[*/
@import "../../../raw/MediaWiki%7ECommon.css";
@import "../../../raw/MediaWiki%7EMonobook.css";
@import "../../../raw/gen.css";
/*]]>*/</style>          </head>
  <body
    class="ns-2">
    <div id="globalWrapper">
      <div id="column-content">
	<div id="content">
	  <a name="top" id="contentTop"></a>
	        <h1 class="firstHeading">User:AllyUnion/VFD bot code</h1>
	  <div id="bodyContent">
	    <h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
	    <div id="contentSub"><span class="subpages">&lt; <a href="../../../a/l/l/User%7EAllyUnion_7163.html" title="User:AllyUnion">User:AllyUnion</a></span></div>
	    	    	    <!-- start content -->
	    <p>These are a copy all the files that are run for <a href="../../../v/f/d/User%7EVFD_Bot_4e8f.html" title="User:VFD Bot">User:VFD Bot</a>. This page and its contents are copyrighted under the <a href="../../../c/r/e/Creative_Commons_95b5.html" title="Creative Commons">Creative Commons</a> Attribution ShareAlike 1.0 License: <a href="http://creativecommons.org/licenses/by-sa/1.0/" class="external free" title="http://creativecommons.org/licenses/by-sa/1.0/" rel="nofollow">http://creativecommons.org/licenses/by-sa/1.0/</a>. The information here is not licensed by <a href="../../../g/n/u/GNU_Free_Documentation_License_9d01.html" title="GNU Free Documentation License">GNU Free Documentation License</a>. The purpose of hosting this code is to allow the public viewing of the code being run on the Wikipedia. -- <a href="../../../a/l/l/User%7EAllyUnion_7163.html" title="User:AllyUnion">AllyUnion</a> <a href="../../../a/l/l/User_talk%7EAllyUnion_d722.html" title="User talk:AllyUnion">(talk)</a> 23:06, 7 Apr 2005 (UTC)</p>
<ul>
<li>Should I happen to leave the Wikipedia or I am unable to continue run <a href="../../../v/f/d/User%7EVFD_Bot_4e8f.html" title="User:VFD Bot">User:VFD Bot</a>, I politely ask that you email me before using my code. -- <a href="../../../a/l/l/User%7EAllyUnion_7163.html" title="User:AllyUnion">AllyUnion</a> <a href="../../../a/l/l/User_talk%7EAllyUnion_d722.html" title="User talk:AllyUnion">(talk)</a> 23:08, 7 Apr 2005 (UTC)</li>
</ul>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#en-wp-vfd-list.py"><span class="tocnumber">1</span> <span class="toctext">en-wp-vfd-list.py</span></a></li>
<li class="toclevel-1"><a href="#en-wp-vfd-list-fix.py"><span class="tocnumber">2</span> <span class="toctext">en-wp-vfd-list-fix.py</span></a></li>
<li class="toclevel-1"><a href="#en-wp-vfd-old-update.py"><span class="tocnumber">3</span> <span class="toctext">en-wp-vfd-old-update.py</span></a></li>
<li class="toclevel-1"><a href="#en-wp-vfd-yesterday.py"><span class="tocnumber">4</span> <span class="toctext">en-wp-vfd-yesterday.py</span></a></li>
<li class="toclevel-1"><a href="#en-wp-vfd-newday.py"><span class="tocnumber">5</span> <span class="toctext">en-wp-vfd-newday.py</span></a></li>
<li class="toclevel-1"><a href="#en-wp-vfd-update2.py"><span class="tocnumber">6</span> <span class="toctext">en-wp-vfd-update2.py</span></a></li>
<li class="toclevel-1"><a href="#en-wp-vfd-update3.py"><span class="tocnumber">7</span> <span class="toctext">en-wp-vfd-update3.py</span></a></li>
</ul>
</td>
</tr>
</table>
<p><script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script><a name="en-wp-vfd-list.py" id="en-wp-vfd-list.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-list.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-list.py</span></h2>
<pre>
#!/usr/bin/python2.3
# Author: Jason Y. Lee (AllyUnion)
# Purpose: Automatically update a VFD List on User:AllyUnion/VFD List
#          every hour.  Keeps 7 days, presumes for exactly 7 sections
#          on specified page.  (Seven days, seven sections)
#          To be run by a cron job.
#          Also removes the top section once the next UTC day comes

# Revision 3.07

import wikipedia, config
import os
import commands
import sys
import datetime

if __name__ == "__main__":
        utc = datetime.datetime.utcnow()
        # Get the dates
#       yyyy = int(datetime.datetime.utcnow().strftime('%Y'))
#       mm = int(datetime.datetime.utcnow().strftime('%m'))
#       dd = int(datetime.datetime.utcnow().strftime('%d'))

        # Today's date, exactly at 0000 hours
#       today = datetime.datetime(yyyy, mm, dd, 0, 0, 0, 0)
        today = utc.replace(hour=0,minute=0,second=0,microsecond=0)

        # Today's date, exactly at 1000 hours
#       onehour = datetime.datetime(yyyy, mm, dd, 1, 0, 0, 0)
        onehour = utc.replace(hour=1,minute=0,second=0,microsecond=0)

        # Tomorrow's date, exactly at 0000 hours
        tomorrow = today + datetime.timedelta(1)

        # Yesterday's date, exactly at 0000 hours
        yesterday = today - datetime.timedelta(1)

        # Seven days prior to today's date at 0000 hours
        sevendaysago = today - datetime.timedelta(7)

        # Check the time now
        utctime = datetime.datetime.utcnow()# - datetime.timedelta(0, 14400)

        # Wikipedia Variable Setup
        # VFD Page log name
        vfdlog = "Wikipedia:Votes_for_deletion/Log/"
        # Which site, as specified in user-config.py
        mysite = wikipedia.getSite()

        # Page: User:AllyUnion/VFD List and sections
        oldvpage = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List', True, True, False)
        section1 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=1', True, True, False)
        section2 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=2', True, True, False)
        section3 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=3', True, True, False)
        section4 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=4', True, True, False)
        section5 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=5', True, True, False)
        section6 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=6', True, True, False)
        section7 = wikipedia.getPage(mysite, 'User:AllyUnion/VFD List&amp;section=7', True, True, False)

        # Top heading
        notice = str('This is a list of [[Wikipedia:Votes for deletion|VFD discussions]], updated hourly.&lt;br/&gt;\n&lt;!-- Please do not add your own VFD sections to this page.  It is not necessary. --&gt;\n').encode('iso-8859-1')

        comment = 'Hourly Automatic Update of VFD List: '

        # Newline
        newline = '\n'

        # Temporary Log File
        logfile = 'tmp/vfd.log'

        # Temporary Old Log File
        difffile = 'tmp/diff-vfd.log'

        # Temporary Parse File
        parsefile = 'tmp/vfd-parse.log'

        # Temporary Yesterday Parse File
        yparsefile = 'tmp/vfd-yparse.log'

        # Grep command
        grepcmd = ' | grep -v \'&lt;!-- New votes to the bottom, please. --&gt;\''

        # Perl command to parse file
        perlcmd = ' | perl -pi -e \'s/{{/\* [[/g\' | perl -pi -e \'s/}}/]]/g\''

        # Diff command
        diffcmd = 'diff -u ' + difffile + ' ' + logfile + ' | grep ^+ | grep \'* \[\[\' | perl -pi -e \'s/\*.\[\[Wikipedia:Votes.for.deletion\// /g\' | perl -pi -e \'s/\]\]//g\''

        diffcmd2 = 'diff -u ' + difffile + ' ' + logfile + ' | grep ^- | grep \'* \[\[\'| perl -pi -e \'s/\*.\[\[Wikipedia:Votes.for.deletion\// /g\' | perl -pi -e \'s/\]\]//g\''

        # Login file, full path and filename
#       loginfile = 'pywikipediabot/login.py'

        log = file(difffile, 'w')
        log.write(oldvpage.encode('iso-8859-1'))
        log.close()

        # today &lt;= utctime &lt;= onehour
        if (today &lt;= utctime &lt;= onehour):
                print 'Operation: Remove top, add new day'
                # Perform top removal procedure
                # Get yesterday's VFD and convert
                # Get today's VFD and convert
                # Replace sections 6 and 7

                # Open log for writing
                log = file(logfile, 'w')

                # Write notice
                log.write(notice.encode('iso-8859-1'))

                # Plus newline
                log.write(newline.encode('iso-8859-1'))

                # Write sections 2, 3, 4, 5, 6 with a newline between each one
                # Since, we removed section 1, sections 2-6 become our new sections 1-5
                log.write(section2.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section3.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section4.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section5.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section6.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Get the VFD page from yesterday
                vfdpage = vfdlog + str(yesterday.strftime('%Y_%B_')) + str(int(yesterday.strftime('%d')))
                toparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

                # Write the VFD yesterday to a temporary parse log
                parselog = file(yparsefile, 'w')
                parselog.write(toparse.encode('iso-8859-1'))
                parselog.close()

                # Yesterday's VFD, parsed into a list
                yparsecmd = 'cat ' + yparsefile + grepcmd + perlcmd
                yparsed = commands.getoutput(yparsecmd)
                yparsed = yparsed.decode('iso-8859-1')

                # Link to VFD page
                # Long Date: example: 2005_January_1
                ydate1 = yesterday.strftime('%Y_%B_') + str(int(yesterday.strftime('%d')))

                # Short Date: example: January 1
                ydate2 = yesterday.strftime('%B') + ' ' + str(int(yesterday.strftime('%d')))

                # Give the page name
                yfind1 = '[[Wikipedia:Votes for deletion/Log/' + ydate1 + '|' + ydate2 + ']]'
                yfind2 = '[[Wikipedia:Votes for deletion/Log/' + ydate1 + '|[[Wikipedia:Votes for deletion/Log/' + ydate1 + '|' + ydate2 + ']]]]'

                # Section space remove
                yparsed = yparsed.replace('== ', '==')
                yparsed = yparsed.replace(' ==', '==')

                # First, replace it once, so a link is established
                yparsed = yparsed.replace('==' + ydate2 + '==', '==' + yfind1 + '==', 1)

                # Second, if it has been done before, this will fix (hopefully), the internal link to the proper form
                yparsed = yparsed.replace(yfind2, yfind1, 1)

                yplines = yparsed.splitlines();
                ypnum = yplines.index('==' + yfind1 + '==')

                log.write(yplines[ypnum].encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                for x in range(ypnum-1):
                        log.write(yplines[x].encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))

                for x in range(len(yplines) - ypnum - 1):
                        x = x + ypnum + 1
                        log.write(yplines[x].encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))

                # Write yesterday's stuff to the log
#               log.write(yparsed.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Get the VFD page for today
                vfdpage = vfdlog + str(today.strftime('%Y_%B_')) + str(int(today.strftime('%d')))
                toparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

                # Write the VFD page for today to a temporary parse log
                parselog = file(parsefile, 'w')
                parselog.write(toparse.encode('iso-8859-1'))
                parselog.close()

                # Today's VFD, parsed into a list
                parsecmd = 'cat ' + parsefile + grepcmd + perlcmd
                parsed = commands.getoutput(parsecmd)
                parsed = parsed.decode('iso-8859-1')

                # Link to VFD page

                # Long Date: example: 2005_January_1
                date1 = today.strftime('%Y_%B_') + str(int(today.strftime('%d')))

                # Short Date: example: January 1
                date2 = today.strftime('%B') + ' ' + str(int(today.strftime('%d')))

                # Give the page name
                find1 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]'
                find2 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]]]'

                # Section space remove
                parsed = parsed.replace('== ', '==')
                parsed = parsed.replace(' ==', '==')

                # First, replace it once, so a link is established
                parsed = parsed.replace('==' + date2 + '==', '==' + find1 + '==', 1)

                # Second, if it has been done before, this will fix (hopefully), the internal link to the proper form
                parsed = parsed.replace(find2, find1, 1)

                plines = parsed.splitlines();
                pnum = plines.index('==' + find1 + '==')

                log.write(plines[pnum].encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                for x in range(pnum-1):
                        log.write(plines[x].encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))

                for x in range(len(plines) - pnum - 1):
                        x = x + pnum + 1
                        log.write(plines[x].encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))

                # Write today's stuff to the log
#               log.write(parsed.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Close the file, making sure all the contents are written to the log
                log.close()

                # User:Mozzerati Feature request
                diffcomment = commands.getoutput(diffcmd)
                diffcomment = diffcomment.decode('iso-8859-1')
                difflist = diffcomment.splitlines()

                diffcomment2 = commands.getoutput(diffcmd2)
                diffcomment2 = diffcomment2.decode('iso-8859-1')
                difflist2 = diffcomment2.splitlines()

                for check in difflist:
                        for checking in difflist2:
                                if (checking[1:] == check[1:]):
                                        difflist.remove(check)
                for x in range(len(difflist) - 1):
                        comment += difflist[x] + ', '
                comment += difflist[x+1] + '.'
#               for check in difflist:
#                       comment += check + ', '
#               comment[-2:] = '.'

                # Reopen the log file           
                log = file(logfile, 'r')

                # Read the whole log into a variable
                post = log.read()

                # Close log file
                log.close()

                # Log in to Wikipedia
#               cmd = 'python2.3 ' + loginfile
#               os.system(cmd)

                page = wikipedia.PageLink(mysite, 'User:AllyUnion/VFD List')
                # Post to the Wikipedia
                page.put(post, comment)

                cmd = 'rm -f ' + logfile + ' ' + parsefile + ' ' + yparsefile + ' ' + difffile
                os.system(cmd)

        # onehour &lt; utctime &lt;= tomorrow
        elif (onehour &lt; utctime &lt;= tomorrow):
                print 'Operation: Normal - Update last section'
                # Get today's VFD and convert
                # Replace section 7

                # Open log for writing
                log = file(logfile, 'w')

                # Write notice
                log.write(notice.encode('iso-8859-1'))

                # Plus newline
                log.write(newline.encode('iso-8859-1'))

                # Write sections 1, 2, 3, 4, 5, 6 with a newline between each one
                log.write(section1.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section2.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section3.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section4.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section5.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))
                log.write(section6.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Get the VFD page for today
                vfdpage = vfdlog + str(today.strftime('%Y_%B_')) + str(int(today.strftime('%d')))
                toparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

                # Write the VFD page for today to a temporary parse log
                parselog = file(parsefile, 'w')
                parselog.write(toparse.encode('iso-8859-1'))
                parselog.close()

                # Today's VFD, parsed into a list
                parsecmd = 'cat ' + parsefile + grepcmd + perlcmd
                parsed = commands.getoutput(parsecmd)
                parsed = parsed.decode('iso-8859-1')

                # Link to VFD page

                # Long Date: example: 2005_January_1
                date1 = today.strftime('%Y_%B_') + str(int(today.strftime('%d')))

                # Short Date: example: January 1
                date2 = today.strftime('%B') + ' ' + str(int(today.strftime('%d')))

                # Give the page name
                find1 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]'
                find2 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]]]'

                # Section space remove
                parsed = parsed.replace('== ', '==')
                parsed = parsed.replace(' ==', '==')
                
                # First, replace it once, so a link is established
                parsed = parsed.replace('==' + date2 + '==', '==' + find1 + '==', 1)

                # Second, if it has been done before, this will fix (hopefully), the internal link to the proper form
                parsed = parsed.replace(find2, find1, 1)

                plines = parsed.splitlines();
                pnum = plines.index('==' + find1 + '==')

                log.write(plines[pnum].encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                for x in range(pnum-1):
                        log.write(plines[x].encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))

                for x in range(len(plines) - pnum - 1):
                        x = x + pnum + 1
                        log.write(plines[x].encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))

                # Write today's stuff to the log
#               log.write(parsed.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Close the file, making sure all the contents are written to the log
                log.close()

                # User:Mozzerati Feature request
                diffcomment = commands.getoutput(diffcmd)
                diffcomment = diffcomment.decode('iso-8859-1')
                difflist = diffcomment.splitlines()

                diffcomment2 = commands.getoutput(diffcmd2)
                diffcomment2 = diffcomment2.decode('iso-8859-1')
                difflist2 = diffcomment2.splitlines()

                for check in difflist:
                        for checking in difflist2:
                                if (checking[1:] == check[1:]):
                                        difflist.remove(check)
                for x in range(len(difflist) - 1):
                        comment += difflist[x] + ', '
                comment += difflist[x+1] + '.'
#               comment[-2:] = '.'

                # Reopen the log file           
                log = file(logfile, 'r')

                # Read the whole log into a variable
                post = log.read()

                # Close log file
                log.close()

                # Log in to Wikipedia
#               cmd = 'python2.3 ' + loginfile
#               os.system(cmd)

                page = wikipedia.PageLink(mysite, 'User:AllyUnion/VFD List')
                # Post to the Wikipedia
                page.put(post, comment)

                cmd = 'rm -f ' + logfile + ' ' + parsefile + ' ' + difffile
                os.system(cmd)


        # Possibility is that utctime == tomorrow, but should never happen
        else:
                sys.exit(1)

sys.exit(0)
</pre>
<p><a name="en-wp-vfd-list-fix.py" id="en-wp-vfd-list-fix.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-list-fix.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-list-fix.py</span></h2>
<pre>
#!/usr/bin/python2.3
# Author: Jason Y. Lee (AllyUnion)
# Purpose: Automatically update a VFD List on User:AllyUnion/VFD List
#          every hour.  Keeps 7 days, presumes for exactly 7 sections
#          on specified page.  (Seven days, seven sections)
#          To be run by a cron job.
#          Also removes the top section once the next UTC day comes

import wikipedia, config
import os
import commands
import sys
import datetime

def vfdsection(vfddate):
        vfdslogfile = 'tmp/vfdsection.log'
        # Grep command
        # VFD Page log name
        vfdlog = "Wikipedia:Votes_for_deletion/Log/"
        # Which site, as specified in user-config.py
        mysite = wikipedia.getSite()

        # Grep command to parse file
        grepcmd = ' | grep -v \'&lt;!-- New votes to the bottom, please. --&gt;\''

        # Perl command to parse file
        perlcmd = ' | perl -pi -e \'s/{{/\* [[/g\' | perl -pi -e \'s/}}/]]/g\''

        vfdpage = vfdlog + str(vfddate.strftime('%Y_%B_')) + str(int(vfddate.strftime('%d')))

        fixparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

        vfdslog = file(vfdslogfile, 'w')
        vfdslog.write(fixparse.encode('iso-8859-1'))
        vfdslog.close()

        vfdscmd = 'cat ' + vfdslogfile + grepcmd + perlcmd
        vfdsparsed = commands.getoutput(vfdscmd)
        vfdsparsed = vfdsparsed.decode('iso-8859-1')

        os.system('rm -f ' + vfdslogfile)

        vdate1 = vfddate.strftime('%Y_%B_') + str(int(vfddate.strftime('%d')))
        vdate2 = vfddate.strftime('%B') + ' ' + str(int(vfddate.strftime('%d')))
        vfind1 = '[[Wikipedia:Votes for deletion/Log/' + vdate1 + '|' + vdate2 + ']]'
        vfind2 = '[[Wikipedia:Votes for deletion/Log/' + vdate1 + '|[[Wikipedia:Votes for deletion/Log/' + vdate1 + '|' + vdate2 + ']]]]'
        vfdsparsed = vfdsparsed.replace(vdate2, vfind1, 1)
        vfdsparsed = vfdsparsed.replace(vfind2, vfind1, 1)

        return vfdsparsed

if __name__ == "__main__":
        # Get the dates
        utc = datetime.datetime.utcnow()
#       yyyy = int(datetime.datetime.utcnow().strftime('%Y'))
#       mm = int(datetime.datetime.utcnow().strftime('%m'))
#       dd = int(datetime.datetime.utcnow().strftime('%d'))

        # Today's date, exactly at 0000 hours
        today = utc.replace(hour=0,minute=0,second=0,microsecond=0)

        # Today's date, exactly at 1000 hours
#       onehour = datetime.datetime(yyyy, mm, dd, 1, 0, 0, 0)
        onehour = utc.replace(hour=1,minute=0,second=0,microsecond=0)

        # Tomorrow's date, exactly at 0000 hours
        tomorrow = today + datetime.timedelta(1)

        # Yesterday's date, exactly at 0000 hours
        yesterday = today - datetime.timedelta(1)

        # Seven days prior to today's date at 0000 hours
        sevendaysago = today - datetime.timedelta(6)

        # Check the time now
        utctime = datetime.datetime.utcnow()

        # Wikipedia Variable Setup
        # VFD Page log name
        vfdlog = "Wikipedia:Votes_for_deletion/Log/"
        # Which site, as specified in user-config.py
        mysite = wikipedia.getSite()

        # Page: User:AllyUnion/VFD List and sections
#       page = wikipedia.PageLink(mysite, 'User:AllyUnion/VFD List')

        # Top heading
        notice = str('This is a list of [[Wikipedia:Votes for deletion|VFD discussions]], updated hourly.&lt;br/&gt;\n&lt;!-- Please do not add your own VFD sections to this page.  It is not necessary. --&gt;\n').encode('iso-8859-1')

        # Newline
        newline = '\n'

        # Temporary Log File
        logfile = 'tmp/vfd.log'

        # Temporary Parse File
        parsefile = 'tmp/vfd-parse.log'

        # Temporary Yesterday Parse File
        yparsefile = 'tmp/vfd-yparse.log'

        # Grep command
        grepcmd = ' | grep -v \'&lt;!-- New votes to the bottom, please. --&gt;\''

        # Perl command to parse file
        perlcmd = ' | perl -pi -e \'s/{{/\* [[/g\' | perl -pi -e \'s/}}/]]/g\''

        # Login file, full path and filename
        loginfile = 'pywikipediabot/login.py'

        # today &lt;= utctime &lt;= onehour
        if (today &lt;= utctime &lt;= onehour):
                # Perform top removal procedure
                # Get yesterday's VFD and convert
                # Get today's VFD and convert
                # Replace sections 6 and 7

                # Open log for writing
                log = file(logfile, 'w')

                # Write notice
                log.write(notice.encode('iso-8859-1'))

                # Plus newline
                log.write(newline.encode('iso-8859-1'))

                # Write sections 2, 3, 4, 5, 6 with a newline between each one
                # Since, we removed section 1, sections 2-6 become our new sections 1-5
                datecounter = sevendaysago + datetime.timedelta(2)
                while datecounter &lt; yesterday:
                        fixsection = vfdsection(datecounter)
                        log.write(fixsection.encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))
                        datecounter = datecounter + datetime.timedelta(1)

                # Get the VFD page from yesterday
                vfdpage = vfdlog + str(yesterday.strftime('%Y_%B_')) + str(int(yesterday.strftime('%d')))
                toparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

                # Write the VFD yesterday to a temporary parse log
                parselog = file(yparsefile, 'w')
                parselog.write(toparse.encode('iso-8859-1'))
                parselog.close()

                # Yesterday's VFD, parsed into a list
                yparsecmd = 'cat ' + yparsefile + grepcmd + perlcmd
                yparsed = commands.getoutput(yparsecmd)
                yparsed = yparsed.decode('iso-8859-1')

                # Link to VFD page
                # Long Date: example: 2005_January_1
                ydate1 = yesterday.strftime('%Y_%B_') + str(int(yesterday.strftime('%d')))

                # Short Date: example: January 1
                ydate2 = yesterday.strftime('%B') + ' ' + str(int(yesterday.strftime('%d')))

                # Give the page name
                yfind1 = '[[Wikipedia:Votes for deletion/Log/' + ydate1 + '|' + ydate2 + ']]'
                yfind2 = '[[Wikipedia:Votes for deletion/Log/' + ydate1 + '|[[Wikipedia:Votes for deletion/Log/' + ydate1 + '|' + ydate2 + ']]]]'

                # Section space remove
                yparsed = yparsed.replace('== ', '==')
                yparsed = yparsed.replace(' ==', '==')

                # First, replace it once, so a link is established
                yparsed = yparsed.replace(ydate2, yfind1, 1)

                # Second, if it has been done before, this will fix (hopefully), the internal link to the proper form
                yparsed = yparsed.replace(yfind2, yfind1, 1)

                # Write yesterday's stuff to the log
                log.write(yparsed.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Get the VFD page for today
                vfdpage = vfdlog + str(today.strftime('%Y_%B_')) + str(int(today.strftime('%d')))
                toparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

                # Write the VFD page for today to a temporary parse log
                parselog = file(parsefile, 'w')
                parselog.write(toparse.encode('iso-8859-1'))
                parselog.close()

                # Today's VFD, parsed into a list
                parsecmd = 'cat ' + parsefile + grepcmd + perlcmd
                parsed = commands.getoutput(parsecmd)
                parsed = parsed.decode('iso-8859-1')

                # Link to VFD page

                # Long Date: example: 2005_January_1
                date1 = today.strftime('%Y_%B_') + str(int(today.strftime('%d')))

                # Short Date: example: January 1
                date2 = today.strftime('%B') + ' ' + str(int(today.strftime('%d')))

                # Give the page name
                find1 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]'
                find2 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]]]'

                # Section space remove
                parsed = parsed.replace('== ', '==')
                parsed = parsed.replace(' ==', '==')

                # First, replace it once, so a link is established
                parsed = parsed.replace(date2, find1, 1)

                # Second, if it has been done before, this will fix (hopefully), the internal link to the proper form
                parsed = parsed.replace(find2, find1, 1)

                # Write today's stuff to the log
                log.write(parsed.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Close the file, making sure all the contents are written to the log
                log.close()

                # Reopen the log file           
                log = file(logfile, 'r')

                # Read the whole log into a variable
                post = log.read()

                # Close log file
                log.close()

                # Log in to Wikipedia
#               cmd = 'python2.3 ' + loginfile
#               os.system(cmd)

                page = wikipedia.PageLink(mysite, 'User:AllyUnion/VFD List')
                # Post to the Wikipedia
                page.put(post, 'Fixing VFD List...')

                cmd = 'rm -f ' + logfile + ' ' + parsefile + ' ' + yparsefile
                os.system(cmd)

        # onehour &lt; utctime &lt;= tomorrow
        elif (onehour &lt; utctime &lt; tomorrow):
                # Get today's VFD and convert
                # Replace section 7

                # Open log for writing
                log = file(logfile, 'w')

                # Write notice
                log.write(notice.encode('iso-8859-1'))

                # Plus newline
                log.write(newline.encode('iso-8859-1'))

                # Write sections 1, 2, 3, 4, 5, 6 with a newline between each one
                datecounter = sevendaysago# - datetime.timedelta(1)
                while datecounter &lt; today:
                        fixsection = vfdsection(datecounter)
                        log.write(fixsection.encode('iso-8859-1'))
                        log.write(newline.encode('iso-8859-1'))
                        datecounter = datecounter + datetime.timedelta(1)

                # Get the VFD page for today
                vfdpage = vfdlog + str(today.strftime('%Y_%B_')) + str(int(today.strftime('%d')))
                toparse = wikipedia.getPage(mysite, vfdpage, True, True, False)

                # Write the VFD page for today to a temporary parse log
                parselog = file(parsefile, 'w')
                parselog.write(toparse.encode('iso-8859-1'))
                parselog.close()

                # Today's VFD, parsed into a list
                parsecmd = 'cat ' + parsefile + grepcmd + perlcmd
                parsed = commands.getoutput(parsecmd)
                parsed = parsed.decode('iso-8859-1')

                # Link to VFD page

                # Long Date: example: 2005_January_1
                date1 = today.strftime('%Y_%B_') + str(int(today.strftime('%d')))

                # Short Date: example: January 1
                date2 = today.strftime('%B') + ' ' + str(int(today.strftime('%d')))

                # Give the page name
                find1 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]'
                find2 = '[[Wikipedia:Votes for deletion/Log/' + date1 + '|[[Wikipedia:Votes for deletion/Log/' + date1 + '|' + date2 + ']]]]'

                # Section space remove
                parsed = parsed.replace('== ', '==')
                parsed = parsed.replace(' ==', '==')

                # First, replace it once, so a link is established
                parsed = parsed.replace(date2, find1, 1)

                # Second, if it has been done before, this will fix (hopefully), the internal link to the proper form
                parsed = parsed.replace(find2, find1, 1)

                # Write today's stuff to the log
                log.write(parsed.encode('iso-8859-1'))
                log.write(newline.encode('iso-8859-1'))

                # Close the file, making sure all the contents are written to the log
                log.close()

                # Reopen the log file           
                log = file(logfile, 'r')

                # Read the whole log into a variable
                post = log.read()

                # Close log file
                log.close()

                # Log in to Wikipedia
#               cmd = 'python2.3 ' + loginfile
#               os.system(cmd)

                page = wikipedia.PageLink(mysite, 'User:AllyUnion/VFD List')
                # Post to the Wikipedia
                page.put(post, 'Fixing VFD List...')

                cmd = 'rm -f ' + logfile + ' ' + parsefile
                os.system(cmd)


        # Possibility is that utctime == tomorrow, but should never happen
        else:
                sys.exit(1)

sys.exit(0)
</pre>
<p><a name="en-wp-vfd-old-update.py" id="en-wp-vfd-old-update.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-old-update.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-old-update.py</span></h2>
<pre>
#!/usr/bin/python2.3
# -*- coding: utf-8 -*-

import os, sys
if (not (sys.path[0] == '')):
        os.chdir(sys.path[0])

# Automatic VFD Update script
# Written by Jason Y. Lee (AllyUnion)
# Assumes to be run by a cron job, 10 minutes prior to the next 00:00 UTC.
# Rewritten for any time zone, so it can be run hourly if anyone wishes.

# Author's note:
# Yes, I do realize I can make an array for all the variables below
# but I rather have everything clearly spelled out just to make absolutely
# certain that whatever error is going on can be clearly seen

#import wikiipedia, config
import datetime

if __name__ == "__main__":
        utc = datetime.datetime.utcnow()# - datetime.timedelta(1)
        if (not (utc.replace(hour=23,minute=0,second=0,microsecond=0) &lt;= utc &lt;= (utc.replace(hour=0,minute=0,second=0,microsecond=0) + datetime.timedelta(1)))):
                sys.exit(1)

        # Get today's date:
#       yyyy = int(datetime.datetime.utcnow().strftime('%Y'))
#       mm = int(datetime.datetime.utcnow().strftime('%m'))
#       dd = int(datetime.datetime.utcnow().strftime('%d'))

        import wikipedia, config

        # Today's date, exactly at 0000 hours
        # Required as a point of reference
#       today = datetime.datetime(yyyy, mm, dd, 0, 0, 0, 0)
        today = utc.replace(hour=0,minute=0,second=0,microsecond=0)

        tag = '&lt;!-- Place latest vote day above - Do not remove this line --&gt;'

        # Five days prior to today's date at 0000 hours
        # The day that will be moved to Old
        fivedaysago = today - datetime.timedelta(5)

        # Six days prior to today's date at 0000 hours
        # The day which we need to search for
#       sixdaysago = today - datetime.timedelta(6)

        # Today's transinclude
#       today_vfdtag = '* [[Wikipedia:Votes for deletion/Log/' + today.strftime('%Y %B ') + str(int(today.strftime('%d'))) + ']]'

        # Five days ago (transinclude)
        fivedaysago_vfdtag = '* [[Wikipedia:Votes for deletion/Log/' + fivedaysago.strftime('%Y %B ') + str(int(fivedaysago.strftime('%d'))) + ']]'

        # Six days ago (transinclude)
#       sixdaysago_vfdtag = '* [[Wikipedia:Votes for deletion/Log/' + sixdaysago.strftime('%Y %B ') + str(int(sixdaysago.strftime('%d'))) + ']]'

#       print today_vfdtag
#       print fivedaysago_vfdtag
#       print sixdaysago_vfdtag

#       import sys
#       sys.exit(0)

        # Site configured in user-config.py
        mysite = wikipedia.getSite()

        # Get vfd pages
        vfdold = wikipedia.Page(mysite, 'Wikipedia:Votes_for_deletion/Old').get(False, True)

        # Search and replace

        # Transinclude on VFD Old
        # Replace six days ago transinclude with six days ago transinclude + '\n' + five days ago transinclude (once)
        if (vfdold.find(fivedaysago_vfdtag) == -1):
                vfdold = vfdold.replace(tag, fivedaysago_vfdtag + '\n' + tag, 1)

        # Page links
                vfdoldpage = wikipedia.Page(mysite, 'Wikipedia:Votes for deletion/Old')

                vfdoldpage.put(vfdold, '[[User:VFD Bot|VFD Bot]] ([[User talk:AllyUnion|talk]]) ([[Special:Contributions/VFD Bot|contributions]]): Auto-update of VFD Old - Bot work')
</pre>
<p><a name="en-wp-vfd-yesterday.py" id="en-wp-vfd-yesterday.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-yesterday.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-yesterday.py</span></h2>
<pre>
#!/usr/bin/python2.3
# -*- coding: utf-8 -*-

import os, sys
if (not (sys.path[0] == '')):
        os.chdir(sys.path[0])

# Will only run between 00:00 UTC and 01:00 UTC.

import datetime

if __name__ == "__main__":
        utc = datetime.datetime.utcnow()
#       if (not (utc.replace(hour=0,minute=0,second=0,microsecond=0) &lt;= utc &lt;= utc.replace(hour=1,minute=0,second=0,microsecond=0))):
#               sys.exit()

        import wikipedia, config

        page = 'Wikipedia:Votes for deletion/Log/Yesterday'
        yesterday = utc.replace(hour=0,minute=0,second=0,microsecond=0) - datetime.timedelta(1)

        header = u''
        header += '{{Shortcut|[[WP:VFD/Yesterday]]}}\n'
        header += '{{VfD header}}\n'
        header += '{{deletiontools}}\n'
        header += '&lt;div align="center"&gt;&lt;small&gt;\'\'\'[{{SERVER}}{{localurl:{{NAMESPACE}}:{{PAGENAMEE}}|action=purge}} Purge page cache] if page isn\'t updating.\'\'\'&lt;/small&gt;&lt;/div&gt;\n'
        header += '&lt;!-- Do not edit this page!!! This page is automatically updated by a bot.  VFD entries DO NOT GO ON THIS PAGE.  The bot will forcibly update the page daily, removing any changes added by a user.  Should you wish any of the text change, please alert User:AllyUnion. --&gt;\n'
        header += '\n'

        transinclude = u'{{' + 'Wikipedia:Votes for deletion/Log/' + yesterday.strftime('%Y %B ') + str(int(yesterday.strftime('%d'))) + '}}'

        footer = u''
        footer += '\n&lt;!-- Do not edit this page!!! This page is automatically updated by a bot.  VFD entries DO NOT GO ON THIS PAGE.  The bot will forcibly update the page daily, removing any changes added by a user.  Should you wish any of the text change, please alert User:AllyUnion. --&gt;\n'
        footer += '\n'
        footer += '== VfD footer ==\n'
        footer += '&lt;!-- Do not edit this page!!! This page is automatically updated by a bot.  VFD entries DO NOT GO ON THIS PAGE.  The bot will forcibly update the page daily, removing any changes added by a user.  Should you wish any of the text change, please alert User:AllyUnion. --&gt;\n'
        footer += '\n'
        footer += '{{VfDFooter}}\n'
        footer += '\n'
        footer += '&lt;!-- Categories and interwiki links --&gt;\n'
        footer += '[[Category:Wikipedia deletion|Votes for deletion]]\n'
        footer += '\n'
        footer += '[[ar:ويكيبيديا:تصويت للحذف]]\n'
        footer += '[[bg:Уикипедия:Страници за изтриване]]\n'
        footer += '[[cs:Wikipedie:Hlasov%C3%A1n%C3%AD_o_smaz%C3%A1n%C3%AD]]\n'
        footer += '[[da:Wikipedia:Sider_der_b%C3%B8r_slettes]]\n'
        footer += '[[de:Wikipedia:L%C3%B6schkandidaten]]\n'
        footer += '[[es:Wikipedia:P%C3%A1ginas para borrar]]\n'
        footer += '[[eo:Vikipedio:Forigendaj artikoloj]]\n'
        footer += '[[fi:Wikipedia:Poistettavat sivut]]\n'
        footer += '[[fr:Wikip%C3%A9dia:Pages_%C3%A0_supprimer]]\n'
        footer += '[[fy:Wikipedy:Siden wiskje]]\n'
        footer += '[[he:ויקיפדיה:רשימת מועמדים למחיקה]]\n'
        footer += '[[hu:Wikip%C3%A9dia:Szavaz%C3%A1s_t%C3%B6rl%C3%A9sr%C5%91l]]\n'
        footer += '[[it:Wikipedia:Pagine da cancellare]]\n'
        footer += '[[ja:Wikipedia:削除依頼]]\n'
        footer += '[[ko:위키백과:삭제요청]]\n'
        footer += '[[lb:Wikipedia:L%C3%A4schen]]\n'
        footer += '[[na:Wikipedia:Animwen ijababa]]\n'
        footer += '[[nl:Wikipedia:Te verwijderen pagina\'s]]\n'
        footer += '[[no:Wikipedia:Sletting]]\n'
        footer += '[[pl:Wikipedia:Strony do usunięcia]]\n'
        footer += '[[pt:Wikipedia:P%C3%A1ginas_para_eliminar]]\n'
        footer += '[[ro:Wikipedia:Pagini de şters]]\n'
        footer += '[[ru:%D0%92%D0%B8%D0%BA%D0%B8%D0%BF%D0%B5%D0%B4%D0%B8%D1%8F:%D0%9A_%D1%83%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%B8%D1%8E]]'
        footer += '[[simple:Wikipedia:Requests for deletion]]\n'
        footer += '[[sk:Wikip%C3%A9dia:Str%C3%A1nky_na_zmazanie]]\n'
        footer += '[[sl:Wikipedija:Predlogi za brisanje]]\n'
        footer += '[[sv:Wikipedia:Sidor_som_b%C3%B6r_raderas]]\n'
        footer += '[[vi:Wikipedia:Bi%E1%BB%83u_quy%E1%BA%BFt_xo%C3%A1_b%C3%A0i]]\n'
        footer += '[[zh:Wikipedia:删除投票和请求]]\n'

#       text = header.encode('utf-8') + transinclude.encode('utf-8') + footer.encode('utf-8')
#       text = text.decode('utf-8')

        attempt = True
        while(attempt):
                try:
                        wikipedia.Page(wikipedia.getSite(), page).put(header + transinclude + footer, '[[User:VFD Bot|VFD Bot]] ([[User talk:AllyUnion|talk]]) ([[Special:Contributions/VFD Bot|contributions]]): Updating page with VFD page from ' + yesterday.strftime('%A, %B %d, %Y.'))
                        attempt = False
                except wikipedia.EditConflict:
                        wikipedia.Page(wikipedia.getSite(), page).put(header + transinclude + footer, '[[User:VFD Bot|VFD Bot]] ([[User talk:AllyUnion|talk]]) ([[Special:Contributions/VFD Bot|contributions]]): Updating page with VFD page from ' + yesterday.strftime('%A, %B %d, %Y.'))
                        attempt = True
</pre>
<p><a name="en-wp-vfd-newday.py" id="en-wp-vfd-newday.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-newday.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-newday.py</span></h2>
<pre>
#!/usr/bin/python2.3
# -*- coding: utf-8 -*-

import os, sys
if (not (sys.path[0] == '')):
        os.chdir(sys.path[0])

# Automatic VFD Update script
# Written by Jason Y. Lee (AllyUnion)
# Assumes to be run by a cron job, some time prior to the next 00:00 UTC.

# Due to DST errors, the new assumption is that is run hourly, so that no
# matter what weird time zone this is run from, it will always work
# Will only run IF time is some time IS between one hour prior to the next
# 00:00 UTC and 00:00 UTC

#import wikipedia, config
import datetime

if __name__ == "__main__":
        utc = datetime.datetime.utcnow()# - datetime.timedelta(1)
        if (not (utc.replace(hour=22,minute=50,second=0,microsecond=0) &lt;= utc &lt;= (utc.replace(hour=0,minute=10,second=0,microsecond=0) + datetime.timedelta(1)))):
                sys.exit(1)

        # Get today's date:
        import wikipedia, config
        # Today's date, exactly at 0000 hours
        # Required as a point of reference
        today = utc.replace(hour=0,minute=0,second=0,microsecond=0)

        # Tomorrow's date, exactly at 0000 hours
        # The new day going up
        tomorrow = today + datetime.timedelta(1)

        # Site configured in user-config.py
        mysite = wikipedia.getSite()

        # Section heading for tomorrow
        sectionheading = '&lt;div align = \"center\"&gt;\'\'\'[[Wikipedia:Guide to Votes for Deletion|Guide to Votes for Deletion]]\'\'\'&lt;/div&gt;\n'
        sectionheading += '{{Cent}}\n'
        sectionheading += '&lt;small&gt;{{purge|Purge server cache}}&lt;/small&gt;\n'
        sectionheading += '== [[' + tomorrow.strftime('%B ') + str(int(tomorrow.strftime('%d'))) + ']] ==\n&lt;!-- New votes to the bottom, please. --&gt;\n'

        # Tomorrow's page name
        tomorrow_pagename = 'Wikipedia:Votes_for_deletion/Log/' + tomorrow.strftime('%Y_%B_') + str(int(tomorrow.strftime('%d')))

        # Post section heading for tomorrow's VFD page
        tomorrow_page = wikipedia.Page(mysite, tomorrow_pagename)
        tomorrow_page.put(sectionheading, '[[User:VFD Bot|VFD Bot]] ([[User talk:AllyUnion|talk]]) ([[Special:Contributions/VFD Bot|contributions]]): Creating new VFD day - automatic VFD bot work')
#       else:
#               print "False\n";
</pre>
<p><a name="en-wp-vfd-update2.py" id="en-wp-vfd-update2.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-update2.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-update2.py</span></h2>
<pre>
#!/usr/bin/python2.3
# -*- coding: utf-8 -*-

import os, sys
if (not (sys.path[0] == '')):
        os.chdir(sys.path[0])

# Automatic VFD Update script
# Written by Jason Y. Lee (AllyUnion)
# Assumes to be run by a cron job, 10 minutes prior to the next 00:00 UTC.

# Author's note:
# Yes, I do realize I can make an array for all the variables below
# but I rather have everything clearly spelled out just to make absolutely
# certain that whatever error is going on can be clearly seen

#import wikipedia, config
import datetime

def stndrdth(n):
        '''Return the appropriate st, nd, rd, or th to a number
        Example: stndrdth(2), returns "2nd" as the result'''
        remain = n % 10
        if (remain == 1):
                if (n == 11): return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'
                return str(n) + '&lt;sup&gt;st&lt;/sup&gt;'
        elif (remain == 2):
                if (n == 12): return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'
                return str(n) + '&lt;sup&gt;nd&lt;/sup&gt;'
        elif (remain == 3):
                if (n == 13): return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'
                return str(n) + '&lt;sup&gt;rd&lt;/sup&gt;'
        else:
                return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'

if __name__ == "__main__":
        utc = datetime.datetime.utcnow()# - datetime.timedelta(1)
        if (not (utc.replace(hour=23,minute=0,second=0,microsecond=0) &lt;= utc &lt;= (utc.replace(hour=0,minute=0,second=0,microsecond=0) + datetime.timedelta(1)))):
                sys.exit(1)

        import wikipedia, config

        # Get today's date:
#       yyyy = int(datetime.datetime.utcnow().strftime('%Y'))
#       mm = int(datetime.datetime.utcnow().strftime('%m'))
#       dd = int(datetime.datetime.utcnow().strftime('%d'))

        # Today's date, exactly at 0000 hours
        # Required as a point of reference
#       today = datetime.datetime(yyyy, mm, dd, 0, 0, 0, 0)
        today = utc.replace(hour=0,minute=0,second=0,microsecond=0)

        # Tomorrow's date, exactly at 0000 hours
        # The new day going up
        tomorrow = today + datetime.timedelta(1)

        # Five days prior to today's date at 0000 hours
        # The day that will be moved to Old
        fivedaysago = today - datetime.timedelta(5)

        # Six days prior to today's date at 0000 hours
        # The day which we need to search for
        sixdaysago = today - datetime.timedelta(6)

        # Today's transinclude
        today_vfdtag = '*[[Wikipedia:Votes for deletion/Log/' + today.strftime('%Y %B ') + str(int(today.strftime('%d'))) + '|' + today.strftime('%A, ') + str(int(today.strftime('%d'))) + today.strftime(' %B') + ']]'

        # Tomorrow's transinclude
        tomorrow_vfdtag = '*[[Wikipedia:Votes for deletion/Log/' + tomorrow.strftime('%Y %B ') + str(int(tomorrow.strftime('%d'))) + '|' + tomorrow.strftime('%A, ') + str(int(tomorrow.strftime('%d'))) + tomorrow.strftime(' %B') + ']]'

        # Five days ago (transinclude)
        fivedaysago_vfdtag = '*[[Wikipedia:Votes for deletion/Log/' + fivedaysago.strftime('%Y %B ') + str(int(fivedaysago.strftime('%d'))) + '|' + fivedaysago.strftime('%A, ') + str(int(fivedaysago.strftime('%d'))) + fivedaysago.strftime(' %B') + ']]'

#       print fivedaysago_vfdtag
#       sys.exit(0)

        # Current votes section links
        # Need: Tomorrow's, today's, and five days ago
        # Today's
        today_sectionlink = '[[#' + today.strftime('%B ') + str(int(today.strftime('%d'))) + '|' + stndrdth(int(today.strftime('%d'))) + ']]'

        # Tomorrow's
        tomorrow_sectionlink = '[[#' + tomorrow.strftime('%B ') + str(int(tomorrow.strftime('%d'))) + '|' + stndrdth(int(tomorrow.strftime('%d'))) + ']]'

        # Five days ago
        fivedaysago_sectionlink = '[[#' + fivedaysago.strftime('%B ') + str(int(fivedaysago.strftime('%d'))) + '|' + stndrdth(int(fivedaysago.strftime('%d'))) + ']]'   

        # Old votes section links
        # Need: Five days ago, and six days ago

        # Five days ago
        fivedaysago_oldsectionlink = '\'\'[[Wikipedia:Votes for deletion/Log/' + fivedaysago.strftime('%Y %B ') + str(int(fivedaysago.strftime('%d'))) + '|' + stndrdth(int(fivedaysago.strftime('%d'))) + ']]\'\''

        # Six days ago
#       sixdaysago_oldsectionlink = '\'\'[[Wikipedia:Votes for deletion/Log/' + sixdaysago.strftime('%Y %B ') + str(int(sixdaysago.strftime('%d'))) + '|' + stndrdth(int(sixdaysago.strftime('%d'))) + ']]\'\''
        
        # Five days ago
#       fivedaysago_oldsectionlink = '\'\'[[/Old#' + fivedaysago.strftime('%B ') + str(int(fivedaysago.strftime('%d'))) + '|' + stndrdth(int(fivedaysago.strftime('%d'))) + ']]\'\''

        # Six days ago
#       sixdaysago_oldsectionlink = '\'\'[[/Old#' + sixdaysago.strftime('%B ') + str(int(sixdaysago.strftime('%d'))) + '|' + stndrdth(int(sixdaysago.strftime('%d'))) + ']]\'\''
        # Site configured in user-config.py
        mysite = wikipedia.getSite()

        # Get vfd pages
        vfd = wikipedia.Page(mysite, 'Wikipedia:Votes_for_deletion').get(False, True)

        # Search and replace

        # Section links (taxobox)
        # Today's section link, replace with today's section link + newline + tomorrow's section link (replace once)
        vfd = vfd.replace(today_sectionlink, tomorrow_sectionlink + '\n' + today_sectionlink, 1)

        # Five days section link + newline, replace with nothing (replace once)
        vfd = vfd.replace(fivedaysago_sectionlink + '\n', '', 1)

        # Six days ago old section link, replace with five days ago old section link + '\n' + six days ago old section link (replace once)
#       vfd = vfd.replace(sixdaysago_oldsectionlink, fivedaysago_oldsectionlink + '\n' + sixdaysago_oldsectionlink, 1)
        # Replace using section title
        vfd = vfd.replace('==Old votes==', '==Old votes==\n' + fivedaysago_oldsectionlink, 1)

        # Transincludes on VFD
        # Replace today's transinclude with today's transinclude + '\n' + tomorrow's transinclude
        vfd = vfd.replace(today_vfdtag, tomorrow_vfdtag + '\n' + today_vfdtag, 1)

        # Remove five days ago transinclude
        vfd = vfd.replace(fivedaysago_vfdtag + '\n', '', 1)

        # Page links
        vfdpage = wikipedia.Page(mysite, 'Wikipedia:Votes for deletion')

        vfdpage.put(vfd, '[[User:VFD Bot|VFD Bot]] ([[User talk:AllyUnion|talk]]) ([[Special:Contributions/VFD Bot|contributions]]): Auto-update of VFD')
</pre>
<p><a name="en-wp-vfd-update3.py" id="en-wp-vfd-update3.py"></a></p>
<h2><span class="editsection">[<a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html" title="Edit section: en-wp-vfd-update3.py">edit</a>]</span> <span class="mw-headline">en-wp-vfd-update3.py</span></h2>
<pre>
#!/usr/bin/python2.3
# -*- coding: utf-8 -*-

import sys
sys.exit(1)

import os, sys
if (not (sys.path[0] == '')):
        os.chdir(sys.path[0])

# Automatic VFD Update script
# Written by Jason Y. Lee (AllyUnion)
# Assumes to be run by a cron job, 10 minutes prior to the next 00:00 UTC.

# Author's note:
# Yes, I do realize I can make an array for all the variables below
# but I rather have everything clearly spelled out just to make absolutely
# certain that whatever error is going on can be clearly seen

#import wikipedia, config
import datetime

def stndrdth(n):
        '''Return the appropriate st, nd, rd, or th to a number
        Example: stndrdth(2), returns "2nd" as the result'''
        remain = n % 10
        if (remain == 1):
                if (n == 11): return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'
                return str(n) + '&lt;sup&gt;st&lt;/sup&gt;'
        elif (remain == 2):
                if (n == 12): return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'
                return str(n) + '&lt;sup&gt;nd&lt;/sup&gt;'
        elif (remain == 3):
                if (n == 13): return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'
                return str(n) + '&lt;sup&gt;rd&lt;/sup&gt;'
        else:
                return str(n) + '&lt;sup&gt;th&lt;/sup&gt;'

if __name__ == "__main__":
        utc = datetime.datetime.utcnow()# - datetime.timedelta(1)
#       if (not (utc.replace(hour=23,minute=0,second=0,microsecond=0) &lt;= utc &lt;= (utc.replace(hour=0,minute=0,second=0,microsecond=0) + datetime.timedelta(1)))):
#               sys.exit(1)

        import wikipedia, config

        # Get today's date:
#       yyyy = int(datetime.datetime.utcnow().strftime('%Y'))
#       mm = int(datetime.datetime.utcnow().strftime('%m'))
#       dd = int(datetime.datetime.utcnow().strftime('%d'))

        # Today's date, exactly at 0000 hours
        # Required as a point of reference
#       today = datetime.datetime(yyyy, mm, dd, 0, 0, 0, 0)
        today = utc.replace(hour=0,minute=0,second=0,microsecond=0)

        # Tomorrow's date, exactly at 0000 hours
        # The new day going up
        tomorrow = today + datetime.timedelta(1)

        # Five days prior to today's date at 0000 hours
        # The day that will be moved to Old
        fivedaysago = today - datetime.timedelta(5)

        # Six days prior to today's date at 0000 hours
        # The day which we need to search for
        sixdaysago = today - datetime.timedelta(6)

        # Today's transinclude
        today_vfdtag = '*[[Wikipedia:Votes for deletion/Log/' + today.strftime('%Y %B ') + str(int(today.strftime('%d'))) + '|' + today.strftime('%A, ') + str(int(today.strftime('%d'))) + today.strftime(' %B') + ']]'

        # Tomorrow's transinclude
        tomorrow_vfdtag = '*[[Wikipedia:Votes for deletion/Log/' + tomorrow.strftime('%Y %B ') + str(int(tomorrow.strftime('%d'))) + '|' + tomorrow.strftime('%A, ') + str(int(tomorrow.strftime('%d'))) + tomorrow.strftime(' %B') + ']]'

        # Five days ago (transinclude)
        fivedaysago_vfdtag = '*[[Wikipedia:Votes for deletion/Log/' + fivedaysago.strftime('%Y %B ') + str(int(fivedaysago.strftime('%d'))) + '|' + fivedaysago.strftime('%A, ') + str(int(fivedaysago.strftime('%d'))) + fivedaysago.strftime(' %B') + ']]'

#       print fivedaysago_vfdtag
#       sys.exit(0)

        # Site configured in user-config.py
        mysite = wikipedia.getSite()

        # Get vfd pages
#       vfd = wikipedia.getPage(mysite, 'Wikipedia:Votes_for_deletion', True, True, False)
        pagename = wikipedia.Page(mysite, 'WP:NAC').getRedirectTo()
        vfd = wikipedia.getPage(mysite, pagename, True, True, False)

        # Search and replace

        # Transincludes on VFD
        # Replace today's transinclude with today's transinclude + '\n' + tomorrow's transinclude
        vfd = vfd.replace(today_vfdtag, tomorrow_vfdtag + '\n' + today_vfdtag, 1)

        # Remove five days ago transinclude
        vfd = vfd.replace(fivedaysago_vfdtag + '\n', '', 1)

        # Page links
        vfdpage = wikipedia.Page(mysite, pagename)

        vfdpage.put(vfd, '[[User:VFD Bot|VFD Bot]] ([[User talk:AllyUnion|talk]]) ([[Special:Contributions/VFD Bot|contributions]]): Updating Votes for deletion section')
</pre>
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html">http://en.wikipedia.org../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html</a>"</div>
	    	    <!-- end content -->
	    <div class="visualClear"></div>
	  </div>
	</div>
      </div>
      <div id="column-one">
	<div id="p-cactions" class="portlet">
	  <h5>Views</h5>
	  <ul>
	    <li id="ca-nstab-user"
	       class="selected"	       ><a href="../../../a/l/l/User%7EAllyUnion_VFD_bot_code_dae7.html">User page</a></li><li id="ca-talk"
	       class="new"	       ><a href="../../../a/l/l/User_talk%7EAllyUnion_VFD_bot_code_83df.html">Discussion</a></li><li id="ca-current"
	       	       ><a href="http://en.wikipedia.org/wiki/User:AllyUnion/VFD_bot_code">Current revision</a></li>	  </ul>
	</div>
	<div class="portlet" id="p-logo">
	  <a style="background-image: url(../../../images/wiki-en.png);"
	    href="../../../index.html"
	    title="Main Page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
	  <h5>Navigation</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-Main-page"><a href="../../../index.html">Main page</a></li>
	     	      <li id="n-Contents"><a href="../../../c/o/n/Wikipedia%7EContents_3181.html">Contents</a></li>
	     	      <li id="n-Featured-content"><a href="../../../f/e/a/Wikipedia%7EFeatured_content_24ba.html">Featured content</a></li>
	     	      <li id="n-currentevents"><a href="../../../c/u/r/Portal%7ECurrent_events_bb60.html">Current events</a></li>
	     	    </ul>
	  </div>
	</div>
		<div class='portlet' id='p-interaction'>
	  <h5>interaction</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-About-Wikipedia"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html">About Wikipedia</a></li>
	     	      <li id="n-portal"><a href="../../../c/o/m/Wikipedia%7ECommunity_Portal_6a3c.html">Community portal</a></li>
	     	      <li id="n-contact"><a href="../../../c/o/n/Wikipedia%7EContact_us_afd6.html">Contact us</a></li>
	     	      <li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising">Make a donation</a></li>
	     	      <li id="n-help"><a href="../../../c/o/n/Help%7EContents_22de.html">Help</a></li>
	     	    </ul>
	  </div>
	</div>
		<div id="p-search" class="portlet">
	  <h5><label for="searchInput">Search</label></h5>
	  <div id="searchBody" class="pBody">
	    <form action="javascript:goToStatic(3)" id="searchform"><div>
	      <input id="searchInput" name="search" type="text"
	        accesskey="f" value="" />
	      <input type='submit' name="go" class="searchButton" id="searchGoButton"
	        value="Go" />
	    </div></form>
	  </div>
	</div>
	      </div><!-- end of the left (by default at least) column -->
      <div class="visualClear"></div>
      <div id="footer">
    <div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../../../skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>	<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="../../../images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>	<ul id="f-list">
	  	  	  <li id="f-credits">This page was last modified 00:15, 4 January 2006 by Wikipedia user <a href="../../../a/l/l/User%7EAllyUnion_7163.html" title="User:AllyUnion">AllyUnion</a>. </li>	  <li id="f-copyright">All text is available under the terms of the <a class='internal' href="../../../t/e/x/Wikipedia%7EText_of_the_GNU_Free_Documentation_License_702a.html" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="../../../c/o/p/Wikipedia%7ECopyrights_92c4.html" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a US-registered <a class='internal' href="../../../5/0/1/501%28c%29.html#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="../../../n/o/n/Non-profit_organization.html" title="Non-profit organization">nonprofit</a> <a href="../../../c/h/a/Charitable_organization.html" title="Charitable organization">charity</a>.<br /></li>	  <li id="f-about"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html" title="Wikipedia:About">About Wikipedia</a></li>	  <li id="f-disclaimer"><a href="../../../g/e/n/Wikipedia%7EGeneral_disclaimer_3e44.html" title="Wikipedia:General disclaimer">Disclaimers</a></li>	  	</ul>
      </div>
    </div>
  </body>
</html>
