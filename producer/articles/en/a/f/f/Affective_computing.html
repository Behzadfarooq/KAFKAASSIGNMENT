<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    		<meta name="keywords" content="Affective computing,Affective,Affective design,Artificial intelligence,Cognitive,Computer sciences,Counseling,Digital pet,E-learning,ELIZA,Emotions" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="../../../COPYING.html" />
    <title>Affective computing - Wikipedia, the free encyclopedia</title>
    <style type="text/css">/*<![CDATA[*/ @import "../../../skins/htmldump/main.css"; /*]]>*/</style>
    <link rel="stylesheet" type="text/css" media="print" href="../../../skins/common/commonPrint.css" />
    <!--[if lt IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE50Fixes.css";</style><![endif]-->
    <!--[if IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE55Fixes.css";</style><![endif]-->
    <!--[if IE 6]><style type="text/css">@import "../../../skins/monobook/IE60Fixes.css";</style><![endif]-->
    <!--[if IE]><script type="text/javascript" src="../../../skins/common/IEFixes.js"></script>
    <meta http-equiv="imagetoolbar" content="no" /><![endif]-->
    <script type="text/javascript" src="../../../skins/common/wikibits.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/md5.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/utf8.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/lookup.js"></script>
    <script type="text/javascript" src="../../../raw/gen.js"></script>        <style type="text/css">/*<![CDATA[*/
@import "../../../raw/MediaWiki%7ECommon.css";
@import "../../../raw/MediaWiki%7EMonobook.css";
@import "../../../raw/gen.css";
/*]]>*/</style>          </head>
  <body
    class="ns-0">
    <div id="globalWrapper">
      <div id="column-content">
	<div id="content">
	  <a name="top" id="contentTop"></a>
	        <h1 class="firstHeading">Affective computing</h1>
	  <div id="bodyContent">
	    <h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
	    <div id="contentSub"></div>
	    	    <div class="usermessage">You have <a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">new messages</a> (<a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">last change</a>).</div>	    <!-- start content -->
	    <p><b>Affective computing</b> is a branch of <a href="../../../a/r/t/Artificial_intelligence.html" title="Artificial intelligence">artificial intelligence</a> that deals with the design of devices which can process <a href="../../../e/m/o/Emotions.html" title="Emotions">emotions</a>. It is an interdisciplinary field spanning <a href="../../../c/o/m/Computer_sciences.html" title="Computer sciences">computer sciences</a>, <a href="../../../p/s/y/Psychology.html" title="Psychology">psychology</a>, and <a href="../../../c/o/g/Cognitive.html" title="Cognitive">cognitive</a> science.</p>
<p>The term "<a href="../../../a/f/f/Affective.html" title="Affective">Affective</a> Computing" is also the title of an article by Professor Rosalind Picard<a href="http://affect.media.mit.edu/people.php?id=picard" class="external autonumber" title="http://affect.media.mit.edu/people.php?id=picard" rel="nofollow">[1]</a> at the MIT Media Lab<a href="http://affect.media.mit.edu/" class="external autonumber" title="http://affect.media.mit.edu/" rel="nofollow">[2]</a> written in 1995.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Areas_of_affective_computing"><span class="tocnumber">1</span> <span class="toctext">Areas of affective computing</span></a>
<ul>
<li class="toclevel-2"><a href="#Detecting_and_recognizing_emotional_information"><span class="tocnumber">1.1</span> <span class="toctext">Detecting and recognizing emotional information</span></a></li>
<li class="toclevel-2"><a href="#Emotion_in_machines"><span class="tocnumber">1.2</span> <span class="toctext">Emotion in machines</span></a></li>
<li class="toclevel-2"><a href="#Emotional_understanding"><span class="tocnumber">1.3</span> <span class="toctext">Emotional understanding</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Technologies_of_Affective_computing"><span class="tocnumber">2</span> <span class="toctext">Technologies of Affective computing</span></a>
<ul>
<li class="toclevel-2"><a href="#Emotional_Speech"><span class="tocnumber">2.1</span> <span class="toctext">Emotional Speech</span></a></li>
<li class="toclevel-2"><a href="#Facial_Expression"><span class="tocnumber">2.2</span> <span class="toctext">Facial Expression</span></a></li>
<li class="toclevel-2"><a href="#Body_gesture"><span class="tocnumber">2.3</span> <span class="toctext">Body gesture</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Potential_Applications"><span class="tocnumber">3</span> <span class="toctext">Potential Applications</span></a></li>
<li class="toclevel-1"><a href="#Application_Examples"><span class="tocnumber">4</span> <span class="toctext">Application Examples</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">5</span> <span class="toctext">External links</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>
</ul>
</td>
</tr>
</table>
<p><script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script><a name="Areas_of_affective_computing" id="Areas_of_affective_computing"></a></p>
<h2><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Areas of affective computing">edit</a>]</span> <span class="mw-headline">Areas of affective computing</span></h2>
<p><a name="Detecting_and_recognizing_emotional_information" id="Detecting_and_recognizing_emotional_information"></a></p>
<h3><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Detecting and recognizing emotional information">edit</a>]</span> <span class="mw-headline">Detecting and recognizing emotional information</span></h3>
<p>Detecting emotional information usually involve passive sensors which capture data about the user's physical state or behavior. The data gathered is often analogous to the cues humans use to perceive <a href="../../../e/m/o/Emotions.html" title="Emotions">emotions</a> in others. For example, a video camera might capture facial expressions, body posture and gestures, while a microphone might capture speech. Other sensors detect emotional cues by directly measuring <a href="../../../p/h/y/Physiological.html" title="Physiological">physiological</a> data; such as skin temperature and <a href="../../../g/a/l/Galvanic_skin_response.html" title="Galvanic skin response">galvanic resistance</a>.</p>
<p>Recognizing emotional information requires the extraction of meaningful patterns from the gathered data. This is done by parsing the data through various processes such as <a href="../../../s/p/e/Speech_recognition.html" title="Speech recognition">speech recognition</a>, <a href="../../../n/a/t/Natural_language_processing.html" title="Natural language processing">natural language processing</a>, or <a href="../../../f/a/c/Face_recognition.html" title="Face recognition">facial expression detection</a>.</p>
<p><a name="Emotion_in_machines" id="Emotion_in_machines"></a></p>
<h3><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Emotion in machines">edit</a>]</span> <span class="mw-headline">Emotion in machines</span></h3>
<p>Another area within affective computing is the design of computational devices having either innate emotional capabilities or capable of convincingly simulate emotions (see <a href="../../../s/t/r/Strong_AI_efb5.html" title="Strong AI">strong AI</a>). The possession of innate emotion in non-human intellects is primarily a philosophical topic, since <a href="../../../s/a/p/Sapience.html" title="Sapience">sapience</a> is considered a pre-requisite for the ability to process emotions and there are currently no known models of sapiency besides humans. A more practical approach, based on current technological capabilities, is the simulation of emotions. The goal of such simulation is to enrich and facilitate interactivity between human and machine.</p>
<p><a name="Emotional_understanding" id="Emotional_understanding"></a></p>
<h3><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Emotional understanding">edit</a>]</span> <span class="mw-headline">Emotional understanding</span></h3>
<p>Emotional understanding refers to the ability of a device not only to detect emotional or affective information, but also to store, process, build and maintain an emotional model of the user. The goal is to understand contextual information about the user and its environment, and formulate an appropriate response. This is difficult because human emotions arise from complex external and internal contexts.</p>
<p>Possible features of a system which displays emotional understanding might be adaptive behavior, for example, avoiding interaction with a user it perceives to be angry. A probable use of such capability would be ensuring data integrity and security.</p>
<p><a name="Technologies_of_Affective_computing" id="Technologies_of_Affective_computing"></a></p>
<h2><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Technologies of Affective computing">edit</a>]</span> <span class="mw-headline">Technologies of Affective computing</span></h2>
<p><a name="Emotional_Speech" id="Emotional_Speech"></a></p>
<h3><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Emotional Speech">edit</a>]</span> <span class="mw-headline">Emotional Speech</span></h3>
<p>Emotional speech processing recognizes the user's emotional state by analyzing speech patterns. Vocal parameters and <a href="../../../p/r/o/Prosody.html" title="Prosody">prosody</a> features such as pitch variables and speech rate are analyzed through pattern recognition.</p>
<p>Some related works: Dellaert<sup id="_ref-Dellaert_0" class="reference"><a href="#_note-Dellaert" title="">[1]</a></sup>, Lee<sup id="_ref-Lee_0" class="reference"><a href="#_note-Lee" title="">[2]</a></sup></p>
<p>Emotional inflection and modulation in synthetized speech, either through phrasing or acoustic features is useful in human-computer interaction. Such capability makes speech natural and expressive. For example a dialogue system might modulate its speech to be more puerile if it deems the emotional model of its current user is that of a child.</p>
<p><a name="Facial_Expression" id="Facial_Expression"></a></p>
<h3><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Facial Expression">edit</a>]</span> <span class="mw-headline">Facial Expression</span></h3>
<p>The detection and processing of facial expression is achieved through various methods such as <a href="../../../o/p/t/Optical_flow.html" title="Optical flow">optical flow</a>, <a href="../../../h/i/d/Hidden_Markov_model_f38e.html" title="Hidden Markov model">hidden Markov model</a>, <a href="../../../n/e/u/Neural_network.html" title="Neural network">neural network processing</a> or active appearance model.</p>
<p><a name="Body_gesture" id="Body_gesture"></a></p>
<h3><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Body gesture">edit</a>]</span> <span class="mw-headline">Body gesture</span></h3>
<p>Body gesture is the position and the changes of the body. There are many proposed methods<sup id="_ref-JK_0" class="reference"><a href="#_note-JK" title="">[3]</a></sup> to detect the body gesture.</p>
<p>Hand gestures have been a common focus of body gesture detection, apparentness methods<sup id="_ref-Vladimir_0" class="reference"><a href="#_note-Vladimir" title="">[4]</a></sup> and 3-D modeling methods are traditionally used.</p>
<p><a name="Potential_Applications" id="Potential_Applications"></a></p>
<h2><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Potential Applications">edit</a>]</span> <span class="mw-headline">Potential Applications</span></h2>
<p>In <a href="../../../e/-/l/E-learning.html" title="E-learning">e-learning</a> applications, affective computing can be used to adjust the presentation of a computerized tutor when a learner is bored, interested, frustrated, or pleased.</p>
<p><a href="../../../p/s/y/Psychology.html" title="Psychology">Psychological health services</a> such as <a href="../../../c/o/u/Counseling.html" title="Counseling">counseling</a>, can benefit from affective computing applications, for example, when determining a client's emotional state.</p>
<p><a href="../../../r/o/b/Robot.html" title="Robot">Robotic systems</a> capable of processing affective information might exhibit higher flexibility when working in uncertain or complex environments. Companion devices such as <a href="../../../d/i/g/Digital_pet.html" title="Digital pet">digital pets</a> may also make use of affective computing abilities to enhance realism and provide a higher degree of autonomy.</p>
<p>Affective computing has also been suggested to apply in monitoring society. For example a car which can monitor the emotion of it's occupants may engage additional safety measures, such as alerting other vehicles, if it detects the driver is angry.</p>
<p>Affective computing have a high potential of application in <a href="../../../h/u/m/Human_computer_interaction.html" title="Human computer interaction">human computer interaction</a>, ideas like affective mirrors which let the user see how he perform in front of others, emotion monitoring agents that warn you before you send a negative or angry email, or even music players which can create relationships between music and emotions to select tracks based on mood have also been suggested.</p>
<p>Also see: <a href="../../../a/f/f/Affective_design.html" title="Affective design">Affective design</a></p>
<p><a name="Application_Examples" id="Application_Examples"></a></p>
<h2><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: Application Examples">edit</a>]</span> <span class="mw-headline">Application Examples</span></h2>
<ul>
<li><a href="../../../e/l/i/ELIZA_1cf2.html" title="ELIZA">ELIZA</a></li>
<li><a href="../../../w/e/a/Wearable_computer.html" title="Wearable computer">Wearable computer</a> always make use of affective technologies, such as detection of biosignals</li>
<li><a href="../../../h/u/m/Human%E2%80%93computer_interaction.html" title="Human–computer interaction">Human–computer interaction</a></li>
<li><a href="http://www.autotutor.org/" class="external text" title="http://www.autotutor.org/" rel="nofollow">AutoTutor</a></li>
<li><a href="http://affect.media.mit.edu/projects.php?id=179" class="external text" title="http://affect.media.mit.edu/projects.php?id=179" rel="nofollow">Affective Tangibles</a></li>
<li><a href="http://affect.media.mit.edu/projectpages/lc/ALC/ALC.htm" class="external text" title="http://affect.media.mit.edu/projectpages/lc/ALC/ALC.htm" rel="nofollow">Affective Learning Companions</a></li>
<li><a href="http://robotic.media.mit.edu/projects/RoCo.html" class="external text" title="http://robotic.media.mit.edu/projects/RoCo.html" rel="nofollow">RoCo</a> is a robotic sociable computer</li>
<li><a href="../../../k/i/s/Kismet_%28robot%29.html" title="Kismet (robot)">Kismet</a></li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://affect.media.mit.edu/" class="external text" title="http://affect.media.mit.edu/" rel="nofollow">Affective Computing Group at the MIT Media Laboratory</a></li>
<li><a href="http://www.affectivemedia.com/" class="external text" title="http://www.affectivemedia.com/" rel="nofollow">Affective Media - the Emotion Engineering Laboratory</a></li>
<li><a href="http://emotion.autotutor.org" class="external text" title="http://emotion.autotutor.org" rel="nofollow">Emotive Computing Group at the</a> <a href="../../../f/e/d/FedEx_Institute_of_Technology_5e48.html" title="FedEx Institute of Technology">FedEx Institute of Technology</a></li>
<li><a href="http://www.convo.co.uk/x02/" class="external text" title="http://www.convo.co.uk/x02/" rel="nofollow">An interactive experiment: detection of emotion</a></li>
<li><a href="http://itr.beckman.uiuc.edu/" class="external text" title="http://itr.beckman.uiuc.edu/" rel="nofollow">Multimodal Human Computer Interaction Project</a></li>
<li><a href="http://alumni.media.mit.edu/~cahn/emot-speech.html" class="external text" title="http://alumni.media.mit.edu/~cahn/emot-speech.html" rel="nofollow">Emotional &amp; Expressive Synthesized Speech</a></li>
<li><a href="http://www.kasrl.org/facial_expression.html" class="external text" title="http://www.kasrl.org/facial_expression.html" rel="nofollow">Facial Expression Resources on the Web</a></li>
<li><a href="http://emotion-research.net" class="external text" title="http://emotion-research.net" rel="nofollow">The HUMAINE Portal on emotion-oriented computing</a></li>
</ul>
<p><br /></p>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="../../../a/f/f/Affective_computing.html" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ol>
<li>Dellaert, F., Polizin, t., and Waibel, A., Recognizing Emotion in Speech", In Proc. Of ICSLP 1996, Philadelphia, PA, pp.1970-1973, 1996</li>
<li>Lee, C.M.; Narayanan, S.; Pieraccini, R., Recognition of Negative Emotion in the Human Speech Signals, Workshop on Auto. Speech Recognition and Understanding, Dec 2001</li>
<li>J. K. Aggarwal, Q. Cai, Human Motion Analysis: A Review, Computer Vision and Image Understanding, Vol. 73, No. 3, 1999</li>
<li>Vladimir I. Pavlovic, Rajeev Sharma, Thomas S. Huang, Visual Interpretation of Hand Gestures for Human-Computer Interaction; A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997</li>
</ol>

<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org../../../a/f/f/Affective_computing.html">http://en.wikipedia.org../../../a/f/f/Affective_computing.html</a>"</div>
	    <div id="catlinks"><p class='catlinks'><a href="../../../c/a/t/Special%7ECategories_101d.html" title="Special:Categories">Category</a>: <span dir='ltr'><a href="../../../a/r/t/Category%7EArtificial_intelligence_cc78.html" title="Category:Artificial intelligence">Artificial intelligence</a></span></p></div>	    <!-- end content -->
	    <div class="visualClear"></div>
	  </div>
	</div>
      </div>
      <div id="column-one">
	<div id="p-cactions" class="portlet">
	  <h5>Views</h5>
	  <ul>
	    <li id="ca-nstab-main"
	       class="selected"	       ><a href="../../../a/f/f/Affective_computing.html">Article</a></li><li id="ca-talk"
	       	       ><a href="../../../a/f/f/Talk%7EAffective_computing_f7b8.html">Discussion</a></li><li id="ca-current"
	       	       ><a href="http://en.wikipedia.org/wiki/Affective_computing">Current revision</a></li>	  </ul>
	</div>
	<div class="portlet" id="p-logo">
	  <a style="background-image: url(../../../images/wiki-en.png);"
	    href="../../../index.html"
	    title="Main Page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
	  <h5>Navigation</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-Main-page"><a href="../../../index.html">Main page</a></li>
	     	      <li id="n-Contents"><a href="../../../c/o/n/Wikipedia%7EContents_3181.html">Contents</a></li>
	     	      <li id="n-Featured-content"><a href="../../../f/e/a/Wikipedia%7EFeatured_content_24ba.html">Featured content</a></li>
	     	      <li id="n-currentevents"><a href="../../../c/u/r/Portal%7ECurrent_events_bb60.html">Current events</a></li>
	     	    </ul>
	  </div>
	</div>
		<div class='portlet' id='p-interaction'>
	  <h5>interaction</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-About-Wikipedia"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html">About Wikipedia</a></li>
	     	      <li id="n-portal"><a href="../../../c/o/m/Wikipedia%7ECommunity_Portal_6a3c.html">Community portal</a></li>
	     	      <li id="n-contact"><a href="../../../c/o/n/Wikipedia%7EContact_us_afd6.html">Contact us</a></li>
	     	      <li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising">Make a donation</a></li>
	     	      <li id="n-help"><a href="../../../c/o/n/Help%7EContents_22de.html">Help</a></li>
	     	    </ul>
	  </div>
	</div>
		<div id="p-search" class="portlet">
	  <h5><label for="searchInput">Search</label></h5>
	  <div id="searchBody" class="pBody">
	    <form action="javascript:goToStatic(3)" id="searchform"><div>
	      <input id="searchInput" name="search" type="text"
	        accesskey="f" value="" />
	      <input type='submit' name="go" class="searchButton" id="searchGoButton"
	        value="Go" />
	    </div></form>
	  </div>
	</div>
	      </div><!-- end of the left (by default at least) column -->
      <div class="visualClear"></div>
      <div id="footer">
    <div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../../../skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>	<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="../../../images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>	<ul id="f-list">
	  	  	  <li id="f-credits">This page was last modified 15:09, 28 March 2007 by Anonymous user(s) of Wikipedia. Based on work by Wikipedia user(s) <a href="../../../u/t/c/User%7EUtcursch_88c9.html" title="User:Utcursch">Utcursch</a>, <a href="../../../a/l/a/User%7EAlaibot_de3d.html" title="User:Alaibot">Alaibot</a>, <a href="../../../t/h/i/User%7EThiseye_689a.html" title="User:Thiseye">Thiseye</a>, Christianjones, <a href="../../../c/a/n/User%7ECandiedbug_9b44.html" title="User:Candiedbug">Candiedbug</a>, Bissinger, <a href="../../../e/r/i/User%7EEric_Mathews_Technology_35dd.html" title="User:Eric Mathews Technology">Eric Mathews Technology</a>, <a href="../../../m/y/o/User%7EMyopic_Bookworm_35a2.html" title="User:Myopic Bookworm">Myopic Bookworm</a>, <a href="../../../d/a/m/User%7EDammit_ebf7.html" title="User:Dammit">Dammit</a>, <a href="../../../c/m/d/User%7ECmdrObot_0605.html" title="User:CmdrObot">CmdrObot</a>, <a href="../../../b/l/u/User%7EBluebot_e595.html" title="User:Bluebot">Bluebot</a>, Chpapa, <a href="../../../e/a/g/User%7EEagle_101_bfb5.html" title="User:Eagle 101">Eagle 101</a>, <a href="../../../a/r/r/User%7EArru_dab3.html" title="User:Arru">Arru</a>, <a href="../../../t/e/c/User%7ETechnocratic_3fc8.html" title="User:Technocratic">Technocratic</a>, <a href="../../../i/n/t/User%7EInteriot_4e2d.html" title="User:Interiot">Interiot</a>, <a href="../../../c/o/m/User%7ECommander_Keane_ca6f.html" title="User:Commander Keane">Commander Keane</a>, <a href="../../../s/e/b/User%7ESebastianHelm_63db.html" title="User:SebastianHelm">SebastianHelm</a>, <a href="../../../s/i/m/User%7ESimonP_1010.html" title="User:SimonP">SimonP</a>, <a href="../../../p/a/t/User%7EPatrick_7b47.html" title="User:Patrick">Patrick</a> and <a href="../../../a/w/a/User%7EAwaterl_e341.html" title="User:Awaterl">Awaterl</a>.</li>	  <li id="f-copyright">All text is available under the terms of the <a class='internal' href="../../../t/e/x/Wikipedia%7EText_of_the_GNU_Free_Documentation_License_702a.html" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="../../../c/o/p/Wikipedia%7ECopyrights_92c4.html" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a US-registered <a class='internal' href="../../../5/0/1/501%28c%29.html#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="../../../n/o/n/Non-profit_organization.html" title="Non-profit organization">nonprofit</a> <a href="../../../c/h/a/Charitable_organization.html" title="Charitable organization">charity</a>.<br /></li>	  <li id="f-about"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html" title="Wikipedia:About">About Wikipedia</a></li>	  <li id="f-disclaimer"><a href="../../../g/e/n/Wikipedia%7EGeneral_disclaimer_3e44.html" title="Wikipedia:General disclaimer">Disclaimers</a></li>	  	</ul>
      </div>
    </div>
  </body>
</html>
