<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    		<meta name="keywords" content="Wikipedia:Bots/Requests for approval/BJBot,CAT:ORFU,Python,WP:CSD,WP:IFD,WT:CSD,Alai,Alai/Fairuse-orphans-untagged,Alai/Orphan-image-summary,BJBot,Bjweeks" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="../../../COPYING.html" />
    <title>Wikipedia:Bots/Requests for approval/BJBot - Wikipedia, the free encyclopedia</title>
    <style type="text/css">/*<![CDATA[*/ @import "../../../skins/htmldump/main.css"; /*]]>*/</style>
    <link rel="stylesheet" type="text/css" media="print" href="../../../skins/common/commonPrint.css" />
    <!--[if lt IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE50Fixes.css";</style><![endif]-->
    <!--[if IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE55Fixes.css";</style><![endif]-->
    <!--[if IE 6]><style type="text/css">@import "../../../skins/monobook/IE60Fixes.css";</style><![endif]-->
    <!--[if IE]><script type="text/javascript" src="../../../skins/common/IEFixes.js"></script>
    <meta http-equiv="imagetoolbar" content="no" /><![endif]-->
    <script type="text/javascript" src="../../../skins/common/wikibits.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/md5.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/utf8.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/lookup.js"></script>
    <script type="text/javascript" src="../../../raw/gen.js"></script>        <style type="text/css">/*<![CDATA[*/
@import "../../../raw/MediaWiki%7ECommon.css";
@import "../../../raw/MediaWiki%7EMonobook.css";
@import "../../../raw/gen.css";
/*]]>*/</style>          </head>
  <body
    class="ns-4">
    <div id="globalWrapper">
      <div id="column-content">
	<div id="content">
	  <a name="top" id="contentTop"></a>
	        <h1 class="firstHeading">Wikipedia:Bots/Requests for approval/BJBot</h1>
	  <div id="bodyContent">
	    <h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
	    <div id="contentSub"><span class="subpages">&lt; <a href="../../../b/o/t/Wikipedia%7EBots_fd71.html" title="Wikipedia:Bots">Wikipedia:Bots</a> | <a href="../../../b/o/t/Wikipedia%7EBots_Requests_for_approval_de2f.html" title="Wikipedia:Bots/Requests for approval">Requests for approval</a></span></div>
	    	    <div class="usermessage">You have <a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">new messages</a> (<a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">last change</a>).</div>	    <!-- start content -->
	    <p><br /></p>
<div class="boilerplate metadata" style="background-color: #dedaca; margin: 2em 0 0 0; padding: 0 10px 0 10px; border: 1px solid #AAAAAA;">
<dl>
<dd><i>The following discussion is an archived debate. <span style="color:red"><b>Please do not modify it.</b></span> Subsequent comments should be made in a new section.</i> The result of the discussion was <a href="../../../s/y/m/Image%7ESymbol_keep_vote.svg_19de.html" class="image" title=""><img src="../../../upload/shared/thumb/d/d0/Symbol_keep_vote.svg/20px-Symbol_keep_vote.svg.png" alt="" width="20" height="21" longdesc="../../../s/y/m/Image%7ESymbol_keep_vote.svg_19de.html" /></a> <b>Approved</b>.</dd>
</dl>
<a name="BJBot" id="BJBot"></a>
<h2><span class="editsection">[<a href="../../../b/o/t/Wikipedia%7EBots_Requests_for_approval_BJBot_7c62.html" title="Edit section: BJBot">edit</a>]</span> <span class="mw-headline"><a href="../../../b/j/b/User%7EBJBot_e625.html" title="User:BJBot">BJBot</a></span></h2>
<p><span class="plainlinks"><small><strong class="selflink">tasks</strong> • <a href="../../../c/o/n/Special%7EContributions_BJBot_e4eb.html" title="Special:Contributions/BJBot">contribs</a> • <a href="http://tools.wikimedia.de/~interiot/cgi-bin/Tool1/wannabe_kate?username=BJBot&amp;site=en.wikipedia.org" class="external text" title="http://tools.wikimedia.de/~interiot/cgi-bin/Tool1/wannabe_kate?username=BJBot&amp;site=en.wikipedia.org" rel="nofollow"><span style="color:#002bb8">count</span></a> • <a href="http://en.wikipedia.org/wiki/Special:Log?user=BJBot" class="external text" title="http://en.wikipedia.org/wiki/Special:Log?user=BJBot" rel="nofollow"><span style="color:#002bb8">logs</span></a> • <a href="http://en.wikipedia.org/wiki/Special:Log/move?user=BJBot" class="external text" title="http://en.wikipedia.org/wiki/Special:Log/move?user=BJBot" rel="nofollow"><span style="color:#002bb8">page moves</span></a> • <a href="../../../b/l/o/Special%7EBlockip_BJBot_539c.html" title="Special:Blockip/BJBot">block user</a> • <a href="http://en.wikipedia.org/wiki/Special:Log/block?page=User:BJBot" class="external text" title="http://en.wikipedia.org/wiki/Special:Log/block?page=User:BJBot" rel="nofollow"><span style="color:#002bb8">block log</span></a> • <a href="http://en.wikipedia.org/w/index.php?title=Special%3ALog&amp;type=makebot&amp;user=&amp;page=User:BJBot" class="external text" title="http://en.wikipedia.org/w/index.php?title=Special%3ALog&amp;type=makebot&amp;user=&amp;page=User:BJBot" rel="nofollow">flag log</a> • <a href="../../../m/a/k/Special%7EMakebot_BJBot_9fcb.html" title="Special:Makebot/BJBot">flag bot</a></small></span></p>
<p><b>Operator:</b> <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">Bjweeks</a></p>
<p><b>Automatic or Manually Assisted:</b> Automatic</p>
<p><b>Programming Language(s):</b> <a href="../../../p/y/t/Python.html" title="Python">Python</a> (pywikipedia)</p>
<p><b>Function Summary:</b> Add <a href="../../../o/r/f/Template%7EOrfud_2019.html" title="Template:Orfud">orfud</a> to orphaned fair use images.</p>
<p><b>Edit period(s)</b> <i>(e.g. Continuous, daily, one time run)</i><b>:</b> daily</p>
<p><b>Edit rate requested:</b> 1 edits <i>per</i> minute</p>
<p><b>Already has a bot flag</b> <i>(Y/N)</i><b>:</b> N</p>
<p><b>Function Details:</b> The bot will go through a list provided by the bot operator (for now) it will then check that A) the link is in fact a image, B) that no other pages link to it (orphan), C) it is tagged with a fair use template. The idea for the bot came from <a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu">Mecu</a>, so any questions on what it should be doing or why will most likely be answered by him.</p>
<a name="Discussion" id="Discussion"></a>
<h3><span class="editsection">[<a href="../../../b/o/t/Wikipedia%7EBots_Requests_for_approval_BJBot_7c62.html" title="Edit section: Discussion">edit</a>]</span> <span class="mw-headline">Discussion</span></h3>
<ul>
<li>Sounds OK: assuming this is trialed and approved, will you keep BRFA posted about changes to the "for now" basis? <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 07:04, 21 January 2007 (UTC)</li>
</ul>
<dl>
<dd>
<ul>
<li>Will do. <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 08:55, 21 January 2007 (UTC)</li>
</ul>
</dd>
</dl>
<ul>
<li>Can I add a MECUBot proposal to this? It would be a clone of BJBot. The theory is there are over 100,000 orphaned images. Going through them all at 1 a minute will take 69+ days. By having clone bots to this bot, the time period will be reduced to go through that list, so there could be quite a few clone bots to go through this. The plan is to use a downloaded/created list of all the orphaned images, run through that list, and once done, grab another list, compare the entries, whatever is new, run through that list, and run several times through this. We could then switch over to a more constant cycling mode, with 1 day intervals on the list perhaps. Some administration and coordination between the clone bots would be needed to accomplish this. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 15:04, 21 January 2007 (UTC)
<ul>
<li>This seems to raise several issues beyond the original proposal. Firstly, what's the likely number of orphaned <i>fair use</i> image? The main <a href="../../../f/a/i/Category%7EFair_use_images_e9b5.html" title="Category:Fair use images">Cat:fair use images</a> category currently contains &lt; 4200 images (there's more lurking in subcats, but none of those I've noticed seem especially huge). Fetching <i>every</i> orphaned image page seems a very inefficient way of doing this: why not do so only with those in both the orphaned list, and the fair use categories? (Either from a database dump -- if we ever see one of those again -- or from category listing pages from the live wiki.) Secondly, why such repeated and frequent "cyclings"? While there might be something of a backlog, what's the likely level of throughput on this? Thirdly, why would it be better to have multiple bots doing the same thing, and thus causing the co-ordination issues you mention, as against just having a single bot working at twice (say) the rate? The server hit is certainly no better, and is possibly worse, if they end up duplicating large numbers of page fetches. In short, I'd like more assurance on the resource implications of the how you plan on tackling this. <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 02:34, 22 January 2007 (UTC)
<ul>
<li>I would say that 40% of the orphaned images are fair use. I have personally gone through 1500 images and can give that estimate. So that's 40,000 images, whereas most of the images are likely in the more recent uploads (ie, images in 2006 are more likely to be fair use orphans that from 2003 or 2004 or 2005). The main category is for use of the {{fairuse}} tag (which is depreciated), so most images should be in the subcategories. I went through the first 20 pages of the {{logo}} subcat (4000 images) and was only on the B's. Fetching every orphaned seems a better route, as fetching the orphan list and comparing it to the fair use list doesn't seem useful, as the bot can determine what is a fair use image, so doubly cross-checking with the fair use category seems redundant. The bot can also determine if the image is still orphaned by the time it checks it, as using an out-of-date list it must do this. A database dump is out of date. (It's currently 11-30-2006 for en.wiki) I have sought permission for a toolserver account to use a mysql database, and the en.wiki is only ~13 days out of date for that. But just generating the lists manually may be better (and less time consuming, I've been running a script on toolserver that someone else generated to produce all en.wiki orphaned images for 8.5 hours and it's given me nothing: producing the image list manually would be more efficient). As for multiple bots, I agree it may not be the best method. Increasing the speed of a single bot would accomplish the same purpose and reduce the overhead of maintaining this project. So, I'd like to switch from 1/minute to 2 images processed per minute in "peak" times of en.wiki and a higher rate (TBD) during off-periods, which would be self-controlled by the bot. If my "cyclings" you mean download a list, process (the 100000 images), download a new list and re-process... it's because the orphaned list goes by when the image was uploaded to Wikipedia. So if an image was uploaded in 2004 and is orphaned tomorrow, the orphaned list will show it in uploaded order date in 2004 compared to the rest of the images (somewhere in the low thousands, 1000-10000). "Starting" from the 100,000 numbers of these will miss this images. Also, if we get 30,000 of the orphaned fair use images deleted in the first round, the orphaned list would decrease to 70,000 so new images could appear anywhere inbetween. Bjweeks had the idea to monitor new uploads to fair use to see if they were used after 7 days of uploading, but even this will miss images that were uploaded years ago who get orphaned and appear on the orphaned list. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 03:50, 22 January 2007 (UTC)
<ul>
<li>I'm a bit skeptical of your 40,000 estimate: if your 1500 images are relatively recent, then for the very reason you make reference to, they're likely to have a higher rate than the main body. I'd admittedly missed some of the largest subcats, as they're in categories that don't use the term "fair use", just to add to the confusion (<a href="../../../a/l/b/Category%7EAlbum_covers_f276.html" title="Category:Album covers">Cat:album covers</a> is bigger still). Looks like there was something on the order of 300,000 fair use images in toto last November. But my whole point is we shouldn't need to deal in guestimates, you should be able to calculate how many candidates there are in advance: even the last db dump would give you a pretty good idea of that, and as I say, you can fetch the fair use categories from the live wiki to get a more up to date list of candidates. (Admittedly it's likely to take about over 1000 category listing pages fetches, for all the "fair use" categories, but that seems to me to be a clear winner over 100,000 image description page fetches being done repeatedly and speculatively. 100,000 pages is an appreciable fraction of the whole db, and seems to me to be sailing pretty close to the wind on the "web spider" clause of the bot policy.) I don't see how you can characterise that as "not useful": it's precisely what you've said you want, just whether you get it by intersection, vs. exhaustive search of a single list. I'm not suggesting you don't fetch the image description pages <i>at all</i> (which wouldn't make a lot of sense, given that you have to fetch it before you re-write it), just that you do so only for a smaller list of (very) likely candidates, double-checking, rather than testing on spec.</li>
<li>"Cycling" was your term: you tell me what you mean by it. If you fetch 100,000 pages, tag 40,000 and delete 30,000 (again, I have concerns about the accuracy of the estimate), then simply re-running the same bot on the remaining 70,000 is going to be <i>extremely</i> resource-extravagant: you'll find a handful that have had fair use tags added, and do nothing with the vast majority (since the vast majority will have not changed their copyright-status tag since the last time). And even that handful you could have found much more readily by monitoring changes to the fair use <i>categories</i>. As about 87,000 orphaned images were uploaded before the last database dump, and as those are what you're basing the claim of the size of the problem on, at the very least I'd like to see that tackled with a targetted, non-speculative one-off run before any open-ended approval is considered for any process that's going to be a long-running mini-spider. <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 06:21, 22 January 2007 (UTC)
<ul>
<li>I'm tending to agree with the above, it shouldn't be very hard to get list of orphans, a list of fair use images and images to be deleted and cross reference them. (toolserver or database dump) What I'm thinking is a script on the tool server that queries the DB and produces a current list of images to be checked (once), the bot would then request part of the list and begin working. The toolserver script then removes the chunk that the bot requested till the list is complete. The toolserver script would be run x (replication lag) days after the first list was totally finished. Wash, rinse, repeat. <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 06:47, 22 January 2007 (UTC)
<ul>
<li>That sounds sensible to me. For the orphans alone, I don't see any need for the toolserver: the special page is actually <i>more</i> up-to-date (completely live?) (you lucky things, look at how limited the uncategorised pages special is...). However, it would be a convenient way of getting an integrated list of tagged-as-fair-use-and-orphaned, which otherwise you'd need a middling-large number of category listing queries to the wiki to get. <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 07:10, 22 January 2007 (UTC)
<ul>
<li>You're assuming that during cycling we'll double check the previous 70,000 images. That doesn't need to be done, since we "just" checked them, and I agree that they likely won't change license status. By having the list that we know we've checked, getting a new list, comparing to the old list of checked images, we can eliminate the images we've already checked. Thus, if a new image appears at #35958, we'll see it as new and check it.</li>
<li>I still don't see how grabbing all 500,000 (guess) fair use images in whatever category they are in will help speed up the process. Pulling the 100,000 image pages will give us 100% accuracy on what images are fair use (an error rate by the bot shall be ignored). Comparing the two and going for "likely" images would have some kind of error rate (above the error rate of the bot). Processing and comparing the two lists would slow us down. As we would need to repeat this for each cycle. If a new image shows up, we have to grab the entire categories again and then re-compare that one image to the entire 500,000 (guess) list. I think I see where you're driving at this: That you want to know better before we begin how many of these orphans are fair use. Comparing the lists would give us knowledge that there are 47,839 (example) images that are orphaned and fair use. We've cut the bot running time by 2.</li>
<li>There are 452 fair use image categories. See <a href="../../../m/e/c/User%7EMecu_AllFairUseImageCats_a1a8.html" title="User:Mecu/AllFairUseImageCats">User:Mecu/AllFairUseImageCats</a>. I used <a href="http://tools.wikimedia.de/~daniel/WikiSense/CategoryTree.php?wikilang=en&amp;wikifam=.wikipedia.org&amp;cat=Fair+use+images&amp;m=c&amp;go=Load&amp;userlang=en&amp;terse=" class="external autonumber" title="http://tools.wikimedia.de/~daniel/WikiSense/CategoryTree.php?wikilang=en&amp;wikifam=.wikipedia.org&amp;cat=Fair+use+images&amp;m=c&amp;go=Load&amp;userlang=en&amp;terse=" rel="nofollow">[1]</a>, there are some duplicates as some are under several locations and the Royal Air Force structure loops and is redundant. I believe I cleaned all the duplicates out, but I may have missed a few. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 15:22, 22 January 2007 (UTC)</li>
<li>The special page is completely live, which is the problem. If a new orphan shows up as #1, every other image drops down by one number. Even more true and likely is if they get deleted. We don't really need (or want) this accuracy. You can only get 5000 images listed at one time, so it would take 20+ pages to get the list with possible duplicates (though few). This method could be (might be) faster than using a toolserver code (that I gave up processing on after 8.5 hours! There is a warning that the en.wiki is too large for such tools). --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 13:56, 22 January 2007 (UTC)
<ul>
<li>I don't think I'm making "assumptions" about the nature of the cycling, as making such inferences as I'm able on the basis of your incomplete description thereof. If you can make this more precise, then so much the better.</li>
<li>I'm not talking about loading all the fair use <i>pages</i> (which would indeed be horrific): I'm talking about obtaining a list of the contents of (i.e., page titles in) the fair use <i>categories</i> (which is about 200 times fewer page fetches, even <i>if</i> you do it from the live wiki, and none at all if you do it via the others methods I've suggested). Yes, this could mean that fewer pages reads are required by a factor of two... or by any other factor, depending on how many images are actually in said intersection: could be almost any number.</li>
<li>Number of FU categories: if you're counting all subcats of the main one, it was just less than 400 in the November dump, so your current total is pretty plausible.</li>
<li>Why is the special page being too live a problem? You had the opposite objection to the db dump! If you're going to keep a log of all pages previously inspected, it's just a matter of looking for new entries (in either the fair use cats, or the orphaned list).</li>
<li>Given especially your very valid point about possible backlogging at IFD, wouldn't it be sensible to defer discussion of a continously running bot until such time as things are clearer with regard to the (hidden) backlog? If the backlog is anything like as large as you suggest, most of it will show up in the last database, and by the time it's tagged and cleared, we <i>ought</i> to have a fresh one, which would further quantify the rate at which they're accreting. <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 06:38, 23 January 2007 (UTC)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>BJ brought up another issue: The bot will create a HUGE backlog of images in the ORFU categories for admins to delete. At processing 2 images/min and a "success" rate of 40% (which may not be accurate if we cross-check the lists), that 2880 images processed per day and 1152 images in the ORFU category for each day. At the 40,000 images I guessed were ORFU, that's 34+ straight days of a category of 1000+ images to be deleted. If we cross-check the lists, a likely 100% rate could put 2880 images in the categories for 13+ days. The delay will likely be months before this hump gets finished off. I personally don't have a problem with the categories sitting around with the images waiting for deletion but some may. The good thing is that these images are tagged and known at least and will eventually get deleted. Perhaps we should warn the CSD admins or create a seperate category for images processed ORFU by the bot so that the "regular" ORFU categories don't get clogged with it, and the bot's category can get worked on the side from CSD, though it would certainly be applicable under CSD, just held off to the side to prevent clogging. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 13:56, 22 January 2007 (UTC)
<ul>
<li>FYI the bot is code complete except for the way it acquires the list to check. If I should upload the source somewhere please advise and if so should I comment it first. <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 07:28, 22 January 2007 (UTC)
<ul>
<li>On that note, would I be allowed to trial the bot on 10 or so images to test the non-list getting parts of the code? <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 09:49, 22 January 2007 (UTC)
<ul>
<li>I'm inclined to note that it appears to be "accepted practice" to make a small number of test edits prior to formal approval of a trial per se, so unofficially, I'd just go ahead and make those. Though easy on the "and so": if you want to make more than 10, it might be better to wait on the latter, from the BAG. (BTW, I have no objection to such a trial, where you're working from some relatively "clean" list of predominantly true positives, and working on the order of small-hundreds of images.) On the backlog: I'm not too worried, as moving a hidden backlog to a visible one is generally a good thing. But it would be both prudent and courteous to give IFD "regulars" a heads-up about this discussion, and the possible consequences, yes. <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 06:03, 23 January 2007 (UTC)
<ul>
<li>Test finished with no errors, had to fix two bugs but it all worked. <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 07:22, 23 January 2007 (UTC)</li>
<li>Great! These images won't go through <a href="../../../i/f/d/WP%7EIFD_bb01.html" title="WP:IFD">WP:IFD</a> though. They will go through <a href="../../../c/s/d/WP%7ECSD_a4a4.html" title="WP:CSD">WP:CSD</a> (It applies under I5) under the <a href="../../../o/r/f/CAT%7EORFU_58f4.html" title="CAT:ORFU">CAT:ORFU</a> categories, unless we do something special. There currently is no backlog and the existing days have between 100-300 images (with the higher ones probably days I had been going through and doing the work this bot will manually).</li>
<li>Also, another note to say the the plan is now to just use the dump that should occur today and then weekly and process the lists offline (on BJ's box) to determine the working list. This method both reduces load on the tool server and increases the likelyhood of finding true images to seek out. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 14:23, 23 January 2007 (UTC)
<ul>
<li>Nice job, BJ. See no reason a larger trial shouldn't be approved. My mistake, Macu; perhaps at <a href="../../../c/s/d/WT%7ECSD_761e.html" title="WT:CSD">WT:CSD</a>, then, or wherever it is the image speedy-deleters hang out. As much as anything to satisfy my curiousity, I've run a query on the November db dump to try to identify what are (or at least were) candidates. The result was a suspiciously exact 19000 in categories in the "fair use" tree, of which something over 4000 were already tagged as orphans. I've summarised the results <a href="../../../a/l/a/User%7EAlai_Orphan-image-summary_a100.html" title="User:Alai/Orphan-image-summary">here</a>, and uploaded a list of the untagged images <a href="../../../a/l/a/User%7EAlai_Fairuse-orphans-untagged_ec07.html" title="User:Alai/Fairuse-orphans-untagged">here</a>. Obviously things have moved on from there, with about 10,000 more orphaned images now existing, and several thousand deletions (hence the copious redlinks), but if it's of any use... <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 01:35, 24 January 2007 (UTC)
<ul>
<li>Two things. Fist I would like to run the bot on that list unless you feel it is too outdated as it would give a large head start on the backlog. Also could you post the queries you used? (I must admit my SQL knowledge is almost nonexistent) <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 01:50, 24 January 2007 (UTC)
<ul>
<li>I'd support running the 'bot on that list; it's <i>possible</i> that it's now uselessly outdated, but my guess would be that it won't be too bad. (Assuming it gets the OK, maybe you could let me know what the false-positive rates of various kinds actually are, whether on the whole list or some portion thereof.) The SQL queries are fairly straightfoward, but I have to reconstruct parts of them, and there's currently a somewhat ugly dependency on a table I build anyway for other purposes, but that would be rather painful to run just to do this. I'll get back to you on this shortly. <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> 04:03, 24 January 2007 (UTC)
<ul>
<li>I have added logging support to the bot, if the bot stays in use I will add summary support. <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 06:33, 24 January 2007 (UTC)</li>
</ul>
</li>
</ul>
</li>
<li>I've made a request at <a href="http://en.wikipedia.org/wiki/Wikipedia_talk:Criteria_for_speedy_deletion#BJBot_.26_Possibly_large_number_of_images_in_ORFU_categories" class="external autonumber" title="http://en.wikipedia.org/wiki/Wikipedia_talk:Criteria_for_speedy_deletion#BJBot_.26_Possibly_large_number_of_images_in_ORFU_categories" rel="nofollow">[2]</a> for comments on the potential large backlog created by the bot. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 02:08, 24 January 2007 (UTC)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>It appears <a href="../../../r/o/o/User%7ERoomba_b392.html" title="User:Roomba">User:Roomba</a> Bot, which does this, may be resurrected soon (<a href="../../../g/m/a/User_talk%7EGmaxwell_8678.html#Roomba_Bot" title="User talk:Gmaxwell">User talk:Gmaxwell#Roomba Bot</a>). Though that bot doesn't notify users. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 17:11, 22 January 2007 (UTC)
<ul>
<li>Gmaxwell is waiting for the en.wiki replication to be closer to real time before starting his bot again. Currently, it's several weeks behind but closing the gap. This bot could have a large portion of the work done by the time it's caught up. --<a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu"><font color="#CEBE70"><b>MECU</b></font></a>≈<small><a href="../../../m/e/c/User_talk%7EMecu_1c42.html" title="User talk:Mecu">talk</a></small> 14:23, 23 January 2007 (UTC)</li>
</ul>
</li>
</ul>
<p>OK, just to sum things up and be perfectly clear before approval: this bot will be run with no clones, will get the list of images to process from <a href="../../../a/l/a/User%7EAlai_Fairuse-orphans-untagged_ec07.html" title="User:Alai/Fairuse-orphans-untagged">User:Alai/Fairuse-orphans-untagged</a> for now, and later database dumps or the toolserver, and will place the tagged images into the regular "orphaned fair use" categories. Correct? —<span style="font: small-caps 14px times; color: red;"><a href="../../../m/e/t/User%7EMets501_2e06.html" title="User:Mets501">Mets501</a> (<a href="../../../m/e/t/User_talk%7EMets501_fc50.html" title="User talk:Mets501">talk</a>)</span> 18:11, 25 January 2007 (UTC)</p>
<dl>
<dd>All correct.&#160;:) <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 18:13, 25 January 2007 (UTC)
<dl>
<dd>Also, can the bot please warn users with {{<a href="../../../o/r/p/Template%7EOrphaned_1e2b.html" title="Template:Orphaned">Orphaned</a>}}, instead of that other message? And perhaps you can make the bot sign the message as "This is an automated message from <a href="../../../b/j/b/User%7EBJBot_e625.html" title="User:BJBot">BJBot</a>. DATE_HERE (UTC)"? —<span style="font: small-caps 14px times; color: red;"><a href="../../../m/e/t/User%7EMets501_2e06.html" title="User:Mets501">Mets501</a> (<a href="../../../m/e/t/User_talk%7EMets501_fc50.html" title="User talk:Mets501">talk</a>)</span> 18:17, 25 January 2007 (UTC)
<dl>
<dd>I already changed the message to {{<a href="../../../o/r/p/Template%7EOrphaned_1e2b.html" title="Template:Orphaned">Orphaned</a>}} in the latest version and I will add the "automated message" part. <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 18:20, 25 January 2007 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p><a href="../../../s/y/m/Image%7ESymbol_support_vote.svg_9978.html" class="image" title=""><img src="../../../upload/shared/thumb/9/94/Symbol_support_vote.svg/20px-Symbol_support_vote.svg.png" alt="" width="20" height="21" longdesc="../../../s/y/m/Image%7ESymbol_support_vote.svg_9978.html" /></a> <b>Approved for trial</b>. Please tag/warn uploader of 100 images or so from <a href="../../../a/l/a/User%7EAlai_Fairuse-orphans-untagged_ec07.html" title="User:Alai/Fairuse-orphans-untagged">User:Alai/Fairuse-orphans-untagged</a> and report back here with a few diffs, and preferably the success rate of the part of the list that was processed. —<span style="font: small-caps 14px times; color: red;"><a href="../../../m/e/t/User%7EMets501_2e06.html" title="User:Mets501">Mets501</a> (<a href="../../../m/e/t/User_talk%7EMets501_fc50.html" title="User talk:Mets501">talk</a>)</span> 18:25, 25 January 2007 (UTC)</p>
<dl>
<dd>Done! The bot tagged 3/4 (71/100) of all images in the list. For this run it with only the pywikipedia rate limiting on and it made about 3-6 EPM, I was wondering if I could keep it this way as it will take forever at 1 EPM. Diffs, (<a href="http://en.wikipedia.org/wiki/Image:Queenssingiel3.jpg" class="external autonumber" title="http://en.wikipedia.org/wiki/Image:Queenssingiel3.jpg" rel="nofollow">[3]</a>, <a href="http://en.wikipedia.org/wiki/User_talk:Ginga" class="external autonumber" title="http://en.wikipedia.org/wiki/User_talk:Ginga" rel="nofollow">[4]</a>) (<a href="http://en.wikipedia.org/wiki/Image:ZZ_Top_-_ZZ_Top%27s_First_Album.jpg" class="external autonumber" title="http://en.wikipedia.org/wiki/Image:ZZ_Top_-_ZZ_Top%27s_First_Album.jpg" rel="nofollow">[5]</a>, <a href="http://en.wikipedia.org/wiki/User_talk:Kingcrimson1973" class="external autonumber" title="http://en.wikipedia.org/wiki/User_talk:Kingcrimson1973" rel="nofollow">[6]</a>) (<a href="http://en.wikipedia.org/wiki/Image:Listenwithyourheart.jpg" class="external autonumber" title="http://en.wikipedia.org/wiki/Image:Listenwithyourheart.jpg" rel="nofollow">[7]</a>, <a href="http://en.wikipedia.org/wiki/User_talk:Kingcrimson1973" class="external autonumber" title="http://en.wikipedia.org/wiki/User_talk:Kingcrimson1973" rel="nofollow">[8]</a>). Also I found this funny <a href="../../../i/l/u/User_talk%7EIluvchineselit_5855.html" title="User talk:Iluvchineselit">User talk:Iluvchineselit</a>&#160;:). <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">BJ</a><small><sup><a href="../../../b/j/w/User_talk%7EBjweeks_e86e.html" title="User talk:Bjweeks">Talk</a></sup></small> 02:29, 26 January 2007 (UTC)</dd>
</dl>
<p><a href="../../../s/y/m/Image%7ESymbol_keep_vote.svg_19de.html" class="image" title=""><img src="../../../upload/shared/thumb/d/d0/Symbol_keep_vote.svg/20px-Symbol_keep_vote.svg.png" alt="" width="20" height="21" longdesc="../../../s/y/m/Image%7ESymbol_keep_vote.svg_19de.html" /></a> <b>Approved</b>. Looks great. This bot shall run with a flag. Feel free to make up to six edits per minute. —<span style="font: small-caps 14px times; color: red;"><a href="../../../m/e/t/User%7EMets501_2e06.html" title="User:Mets501">Mets501</a> (<a href="../../../m/e/t/User_talk%7EMets501_fc50.html" title="User talk:Mets501">talk</a>)</span> 02:43, 26 January 2007 (UTC)</p>
<dl>
<dd><i>The above discussion is preserved as an archive of the debate. <span style="color:red"><b>Please do not modify it.</b></span> Subsequent comments should be made in a new section.</i></dd>
</dl>
</div>

<!-- 
Pre-expand include size: 1470 bytes
Post-expand include size: 1214 bytes
Template argument size: 138 bytes
Maximum: 2048000 bytes
-->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org../../../b/o/t/Wikipedia%7EBots_Requests_for_approval_BJBot_7c62.html">http://en.wikipedia.org../../../b/o/t/Wikipedia%7EBots_Requests_for_approval_BJBot_7c62.html</a>"</div>
	    <div id="catlinks"><p class='catlinks'><a href="../../../c/a/t/Special%7ECategories_101d.html" title="Special:Categories">Category</a>: <span dir='ltr'><a href="../../../w/i/k/Category%7EWikipedia_approved_bot_requests_9d71.html" title="Category:Wikipedia approved bot requests">Wikipedia approved bot requests</a></span></p></div>	    <!-- end content -->
	    <div class="visualClear"></div>
	  </div>
	</div>
      </div>
      <div id="column-one">
	<div id="p-cactions" class="portlet">
	  <h5>Views</h5>
	  <ul>
	    <li id="ca-nstab-project"
	       class="selected"	       ><a href="../../../b/o/t/Wikipedia%7EBots_Requests_for_approval_BJBot_7c62.html">Project page</a></li><li id="ca-talk"
	       class="new"	       ><a href="../../../b/o/t/Wikipedia_talk%7EBots_Requests_for_approval_BJBot_d0da.html">Discussion</a></li><li id="ca-current"
	       	       ><a href="http://en.wikipedia.org/wiki/Wikipedia:Bots/Requests_for_approval/BJBot">Current revision</a></li>	  </ul>
	</div>
	<div class="portlet" id="p-logo">
	  <a style="background-image: url(../../../images/wiki-en.png);"
	    href="../../../index.html"
	    title="Main Page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
	  <h5>Navigation</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-Main-page"><a href="../../../index.html">Main page</a></li>
	     	      <li id="n-Contents"><a href="../../../c/o/n/Wikipedia%7EContents_3181.html">Contents</a></li>
	     	      <li id="n-Featured-content"><a href="../../../f/e/a/Wikipedia%7EFeatured_content_24ba.html">Featured content</a></li>
	     	      <li id="n-currentevents"><a href="../../../c/u/r/Portal%7ECurrent_events_bb60.html">Current events</a></li>
	     	    </ul>
	  </div>
	</div>
		<div class='portlet' id='p-interaction'>
	  <h5>interaction</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-About-Wikipedia"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html">About Wikipedia</a></li>
	     	      <li id="n-portal"><a href="../../../c/o/m/Wikipedia%7ECommunity_Portal_6a3c.html">Community portal</a></li>
	     	      <li id="n-contact"><a href="../../../c/o/n/Wikipedia%7EContact_us_afd6.html">Contact us</a></li>
	     	      <li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising">Make a donation</a></li>
	     	      <li id="n-help"><a href="../../../c/o/n/Help%7EContents_22de.html">Help</a></li>
	     	    </ul>
	  </div>
	</div>
		<div id="p-search" class="portlet">
	  <h5><label for="searchInput">Search</label></h5>
	  <div id="searchBody" class="pBody">
	    <form action="javascript:goToStatic(3)" id="searchform"><div>
	      <input id="searchInput" name="search" type="text"
	        accesskey="f" value="" />
	      <input type='submit' name="go" class="searchButton" id="searchGoButton"
	        value="Go" />
	    </div></form>
	  </div>
	</div>
	      </div><!-- end of the left (by default at least) column -->
      <div class="visualClear"></div>
      <div id="footer">
    <div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../../../skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>	<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="../../../images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>	<ul id="f-list">
	  	  	  <li id="f-credits">This page was last modified 02:43, 26 January 2007 by Wikipedia user <a href="../../../m/e/t/User%7EMets501_2e06.html" title="User:Mets501">Mets501</a>. Based on work by Wikipedia user(s) <a href="../../../b/j/w/User%7EBjweeks_5dc7.html" title="User:Bjweeks">Bjweeks</a>, <a href="../../../a/l/a/User%7EAlai_39a8.html" title="User:Alai">Alai</a> and <a href="../../../m/e/c/User%7EMecu_ba9a.html" title="User:Mecu">Mecu</a>.</li>	  <li id="f-copyright">All text is available under the terms of the <a class='internal' href="../../../t/e/x/Wikipedia%7EText_of_the_GNU_Free_Documentation_License_702a.html" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="../../../c/o/p/Wikipedia%7ECopyrights_92c4.html" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a US-registered <a class='internal' href="../../../5/0/1/501%28c%29.html#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="../../../n/o/n/Non-profit_organization.html" title="Non-profit organization">nonprofit</a> <a href="../../../c/h/a/Charitable_organization.html" title="Charitable organization">charity</a>.<br /></li>	  <li id="f-about"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html" title="Wikipedia:About">About Wikipedia</a></li>	  <li id="f-disclaimer"><a href="../../../g/e/n/Wikipedia%7EGeneral_disclaimer_3e44.html" title="Wikipedia:General disclaimer">Disclaimers</a></li>	  	</ul>
      </div>
    </div>
  </body>
</html>
