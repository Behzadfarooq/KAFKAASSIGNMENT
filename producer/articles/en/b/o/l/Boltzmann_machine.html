<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    		<meta name="keywords" content="Boltzmann machine,Backpropagation,Boltzmann Distribution,Boltzmann distribution,Copycat (software),Douglas Hofstadter,EM algorithm,Generative model,Geoffrey Hinton,Gradient descent,Hebbian" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="../../../COPYING.html" />
    <title>Boltzmann machine - Wikipedia, the free encyclopedia</title>
    <style type="text/css">/*<![CDATA[*/ @import "../../../skins/htmldump/main.css"; /*]]>*/</style>
    <link rel="stylesheet" type="text/css" media="print" href="../../../skins/common/commonPrint.css" />
    <!--[if lt IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE50Fixes.css";</style><![endif]-->
    <!--[if IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE55Fixes.css";</style><![endif]-->
    <!--[if IE 6]><style type="text/css">@import "../../../skins/monobook/IE60Fixes.css";</style><![endif]-->
    <!--[if IE]><script type="text/javascript" src="../../../skins/common/IEFixes.js"></script>
    <meta http-equiv="imagetoolbar" content="no" /><![endif]-->
    <script type="text/javascript" src="../../../skins/common/wikibits.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/md5.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/utf8.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/lookup.js"></script>
    <script type="text/javascript" src="../../../raw/gen.js"></script>        <style type="text/css">/*<![CDATA[*/
@import "../../../raw/MediaWiki%7ECommon.css";
@import "../../../raw/MediaWiki%7EMonobook.css";
@import "../../../raw/gen.css";
/*]]>*/</style>          </head>
  <body
    class="ns-0">
    <div id="globalWrapper">
      <div id="column-content">
	<div id="content">
	  <a name="top" id="contentTop"></a>
	        <h1 class="firstHeading">Boltzmann machine</h1>
	  <div id="bodyContent">
	    <h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
	    <div id="contentSub"></div>
	    	    <div class="usermessage">You have <a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">new messages</a> (<a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">last change</a>).</div>	    <!-- start content -->
	    <p>A <b>Boltzmann machine</b> is the name given to a type of <a href="../../../s/i/m/Simulated_annealing.html" title="Simulated annealing">simulated annealing</a> <a href="../../../s/t/o/Stochastic_neural_network.html" title="Stochastic neural network">stochastic recurrent neural network</a> by <a href="../../../g/e/o/Geoffrey_Hinton_00b0.html" title="Geoffrey Hinton">Geoffrey Hinton</a> and <a href="../../../t/e/r/Terry_Sejnowski_bdb1.html" title="Terry Sejnowski">Terry Sejnowski</a>. Boltzmann machines can be seen as the <a href="../../../s/t/o/Stochastic_process.html" title="Stochastic process">stochastic</a>, <a href="../../../g/e/n/Generative_model.html" title="Generative model">generative</a> counterpart of <a href="../../../h/o/p/Hopfield_net.html" title="Hopfield net">Hopfield nets</a>. They were one of the first examples of a neural network capable of learning internal representations, and are able to represent and (given sufficient time) solve difficult combinatoric problems. However, due to a number of issues discussed below, Boltzmann machines with unconstrained connectivity have not proven useful for practical problems in machine learning or inference. They are still theoretically intriguing, however, due to the locality and <a href="../../../h/e/b/Hebbian.html" title="Hebbian">Hebbian</a> nature of their training algorithm, as well as their parallelism and the resemblance of their dynamics to simple physical processes. If the connectivity is constrained, the learning can be made efficient enough to be useful for practical problems.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Structure"><span class="tocnumber">1</span> <span class="toctext">Structure</span></a></li>
<li class="toclevel-1"><a href="#Training"><span class="tocnumber">2</span> <span class="toctext">Training</span></a></li>
<li class="toclevel-1"><a href="#Problems"><span class="tocnumber">3</span> <span class="toctext">Problems</span></a></li>
<li class="toclevel-1"><a href="#History"><span class="tocnumber">4</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1"><a href="#Restricted_Boltzmann_Machine"><span class="tocnumber">5</span> <span class="toctext">Restricted Boltzmann Machine</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>
</ul>
</td>
</tr>
</table>
<p><script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script><a name="Structure" id="Structure"></a></p>
<h2><span class="editsection">[<a href="../../../b/o/l/Boltzmann_machine.html" title="Edit section: Structure">edit</a>]</span> <span class="mw-headline">Structure</span></h2>
<p>A Boltzmann machine, like a <a href="../../../h/o/p/Hopfield_net.html" title="Hopfield net">Hopfield Network</a>, is a network of units with an "energy" defined for the network. It also has <a href="http://en.wiktionary.org/wiki/binary" class="extiw" title="wiktionary:binary">binary</a> units, but unlike Hopfield nets, Boltzmann machine units are <a href="../../../s/t/o/Stochastic.html" title="Stochastic">stochastic</a>. The global energy, <span class="texhtml"><i>E</i></span>, in a Boltzmann machine is identical in form to that of a Hopfield network:</p>
<dl>
<dd><img class='tex' src="../../../math/b/8/6/b862cda180b92dfd1d9488d3605730bf.png" alt="E = -\sum_{i&lt;j} w_{ij} \, s_i \, s_j + \sum_i \theta_i \, s_i" /></dd>
</dl>
<p>Where:</p>
<ul>
<li><span class="texhtml"><i>w</i><sub><i>i</i><i>j</i></sub></span> is the connection strength between unit <span class="texhtml"><i>j</i></span> and unit <span class="texhtml"><i>i</i></span>.</li>
<li><span class="texhtml"><i>s</i><sub><i>i</i></sub></span> is the state, <img class='tex' src="../../../math/5/3/6/53608099e10005fefdc82e7c16096faa.png" alt="s_i \in \{-1,1\}" />, of unit <span class="texhtml"><i>i</i></span>.</li>
<li><span class="texhtml">θ<sub><i>i</i></sub></span> is the <a href="../../../t/h/r/Threshold.html" title="Threshold">threshold</a> of unit <span class="texhtml"><i>i</i></span>.</li>
</ul>
<p>The connections in a Boltzmann machine have two restrictions:</p>
<ul>
<li><img class='tex' src="../../../math/0/3/f/03faf909c5ea100cf5e799f4f1accb99.png" alt="w_{ii}=0 \qquad \forall i" />. (No unit has a connection with itself.)</li>
<li><img class='tex' src="../../../math/3/4/2/3429254ad854ada76b7d7688f69ad258.png" alt="w_{ij}=w_{ji}\qquad \forall i,j" />. (All connections are <a href="../../../s/y/m/Symmetric.html" title="Symmetric">symmetric</a>.)</li>
</ul>
<p>Thus, the difference in the global energy that results from a single unit <span class="texhtml"><i>i</i></span> being 0 versus 1, written <span class="texhtml">Δ<i>E</i><sub><i>i</i></sub></span>, is given by:</p>
<dl>
<dd><img class='tex' src="../../../math/0/3/5/0355e9d2813b344213247f49701ce8f4.png" alt="\Delta E_i = \sum_j w_{ij} \, s_j - \theta_i" /></dd>
</dl>
<p>A Boltzmann machine is made up of <a href="../../../s/t/o/Stochastic.html" title="Stochastic">stochastic</a> units. The probability, <span class="texhtml"><i>p</i><sub><i>i</i></sub></span> of the <span class="texhtml"><i>i</i></span>-th unit being on is given by:</p>
<dl>
<dd><img class='tex' src="../../../math/e/f/8/ef80c2e24e7ee8e67dfbee85f6b1b664.png" alt="p_i = \frac{1}{1+\exp (-\Delta E_i/T)}" /></dd>
</dl>
<p>where the <a href="../../../s/c/a/Scalar_%28physics%29.html" title="Scalar (physics)">scalar</a> <span class="texhtml"><i>T</i></span> is referred to as the <a href="../../../t/e/m/Temperature.html" title="Temperature">temperature</a> of the system.</p>
<p>The network is run by repeatedly choosing a unit and setting its state according to the above formula. After running for long enough at a certain temperature, the probability of a global state of the network will depend only upon that global state's energy, according to a <a href="../../../b/o/l/Boltzmann_Distribution_ac66.html" title="Boltzmann Distribution">Boltzmann Distribution</a>. This means that log-probabilities of global states become linear in their energies. This relationship is true when the machine is "at <a href="../../../t/h/e/Thermal_equilibrium.html" title="Thermal equilibrium">thermal equilibrium</a>", meaning that the probability distribution of global states has converged. If we start running the network from a high temperature, and gradually decrease it until we reach a <a href="../../../t/h/e/Thermal_equilibrium.html" title="Thermal equilibrium">thermal equilibrium</a> at a low temperature, we are guaranteed to converge to a distribution where the energy level fluctuates around the global minimum. This process is called <a href="../../../s/i/m/Simulated_annealing.html" title="Simulated annealing">simulated annealing</a>.</p>
<p>If we want to train the network so that the chance it will converge to a global state is according to an external distribution that we have over these states, we need to set the weights so that the global states with the highest probabilities will get the lowest energies. This is done by the following training procedure.</p>
<p><a name="Training" id="Training"></a></p>
<h2><span class="editsection">[<a href="../../../b/o/l/Boltzmann_machine.html" title="Edit section: Training">edit</a>]</span> <span class="mw-headline">Training</span></h2>
<p>The units in the Boltzmann Machine are divided into "visible" units, V, and "hidden" units, H. The visible units are those which receive information from the "environment", i.e. our training set is a bunch of binary vectors over the set V. The distribution over the training set is denoted <span class="texhtml"><i>P</i> <sup>+</sup> (<i>V</i>)</span>.</p>
<p>On the Boltzmann Machine side, as recalled, the distribution over the global states is converging as we reach a <a href="../../../t/h/e/Thermal_equilibrium.html" title="Thermal equilibrium">thermal equilibrium</a>. We denote the converged distribution, after we marginalize it over the visible units <span class="texhtml"><i>V</i></span>, as <span class="texhtml"><i>P</i> <sup>−</sup> (<i>V</i>)</span>.</p>
<p>Our goal is to approximate the "real" distribution <span class="texhtml"><i>P</i> <sup>+</sup> (<i>V</i>)</span> using the <span class="texhtml"><i>P</i> <sup>−</sup> (<i>V</i>)</span> which will be produced (eventually) by the machine. To measure how similar the two distributions are we use the <a href="../../../k/u/l/Kullback-Leibler_distance_78a9.html" title="Kullback-Leibler distance">Kullback-Leibler distance</a>, <span class="texhtml"><i>G</i></span>:</p>
<dl>
<dd><img class='tex' src="../../../math/1/b/9/1b920a7c53d710ef6dcbbfb5828e7ca2.png" alt="G = \sum_{v}{P^{+}(v)\ln{\frac{P^{+}(v)}{P^{-}(v)}}}" /></dd>
</dl>
<p>Where the sum is over all the possible states of <span class="texhtml"><i>V</i></span>. <span class="texhtml"><i>G</i></span> is a function of the weights, since they determine the energy of a state, and the energy determines <span class="texhtml"><i>P</i> <sup>−</sup> (<i>v</i>)</span>, as promised by the <a href="../../../b/o/l/Boltzmann_distribution.html" title="Boltzmann distribution">Boltzmann distribution</a>. Hence, we can use a <a href="../../../g/r/a/Gradient_descent.html" title="Gradient descent">gradient descent</a> algorithm over <span class="texhtml"><i>G</i></span>, so a given weight, <span class="texhtml"><i>w</i><sub><i>i</i><i>j</i></sub></span> is changed by subtracting the <a href="../../../p/a/r/Partial_derivative.html" title="Partial derivative">partial derivative</a> of <span class="texhtml"><i>G</i></span> with respect to the weight.</p>
<p>There are two phases to Boltzmann machine training, and we switch iteratively between them. One is the "positive" phase where the visible units' states are clamped to a particular binary state vector sampled from the training set (according to <span class="texhtml"><i>P</i> <sup>+</sup></span> ). The other is the "negative" phase where the network is allowed to run freely, i.e. no units have their state determined by external data. Surprisingly enough, the gradient with respect to a given weight, <span class="texhtml"><i>w</i><sub><i>i</i><i>j</i></sub></span>, is given by the very simple equation:</p>
<dl>
<dd><img class='tex' src="../../../math/6/c/f/6cf97cb161146947308500ae1503db71.png" alt="\frac{\partial{G}}{\partial{w_{ij}}} = -\frac{1}{T}[p_{ij}^{+}-p_{ij}^{-}]" /></dd>
</dl>
<p>Where:</p>
<ul>
<li><img class='tex' src="../../../math/e/0/0/e0011cbc86b7268fbab7dc3433180415.png" alt="p_{ij}^{+}" /> is the probability of units <i>i</i> and <i>j</i> both being on when the machine is at equilibrium on the positive phase.</li>
</ul>
<ul>
<li><img class='tex' src="../../../math/3/3/f/33fc2eb36e2f7534607c0d248baf28d0.png" alt="p_{ij}^{-}" /> is the probability of units <i>i</i> and <i>j</i> both being on when the machine is at equilibrium on the negative phase.</li>
</ul>
<p>This result follows from the fact that at the <a href="../../../t/h/e/Thermal_equilibrium.html" title="Thermal equilibrium">thermal equilibrium</a> the probability <span class="texhtml"><i>P</i> <sup>−</sup> (<i>s</i>)</span> of any global state <span class="texhtml"><i>s</i></span> when the network is free-running is given by the <a href="../../../b/o/l/Boltzmann_distribution.html" title="Boltzmann distribution">Boltzmann distribution</a> (hence the name "Boltzmann machine").</p>
<p>Remarkably, this learning rule is fairly biologically plausible because the only information needed to change the weights is provided by "local" information. That is, the connection (or <a href="../../../s/y/n/Synapse.html" title="Synapse">synapse</a> biologically speaking) does not need information about anything other than the two neurons it connects. This is far more biologically realistic than the information needed by a connection in many other neural network training algorithms, such as <a href="../../../b/a/c/Backpropagation.html" title="Backpropagation">backpropagation</a>.</p>
<p>The training of a Boltzmann machines can also be viewed as an application of the <a href="../../../e/m/_/EM_algorithm_e5b1.html" title="EM algorithm">EM algorithm</a>, which is heavily used in <a href="../../../m/a/c/Machine_learning.html" title="Machine learning">machine learning</a>. We are given an incomplete dataset (we only know the values of the visible units). At the positive phase, we estimate the completed data based on the current parameters of the system (the weights). Later, the weights are updated to maximize the probability of the network producing the completed data.</p>
<p><a name="Problems" id="Problems"></a></p>
<h2><span class="editsection">[<a href="../../../b/o/l/Boltzmann_machine.html" title="Edit section: Problems">edit</a>]</span> <span class="mw-headline">Problems</span></h2>
<p>If it worked, the Boltzmann machine would be a sort of universal computational medium, able to solve nearly any learning problem. For instance, if trained on photographs, the machine would model the distribution of photographs, and could use that model to, for example, complete a partial photograph.</p>
<p>Unfortunately, there is a serious practical problem with the Boltzmann machine, namely that the learning seems to stop working correctly when the machine is scaled up to anything larger than a trivial machine. This is due to a number of effects, the most important of which are:</p>
<ul>
<li>the time the machine must be run for in order to collect equilibrium statistics grows exponentially with the machine's size, and with the magnitude of the connection strengths</li>
<li>connection strengths are more plastic when the units being connected have activation probabilities intermediate between zero and one, leading to a so-called variance trap. The net effect is that noise causes the connection strengths to random walk until the activities saturate.</li>
</ul>
<p><a name="History" id="History"></a></p>
<h2><span class="editsection">[<a href="../../../b/o/l/Boltzmann_machine.html" title="Edit section: History">edit</a>]</span> <span class="mw-headline">History</span></h2>
<p>The Boltzmann machine is a <a href="../../../m/o/n/Monte_Carlo_method_ff34.html" title="Monte Carlo method">Monte Carlo</a> version of the <a href="../../../h/o/p/Hopfield_net.html" title="Hopfield net">Hopfield network</a>.</p>
<p>The idea of using annealed <a href="../../../i/s/i/Ising_model.html" title="Ising model">Ising models</a> for inference is often thought to have originated from Geoff Hinton. However some claim that an earlier version of the same idea is present in <a href="../../../d/o/u/Douglas_Hofstadter_9e14.html" title="Douglas Hofstadter">Douglas Hofstadter</a>'s <a href="../../../c/o/p/Copycat_%28software%29.html" title="Copycat (software)">Copycat</a> project, described in the following two papers:</p>
<ul>
<li>Hofstadter, Douglas R., The Copycat Project: An Experiment in Nondeterminism and Creative Analogies. MIT Artificial Intelligence Laboratory Memo No. 755, January 1984.</li>
</ul>
<ul>
<li>Hofstadter, Douglas R., A Non-Deterministic Approach to Analogy, Involving the Ising Model of Ferromagnetism. In E. Caianiello, ed. The Physics of Cognitive Processes. Teaneck, NJ: World Scientific, 1987.</li>
</ul>
<p>Others, without meaning to disparage Douglas Hofstadter's contributions to the field or any potential claims of independent discovery, contend that the following papers describe the idea and that 1983 is earlier than 1984:</p>
<ul>
<li>Geoffrey E. Hinton and Terrence J. Sejnowski, Analyzing Cooperative Computation. In Proceedings of the 5th Annual Congress of the Cognitive Science Society, Rochester, NY, May 1983.</li>
</ul>
<ul>
<li>Geoffrey E. Hinton and Terrence J. Sejnowski, Optimal Perceptual Inference. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR), pages 448-453, IEEE Computer Society, Washington DC, June 1983.</li>
</ul>
<p><a name="Restricted_Boltzmann_Machine" id="Restricted_Boltzmann_Machine"></a></p>
<h2><span class="editsection">[<a href="../../../b/o/l/Boltzmann_machine.html" title="Edit section: Restricted Boltzmann Machine">edit</a>]</span> <span class="mw-headline">Restricted Boltzmann Machine</span></h2>
<p>Although learning is impractical in general Boltzmann machines, it can be made quite efficient in an architecture called the "Restricted Boltzmann Machine" or "RBM" which does not allow connections between hidden units. After learning one RBM, the activities of its hidden units can be treated as data for training a higher-level RBM. This method of stacking RBM's makes it possible to learn many layers of hidden units efficiently and as each new layer is added the overall generative model gets better. Examples of multilayer RBM models of hand-written digits and faces can be viewed at <a href="http://www.cs.utoronto.ca/~hinton/" class="external free" title="http://www.cs.utoronto.ca/~hinton/" rel="nofollow">http://www.cs.utoronto.ca/~hinton/</a></p>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="../../../b/o/l/Boltzmann_machine.html" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li>Ackley, D. H., Hinton, G. E., Sejnowski, T. J. (1985) A Learning Algorithm for Boltzmann Machines, Cognitive Science, 9:147-169.</li>
</ul>
<ul>
<li>Hinton, G. E., Sejnowski, T. J. (1986) Learning and Relearning in Boltzmann Machines. In D. E. Rumelhart, J. L. McClelland, and the PDP Research Group, <i>Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations</i>. (pp 282-317) Cambridge: MIT Press</li>
</ul>
<ul>
<li>Hinton, G. E.(2002) Training Products of Experts by Minimizing Contrastive Divergence. Neural Computation, 14:1771-1800.</li>
</ul>
<ul>
<li>Hinton, G. E., Osindero, S. and Teh, Y. (2006) A fast learning algorithm for deep belief nets. Neural Computation, 18:1527-1554.</li>
</ul>

<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org../../../b/o/l/Boltzmann_machine.html">http://en.wikipedia.org../../../b/o/l/Boltzmann_machine.html</a>"</div>
	    <div id="catlinks"><p class='catlinks'><a href="../../../c/a/t/Special%7ECategories_101d.html" title="Special:Categories">Category</a>: <span dir='ltr'><a href="../../../n/e/u/Category%7ENeural_networks_dfe5.html" title="Category:Neural networks">Neural networks</a></span></p></div>	    <!-- end content -->
	    <div class="visualClear"></div>
	  </div>
	</div>
      </div>
      <div id="column-one">
	<div id="p-cactions" class="portlet">
	  <h5>Views</h5>
	  <ul>
	    <li id="ca-nstab-main"
	       class="selected"	       ><a href="../../../b/o/l/Boltzmann_machine.html">Article</a></li><li id="ca-talk"
	       	       ><a href="../../../b/o/l/Talk%7EBoltzmann_machine_46b0.html">Discussion</a></li><li id="ca-current"
	       	       ><a href="http://en.wikipedia.org/wiki/Boltzmann_machine">Current revision</a></li>	  </ul>
	</div>
	<div class="portlet" id="p-logo">
	  <a style="background-image: url(../../../images/wiki-en.png);"
	    href="../../../index.html"
	    title="Main Page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
	  <h5>Navigation</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-Main-page"><a href="../../../index.html">Main page</a></li>
	     	      <li id="n-Contents"><a href="../../../c/o/n/Wikipedia%7EContents_3181.html">Contents</a></li>
	     	      <li id="n-Featured-content"><a href="../../../f/e/a/Wikipedia%7EFeatured_content_24ba.html">Featured content</a></li>
	     	      <li id="n-currentevents"><a href="../../../c/u/r/Portal%7ECurrent_events_bb60.html">Current events</a></li>
	     	    </ul>
	  </div>
	</div>
		<div class='portlet' id='p-interaction'>
	  <h5>interaction</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-About-Wikipedia"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html">About Wikipedia</a></li>
	     	      <li id="n-portal"><a href="../../../c/o/m/Wikipedia%7ECommunity_Portal_6a3c.html">Community portal</a></li>
	     	      <li id="n-contact"><a href="../../../c/o/n/Wikipedia%7EContact_us_afd6.html">Contact us</a></li>
	     	      <li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising">Make a donation</a></li>
	     	      <li id="n-help"><a href="../../../c/o/n/Help%7EContents_22de.html">Help</a></li>
	     	    </ul>
	  </div>
	</div>
		<div id="p-search" class="portlet">
	  <h5><label for="searchInput">Search</label></h5>
	  <div id="searchBody" class="pBody">
	    <form action="javascript:goToStatic(3)" id="searchform"><div>
	      <input id="searchInput" name="search" type="text"
	        accesskey="f" value="" />
	      <input type='submit' name="go" class="searchButton" id="searchGoButton"
	        value="Go" />
	    </div></form>
	  </div>
	</div>
	      </div><!-- end of the left (by default at least) column -->
      <div class="visualClear"></div>
      <div id="footer">
    <div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../../../skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>	<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="../../../images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>	<ul id="f-list">
	  	  	  <li id="f-credits">This page was last modified 12:48, 2 April 2007 by Wikipedia user <a href="../../../m/i/s/User%7EMisterSheik_b43e.html" title="User:MisterSheik">MisterSheik</a>. Based on work by Wikipedia user(s) <a href="../../../d/i/o/User%7EDiomidis_Spinellis_7ad8.html" title="User:Diomidis Spinellis">Diomidis Spinellis</a>, <a href="../../../p/e/t/User%7EPeterdjones_56ec.html" title="User:Peterdjones">Peterdjones</a>, Octopod, Stootoon, <a href="../../../b/a/r/User%7EBarak_2a23.html" title="User:Barak">Barak</a>, <a href="../../../d/i/g/User%7EDigfarenough_0902.html" title="User:Digfarenough">Digfarenough</a>, <a href="../../../a/l/e/User%7EAlexDitto_f62e.html" title="User:AlexDitto">AlexDitto</a>, <a href="../../../p/l/a/User%7EPlanktonbot_0c80.html" title="User:Planktonbot">Planktonbot</a>, <a href="../../../g/a/i/User%7EGaius_Cornelius_c35a.html" title="User:Gaius Cornelius">Gaius Cornelius</a>, <a href="../../../t/h/a/User%7EThat_Guy%2C_From_That_Show%21_4388.html" title="User:That Guy, From That Show!">That Guy, From That Show!</a>, <a href="../../../r/o/r/User%7ERory096_e5c4.html" title="User:Rory096">Rory096</a>, <a href="../../../r/u/s/User%7ERussBot_6f95.html" title="User:RussBot">RussBot</a>, <a href="../../../p/a/k/User%7EPak21_529c.html" title="User:Pak21">Pak21</a>, <a href="../../../f/a/l/User%7EFalsifian_bc6d.html" title="User:Falsifian">Falsifian</a>, <a href="../../../n/o/t/User%7ENotjim_b8cf.html" title="User:Notjim">Notjim</a>, <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a>, <a href="../../../k/i/e/User%7EKieff_55f7.html" title="User:Kieff">Kieff</a>, <a href="../../../a/n/t/User%7EAntaeus_Feldspar_9a66.html" title="User:Antaeus Feldspar">Antaeus Feldspar</a> and <a href="../../../t/y/r/User%7ETyrell_turing_3e8b.html" title="User:Tyrell turing">Tyrell turing</a> and Anonymous user(s) of Wikipedia.</li>	  <li id="f-copyright">All text is available under the terms of the <a class='internal' href="../../../t/e/x/Wikipedia%7EText_of_the_GNU_Free_Documentation_License_702a.html" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="../../../c/o/p/Wikipedia%7ECopyrights_92c4.html" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a US-registered <a class='internal' href="../../../5/0/1/501%28c%29.html#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="../../../n/o/n/Non-profit_organization.html" title="Non-profit organization">nonprofit</a> <a href="../../../c/h/a/Charitable_organization.html" title="Charitable organization">charity</a>.<br /></li>	  <li id="f-about"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html" title="Wikipedia:About">About Wikipedia</a></li>	  <li id="f-disclaimer"><a href="../../../g/e/n/Wikipedia%7EGeneral_disclaimer_3e44.html" title="Wikipedia:General disclaimer">Disclaimers</a></li>	  	</ul>
      </div>
    </div>
  </body>
</html>
