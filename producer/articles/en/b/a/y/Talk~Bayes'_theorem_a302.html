<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    		<meta name="keywords" content="Talk:Bayes' theorem,Allele,Bayes' Theorem,Bayes' theorem,Bayesian inference,Conditional probability,Decision theory,Genotype,Hardy-Weinberg equilibrium,Heterozygous,Homozygous" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (English)" />
		<link rel="copyright" href="../../../COPYING.html" />
    <title>Talk:Bayes' theorem - Wikipedia, the free encyclopedia</title>
    <style type="text/css">/*<![CDATA[*/ @import "../../../skins/htmldump/main.css"; /*]]>*/</style>
    <link rel="stylesheet" type="text/css" media="print" href="../../../skins/common/commonPrint.css" />
    <!--[if lt IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE50Fixes.css";</style><![endif]-->
    <!--[if IE 5.5000]><style type="text/css">@import "../../../skins/monobook/IE55Fixes.css";</style><![endif]-->
    <!--[if IE 6]><style type="text/css">@import "../../../skins/monobook/IE60Fixes.css";</style><![endif]-->
    <!--[if IE]><script type="text/javascript" src="../../../skins/common/IEFixes.js"></script>
    <meta http-equiv="imagetoolbar" content="no" /><![endif]-->
    <script type="text/javascript" src="../../../skins/common/wikibits.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/md5.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/utf8.js"></script>
    <script type="text/javascript" src="../../../skins/htmldump/lookup.js"></script>
    <script type="text/javascript" src="../../../raw/gen.js"></script>        <style type="text/css">/*<![CDATA[*/
@import "../../../raw/MediaWiki%7ECommon.css";
@import "../../../raw/MediaWiki%7EMonobook.css";
@import "../../../raw/gen.css";
/*]]>*/</style>          </head>
  <body
    class="ns-1">
    <div id="globalWrapper">
      <div id="column-content">
	<div id="content">
	  <a name="top" id="contentTop"></a>
	        <h1 class="firstHeading">Talk:Bayes' theorem</h1>
	  <div id="bodyContent">
	    <h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
	    <div id="contentSub"></div>
	    	    <div class="usermessage">You have <a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">new messages</a> (<a href="../../../1/2/7/User_talk%7E127.0.0.1.html" title="User talk:127.0.0.1">last change</a>).</div>	    <!-- start content -->
	    <ul>
<li><a href="../../../b/a/y/Talk%7EBayes%27_theorem_Archive_1_c9dd.html" title="Talk:Bayes' theorem/Archive 1">/Archive 1</a>, ending October 2005, created 18:32, 5 December 2005 (UTC)</li>
</ul>
<p><br /></p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Plagiarism"><span class="tocnumber">1</span> <span class="toctext">Plagiarism</span></a>
<ul>
<li class="toclevel-2"><a href="#Example_.231:_False_positives_in_a_medical_test"><span class="tocnumber">1.1</span> <span class="toctext">Example #1: False positives in a medical test</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#The_Statement_of_Bayes.27_Theorem"><span class="tocnumber">2</span> <span class="toctext">The Statement of Bayes' Theorem</span></a></li>
<li class="toclevel-1"><a href="#.22Nontechnical_explanation.22_and_cookies_example"><span class="tocnumber">3</span> <span class="toctext">"Nontechnical explanation" and cookies example</span></a></li>
<li class="toclevel-1"><a href="#Non-technical_explanation"><span class="tocnumber">4</span> <span class="toctext">Non-technical explanation</span></a></li>
<li class="toclevel-1"><a href="#Cookies_example_revisited"><span class="tocnumber">5</span> <span class="toctext">Cookies example revisited</span></a>
<ul>
<li class="toclevel-2"><a href="#Cutting_the_cookies"><span class="tocnumber">5.1</span> <span class="toctext">Cutting the cookies</span></a></li>
<li class="toclevel-2"><a href="#The_main_point_of_the_Medical_Example"><span class="tocnumber">5.2</span> <span class="toctext">The main point of the Medical Example</span></a></li>
<li class="toclevel-2"><a href="#Cookies_are_contrived"><span class="tocnumber">5.3</span> <span class="toctext">Cookies are contrived</span></a></li>
<li class="toclevel-2"><a href="#Arguments"><span class="tocnumber">5.4</span> <span class="toctext">Arguments</span></a></li>
<li class="toclevel-2"><a href="#More_Arguments"><span class="tocnumber">5.5</span> <span class="toctext">More Arguments</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Using_actual_data_in_the_medical_example"><span class="tocnumber">6</span> <span class="toctext">Using actual data in the medical example</span></a></li>
<li class="toclevel-1"><a href="#Text_of_the_Cookies_Example"><span class="tocnumber">7</span> <span class="toctext">Text of the Cookies Example</span></a>
<ul>
<li class="toclevel-2"><a href="#Example_.231:__Conditional_probabilities"><span class="tocnumber">7.1</span> <span class="toctext">Example #1: Conditional probabilities</span></a>
<ul>
<li class="toclevel-3"><a href="#Tables_of_occurences_and_relative_frequencies"><span class="tocnumber">7.1.1</span> <span class="toctext">Tables of occurences and relative frequencies</span></a>
<ul>
<li class="toclevel-4"><a href="#Another_poor_teaching_example"><span class="tocnumber">7.1.1.1</span> <span class="toctext">Another poor teaching example</span></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1"><a href="#Muggles_and_witches"><span class="tocnumber">8</span> <span class="toctext">Muggles and witches</span></a></li>
<li class="toclevel-1"><a href="#A_surprising_example"><span class="tocnumber">9</span> <span class="toctext">A surprising example</span></a></li>
<li class="toclevel-1"><a href="#No.2C_you_don.27t_need_non-zero_probabilities_to_have_well-defined_conditionals"><span class="tocnumber">10</span> <span class="toctext">No, you don't need non-zero probabilities to have well-defined conditionals</span></a>
<ul>
<li class="toclevel-2"><a href="#Bottom-line"><span class="tocnumber">10.1</span> <span class="toctext">Bottom-line</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Good_example_of_a_flame-out"><span class="tocnumber">11</span> <span class="toctext">Good example of a flame-out</span></a></li>
<li class="toclevel-1"><a href="#Simplified_explanation_on_top.3F"><span class="tocnumber">12</span> <span class="toctext">Simplified explanation on top?</span></a></li>
<li class="toclevel-1"><a href="#Possible_plagarism"><span class="tocnumber">13</span> <span class="toctext">Possible plagarism</span></a></li>
<li class="toclevel-1"><a href="#Bayes_theorem_requires_a_key_assumption"><span class="tocnumber">14</span> <span class="toctext">Bayes theorem requires a key assumption</span></a></li>
<li class="toclevel-1"><a href="#Ludicrously_overtechnical_and_hard_to_read"><span class="tocnumber">15</span> <span class="toctext">Ludicrously overtechnical and hard to read</span></a></li>
<li class="toclevel-1"><a href="#Innumeracy"><span class="tocnumber">16</span> <span class="toctext">Innumeracy</span></a></li>
<li class="toclevel-1"><a href="#Definition_of_Likelihood"><span class="tocnumber">17</span> <span class="toctext">Definition of Likelihood</span></a></li>
<li class="toclevel-1"><a href="#Medical_test"><span class="tocnumber">18</span> <span class="toctext">Medical test</span></a></li>
<li class="toclevel-1"><a href="#Graphical_explanation"><span class="tocnumber">19</span> <span class="toctext">Graphical explanation</span></a></li>
<li class="toclevel-1"><a href="#Wording_of_the_question"><span class="tocnumber">20</span> <span class="toctext">Wording of the question</span></a></li>
<li class="toclevel-1"><a href="#Reworking_the_equation"><span class="tocnumber">21</span> <span class="toctext">Reworking the equation</span></a></li>
<li class="toclevel-1"><a href="#Bayes.27_theorem_or_Bayes.27s_theorem.3F"><span class="tocnumber">22</span> <span class="toctext">Bayes' theorem or Bayes's theorem?</span></a></li>
<li class="toclevel-1"><a href="#Obvious_CONTRADICTION_in_the_theorem_itself"><span class="tocnumber">23</span> <span class="toctext">Obvious CONTRADICTION in the theorem itself</span></a></li>
</ul>
</td>
</tr>
</table>
<p><script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script><a name="Plagiarism" id="Plagiarism"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Plagiarism">edit</a>]</span> <span class="mw-headline">Plagiarism</span></h2>
<p>The medical test emaple (Example I) seems to be plagiarized from Sheldon Ross's "A First Course in Probability". Thank you.</p>
<p><a name="Example_.231:_False_positives_in_a_medical_test" id="Example_.231:_False_positives_in_a_medical_test"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Example #1: False positives in a medical test">edit</a>]</span> <span class="mw-headline">Example #1: False positives in a medical test</span></h3>
<p>Suppose that a test for a particular disease has a very high success rate:</p>
<ul>
<li>if a tested patient has the disease, the test accurately reports this, a 'positive', 99% of the time (or, with probability 0.99), and</li>
<li>if a tested patient does not have the disease, the test accurately reports that, a 'negative', 95% of the time (<i>i.e.</i> with probability 0.95).</li>
</ul>
<p>Suppose also, however, that only 0.1% of the population have that disease (<i>i.e.</i> with probability 0.001). We now have all the information required to use Bayes's theorem to calculate the probability that, given the test was positive, that it is a false positive. This problem is discussed at greater length in <a href="../../../b/a/y/Bayesian_inference.html" title="Bayesian inference">Bayesian inference</a>.</p>
<p>Let <i>D</i> be the event that the patient has the disease, and <i>T</i> be the event that the test returns a positive result. Then, using the second alternative form of Bayes' theorem (<a href="#Alternative_forms_of_Bayes.27_theorem" title="">above</a>), the probability of a positive is</p>
<dl>
<dd><img class='tex' src="../../../math/8/8/e/88ef363a5b30cb47d9aa611020f14b69.png" alt="P(T) = P(T|D)\,P(D) + P(T|D^C)\,P(D^C) \!" /></dd>
</dl>
<p>P(T) is the probability that a given person tests positive. This depends on the two populations: those with the disease (and correctly test positive 0.99 x 0.001) and those without the disease (and incorrectly test positive 0.05 x 0.999). The probability that a person has the disease, given that the patient tested positive, is determined by dividing the probability for a true positive result by the probabilty of any positive result, which is the sum of the probabilities for a true positive and a false positive:</p>
<dl>
<dd><img class='tex' src="../../../math/1/5/6/156759fe4692e10eef98250e4e64b650.png" alt="P(disease|test+) = \frac{P(test+|disease)\,P(disease)}{P(test+|disease)\,P(disease) + P(test+|NO disease)\,P(NOdisease)} \!" /></dd>
</dl>
<p><br /></p>
<dl>
<dd><img class='tex' src="../../../math/8/6/e/86ed986f0e5f6b7f379ea9c27dbe6a85.png" alt="P(D|T) = \frac{P(T|D)\,P(D)}{P(T|D)\,P(D) + P(T|D^C)\,P(D^C)} \!" /></dd>
</dl>
<p><br /></p>
<dl>
<dd><img class='tex' src="../../../math/a/9/5/a9581801bb201499a2835b47b5121266.png" alt="P(D|T) = \frac{0.99\times 0.001}{0.99 \times 0.001 + 0.05\times 0.999}  = 11/566 \approx 0.019, \!" /></dd>
</dl>
<p>and hence the probability that a positive result is a <a href="../../../t/y/p/Type_I_and_type_II_errors_c67e.html" title="Type I and type II errors">false positive</a> is about (1 − 0.019) = 0.981.</p>
<p>Despite the apparent high accuracy of the test, the incidence of the disease is so low (one in a thousand) that the vast majority of patients who test positive (98 in a hundred) do not have the disease. It should be noted that this is quite common in screening tests. In many or most cases it is more important to have a very low false negative rate than a high true positive rate. Another strategy to deal with this problem is to try to screen a selected population in which the prevalence of the disease is higher. For example it would be senseless to screen to the whole population for cancer (extremely costly and invasive tests) which would result in an enourmous amount of false positives as is shown above. On the other hand if you select a part of the population (i.e. those who have lost 10% of their weight in the last couple of months without having gone on a diet) the prevalence of cancer is higher and the probability of a false positive will be lower. The higher the number of characteristics your look for before you apply the test (this raises the pre-test probability, or simply put, the prevalence) the more acurate your test will be.</p>
<p><a name="The_Statement_of_Bayes.27_Theorem" id="The_Statement_of_Bayes.27_Theorem"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: The Statement of Bayes' Theorem">edit</a>]</span> <span class="mw-headline">The Statement of Bayes' Theorem</span></h2>
<p>The Statement of Bayes' Theorem section is correct but confusing. I had to re-read this section several times before I remembered from graduate school that "likelihood" has a counter-intuitive technical definition. To the average math-oriented reader, you can't just pop P(A|B) = L(B|A) and not explain that <i>likelihood</i> is an <i>unfortunate technical phrase</i>. Most non-statisticians would not equate "Probability of A | B" with "Likelihood of B | A". If someone doesn't already know Bayes' theorem (reason they're reading the article), they probably don't know what statisticians mean when they say "likelihood function" either. I'd suggest eliminating everything about likelihood functions entirely from this section and just stick with probabilities-oriented terms.--<a href="../../../t/o/m/User%7EToms2866_7e19.html" title="User:Toms2866">Toms2866</a> 13:06, 28 March 2006 (UTC)</p>
<p><a name=".22Nontechnical_explanation.22_and_cookies_example"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: &quot;Nontechnical explanation&quot; and cookies example">edit</a>]</span> <span class="mw-headline">"Nontechnical explanation" and cookies example</span></h2>
<p>Hello. I've cut the "nontechnical explanation" and the cookies example for the following reasons. (1) "Nontechnical explanation" is mistaken. Bayes' theorem isn't limited to observable physical events, as suggested by the repeated use of the word "occurring". The author has been misled by the suggestive term "event". (2) The verbiage about the term likelihood is void of meaning: <i>This measure is sometimes called the likelihood, since it is the likelihood of A occurring given that B occurred. It is important not to confuse the likelihood of A given B and the probability of A given B. Even though both notions may seem similar and are related, they are quite different.</i> Uh huh. (3) Descriptions of each term P(A), P(B), etc are covered elsewhere in the article. (4) P(A), P(B), etc are called "measures" in the "nontechnical explanation" but they're not; I suppose the author intended "quantities". (5) The description of P(B) is mistaken: <i>This measure is sometimes called the normalising constant, since it will always be the same, regardless of which event A one is studying.</i> No, it is not called a normalizing constant because it is always the same. (6) The cookies example doesn't illustrate anything interesting. (7) The cookies example already appears on the <a href="../../../b/a/y/Bayesian_inference.html" title="Bayesian inference">Bayesian inference</a> page. -- The article needs work, and it can be improved, but not pasting random stuff into it. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 07:17, 28 November 2005 (UTC)</p>
<dl>
<dd>I agree with some of the points that you raise, but I also believe that there was some good information in the "non-technical" section that you removed. Furthermore, I believe that many math-related articles on Wikipedia, this one included, tend to start immediately with highly technical explanations that only Ph.D. mathematicians can understand. Yes, the articles do need to include the formal mathematical definitions, but I believe that it would be helpful to begin each article with a simple, non-technical explanation that is accessible to the more general reader. Most of these math-related articles have important applications well beyond mathematics -- including physics, chemistry, biology, engineering, economics, finance, accounting, manufacturing, forensics, medecine, etc. You need to consider your audience when you write articles for Wikipedia. The audience is far broader than the population of Ph.D. mathematicians. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 14:37, 28 November 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>One other point: in my opinion, it is <b>not</b> a good idea in general for articles to point out that they are starting with a non-technical explanation, and that the full technical discussion will come later, as this article originally did. It is better simply to start with simple, non-technical descriptions and then smoothly to transition to the more formal, technical discussion. Sophisticated readers will know immediately that they can skim over the non-technical parts, and read the more advanced section in greater detail. Non-sophisticated readers will appreciate that you have tried to take them by the hand and bring them to a deeper level of understanding. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 14:50, 28 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Hi, I wrote the non-technical explanation, so I'll chip in with my thoughts. First, the reason I wrote it is that this article is too technical. If you check back the history before I first added the section, you'll see there was a "too technical, please simplify" warning on the page. Hell, I'm a computer engineer, I use Bayes' theorem every day, and even I couldn't figure out what the page was talking about. People who don't have a strong (grad level) mathematical background will be completely lost on this page. There is a definite, undeniable need for a simpler, non-technical explaination of Bayes' Theorem.</dd>
<dd>That said, the vision I had for the non-technical explaination was for it to be a stand-alone text. The technical explaination seemed complete and coherent, if too advanced for regular readers, so I did not want to mess around with it. I thought it would be both simpler and better to instead begin the page with a complete non-technical text, which regular readers could limit themselves too while advanced readers could skip completely to get to the more technical stuff. That is why, as Heresiarch pointed out, the definitions of Pr(A), Pr(B) etc. are there twice.</dd>
<dd>So I vote that we restore the non-technical explaination. Heresiarch, if you have a problem with some terms used, such as "occur" or "measure", you should correct those terms, not delete the entire section. But keep in mind when doing those corrections that the people who'll be reading it will have little to no formal background in mathematics – keep it sweet and simple! -- <a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 15:11, 28 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I think there is room for a compromise solution that will make everyone happy <i>and</i> improve the article substantially. Basically, I think Ritchy is correct, the non-technical explanation needs to go back in at the beginning, but it needs to be cleaned up a bit and the transitions need to be a bit smoother. The truth is, the so-called non-technical discussion is not even all that simplified -- it happens to be pretty well written and provides a very good introduction to the topic. Again, I think it just needs a bit of cleaning-up, and it needs to be <i>woven</i> into the article more smoothly. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 15:54, 28 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>As a first step, I have added the simple "cookies" example back, but this time I grouped it with the other example in a single section entitled "Examples." Each example has its own sub-section with its own header. I think it improves the flow of articles when you put all of the examples together in a single section, and begin with simple examples before proceeding to more complicated ones. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 16:11, 28 November 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>The next step is to figure out a way to weave the non-technical explanation back in near the beginning of the article without sounding too repetitious and with smooth transitions. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 16:11, 28 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>I am not opposed to some remarks that are less technical. I am opposed to restoring the section "Non-technical explanation", as it was seriously flawed. If you want to write something else, go ahead, but please don't just restore the previous "Non-technical explanation". Please bear in mind that just making the article longer doesn't necessarily make it any clearer. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 02:22, 29 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Actually, I think it is pretty good as written. You say that it is "seriously flawed." I am confused: what are your specific objections or concerns? -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 03:36, 29 November 2005 (UTC)
<dl>
<dd>See items (1) through (5) above under <i>"Nontechnical explanation" and cookies example</i>. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 07:04, 29 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I have pasted a copy of the text below for reference. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 04:03, 29 November 2005 (UTC)
<dl>
<dd>I have edited the "Nontechnical explanation" according to the critics (1) and (4). (2) and (3) are meaningless – it seems Heresiarch just doesn't like things explained too clearly to people who don't know math. (5) seems to be a misunderstanding. Pr(B) is the probability of B, regardless of A. Meaning, if we're computing Pr(A|B), or Pr(C|B), or Pr(D|B), the term Pr(B) will always be the same. That's what I meant by "it will always be the same, regardless of which event A one is studying." If the statement isn't clear enough, I'm open to ideas on how to improve it. -- <a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 20:10, 29 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p><a name="Non-technical_explanation" id="Non-technical_explanation"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Non-technical explanation">edit</a>]</span> <span class="mw-headline">Non-technical explanation</span></h2>
<p>Simply put, Bayes’ theorem gives the probability of a random event <i>A</i> given that we know the probability of a related event <i>B</i> occurred. This probability is noted Pr(<i>A</i>|<i>B</i>), and is read "probability of <i>A</i> given <i>B</i>". This quantity is sometimes called the "posterior", since it is computed after all other information on <i>A</i> and <i>B</i> is known.</p>
<p>According to Bayes’ theorem, the probability of <i>A</i> given <i>B</i> will be dependent on three things:</p>
<ul>
<li>The probability of <i>A</i> on its own, regardless of <i>B</i>. This is noted Pr(<i>A</i>) and read "probability of <i>A</i>". This quantity is sometimes called the "prior", meaning it precedes any other information – as opposed to the posterior, defined above, which is computed after all other information is known.</li>
<li>The probability of <i>B</i> on its own, regardless of <i>A</i>. This is noted Pr(<i>B</i>) and read "probability of <i>B</i>". This quantity is sometimes called the normalising constant, since it will always be the same, regardless of which event <i>A</i> one is studying.</li>
<li>The probability of <i>B</i> given the probability of <i>A</i>. This is noted Pr(<i>B</i>|<i>A</i>) and is read "probability of <i>B</i> given <i>A</i>". This quantity is sometimes called the likelihood, since it is the <a href="../../../l/i/k/Likelihood_function.html" title="Likelihood function">likelihood</a> of <i>A</i> given <i>B</i>. It is important not to confuse the likelihood of <i>A</i> given <i>B</i> and the probability of <i>A</i> given <i>B</i>. Even though both notions may seem similar and are related, they are quite different.</li>
</ul>
<p>Given these three quantities, the probability of <i>A</i> given <i>B</i> can be computed as</p>
<dl>
<dd><img class='tex' src="../../../math/2/2/6/226c9c8b7b9cfc9cdc8561b0876623d7.png" alt="\Pr(A|B) = \frac{\Pr(B | A) \Pr(A)}{\Pr(B)}." /></dd>
</dl>
<p><a name="Cookies_example_revisited" id="Cookies_example_revisited"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Cookies example revisited">edit</a>]</span> <span class="mw-headline">Cookies example revisited</span></h2>
<p>The continued expansion of the cookies example isn't improving it. The medical test example, presently in <a href="../../../b/a/y/Bayesian_inference.html" title="Bayesian inference">Bayesian inference</a>, is no more complicated, and much more compelling. The medical test, incidentally, is a standard example of the application of Bayes' theorem. I'm going to cut the cookies and copy the medical test unless someone can talk me out of it. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 15:59, 29 November 2005 (UTC)</p>
<dl>
<dd>I totally disagree. The cookies example, although rather simple, provides a tangible example of the relationship between conditional probabilities and Bayes' thoerem. Actually, one of its virtues is the fact that it is such a simple example. If you don't find it interesting, you <i>don't have to read it</i>. If you are so advanced in your understanding of Bayes' theorem that this example is trivial <i>for you</i>, then you <i>don't have to read it</i>. Not all readers of Wikipedia are as smart as you are. What is the harm in leaving it in the article? -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 16:36, 29 November 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>The medical test example is essentially the same as the cookies: bowl 1 = people with disease, bowl 2 = people without, plain = negative test, chocolate chip = positive; Fred has a plain cookie, which bowl is it from = Fred tests negative, does he have the disease. If the cookies example is simple, then so is the medical test, and the latter has the advantage that people (even ordinary readers) truly care about such problems. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 23:21, 29 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>Furthermore, although the medical example is interesting, it is confusing and too advanced for a first example meant to introduce basic concepts. Again, the audience that we are writing for is <b>not</b> Ph.D. mathematicians; the audience is a general audience that includes people who do <b>not</b> have the same background that you do. The goal is to explain the concepts, not to show how smart you are by throwing around a lot of techno mumbo-jumbo that no one understands except the elite few. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 16:42, 29 November 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>That's a nice strawman you have there. If you bothered to check the discussions above, you would see that I've argued against including measure-theoretic stuff (which, I believe, counts as "technical mumbo-jumbo"). More recently, I revised the introduction to remove the technical stuff and make it entirely verbal. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 23:21, 29 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Good. I am glad you agree. BTW, I think the revisions that you made recently to the introduction are excellent. I realize that most people above the age of 12 don't care much about bowls of cookies. Nevertheless, I think it illustrates the concepts very well and in a very straightforward way. Finally, I think the term I used was "techno mumbo-jumbo," not "technical mumbo-jumbo". &#160;;-) -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 04:32, 30 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>One more thing: if any of the examples in this article should be removed, it is <b>Example #2</b> on Bayesian inference and <i>not</i> the cookies example. I have a pretty strong background in math, and I don't have the first clue what this example is all about. What benefit does it provide other than to confuse the reader? -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 16:49, 29 November 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Agreed. In fact I've argued the same point (item 3 in my edit of July 11, 2004, at the top of the page). <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 23:21, 29 November 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p>I agree with Metacomet. The cookie example is clear and relates to a simple tangible situation. Everyone can easily imagine drawing cookies from a bowl. This makes it an excellent medium to explain Bayes' Theorem. The example is complete, and clearly and accurately illustrates the Theorem. It is explained in plain and simple terms, so that anyone can understand it. Furthermore, it does not require any background knowledge from the reader in any other domain, and does not needlessly take on another topic like medicine or polling, something that only serves to confuse readers. I see no reasons to cut it; quite the opposite, it is the perfect example for the page and should definitly be kept. -- <a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 20:01, 29 November 2005 (UTC)</p>
<p><a name="Cutting_the_cookies" id="Cutting_the_cookies"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Cutting the cookies">edit</a>]</span> <span class="mw-headline">Cutting the cookies</span></h3>
<p>Why did the cookie example get cut? There was only one person who didn't like it, and the discussion here clearly highlighted why it was necessary to keep it. You can't possibly think that this medical example is simpler!</p>
<dl>
<dd>I didn't say that it is simpler; I said the medical test example is no more complex than the cookies example. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 00:11, 3 December 2005 (UTC)</dd>
</dl>
<p>The cookie example explained Bayes' Theorem much more clearly, and using a situation everyone is familiar with. Unless someone comes up with a good reason why it should be cut today, I'll restore it tomorrow. -- <a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 15:23, 2 December 2005 (UTC)</p>
<dl>
<dd>I'd like to know in what sense the cookies example is clearer. Try to steer away from repeated assertions of the conclusion this time. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 00:11, 3 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I agree 100 percent with Ritchy. The cookies example is far better than the medical example as a simple way to illustrate the basic concepts. I think it should be restored. I invite others to voice their opinions on this issue. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 21:32, 2 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p><a name="The_main_point_of_the_Medical_Example" id="The_main_point_of_the_Medical_Example"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: The main point of the Medical Example">edit</a>]</span> <span class="mw-headline">The main point of the Medical Example</span></h3>
<p>Read the medical example again. Do you know what the main point of this example is? It is <b>not</b> meant as an example to illustrate the fundamental concepts of Bayes' Theorem. The main purpose of the medical example as written is to illustrate an important and common fallacy in probability theory. As it turns out, Bayes' theorem is particulary useful as a way of uncovering this fallacy and demonstrating the <i>correct</i> inference. So if you accept my premise that we should use Example #1 as a means of illustrating the fundamental concepts, then you would conclude that the medical example is <b>not</b> the appropriate vehicle for that purpose. On the other hand, if you want to use the medical example, then it needs to be <i>completely</i> re-written so that it illustrates the basic concepts, and not as a device for discussing an incorrect logical inference that people commonly make.</p>
<p>I am not interested in re-writing the medical example, because the cookies example is perfectly fine as written, and it serves the desired purpose more than adequately.</p>
<p>Also, I am tired of this discussion. I have more important things to worry about. So I am done. Mr. Wily, please do whatever you want. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 06:36, 3 December 2005 (UTC)</p>
<dl>
<dd>You know, it is truly remarkable. I just compared the medical example that you added to this article with the original medical example as it appears in the <a href="../../../b/a/y/Bayesian_inference.html" title="Bayesian inference">Bayesian inference</a> article. You ripped the guts right out of the example! So we are left with the <i>Readers Digest</i> abridged version, or if you perfer, the <i>Medical Example Lite</i>. No wonder it's so difficult to understand this example. There is no there there. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 06:55, 3 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>There is some discussion in the medical test example as it appears in <a href="../../../b/a/y/Bayesian_inference.html" title="Bayesian inference">Bayesian inference</a> which is related to issues that aren't relevant in <a href="../../../b/a/y/Bayes%27_theorem.html" title="Bayes' theorem">Bayes' theorem</a>, so I omitted that discussion. I carried over just what's needed to illustrate the machinery of Bayes' theorem. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 18:44, 3 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p><a name="Cookies_are_contrived" id="Cookies_are_contrived"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Cookies are contrived">edit</a>]</span> <span class="mw-headline">Cookies are contrived</span></h3>
<p>The question "from which bowl is the cookie" is entirely contrived, and that is the major difficulty with the cookie example. While cookies are familiar, the question posed is not, and that obscures the point of the example. On the other hand, the question "Does Fred or doesn't he have such and such a disease" is posed in real life in the same way as in the example; it doesn't take some kind of cognitive readjustment to comprehend it. You &amp; Ritchy may wish to consider why the medical test is a standard example of Bayes' theorem, while cookies are not. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 00:11, 3 December 2005 (UTC)</p>
<dl>
<dd>Of course the cookies example is contrived. It is meant as a bit of a tongue-in-cheek, overly-simplified, and slightly <i>whimsical</i> example. The idea is to make it simple enough to demonstrate the basic concepts of the theorem and the related definitions, but not deadly dull and boring. Lighten up! -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 06:16, 3 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>The medical test example is serious, but far from boring. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 18:40, 3 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>Like I said, lighten up. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 20:44, 3 December 2005 (UTC)</dd>
</dl>
<p><a name="Arguments" id="Arguments"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Arguments">edit</a>]</span> <span class="mw-headline">Arguments</span></h3>
<p>The arguments for the cookie example are all in the previous text, but as requested by Heresiarch, I will once again list them all for some reason.</p>
<ol>
<li>The example is complete, in the sense that it illustrates all the necessary steps to apply Bayes' Theorem.</li>
<li>The example is written in clear, non-technical English.</li>
<li>The example is limited to Bayes' Theorem, and doesn't try to address other issues such as medical testing or polling.</li>
<li>The example is simple, in that it doesn't require the user to have background knowledge of another field to be understood. Everyone knows what a cookie in a bowl is. Not everyone knows what a false-positive medical diagnostic is, or what binomial distributions are.</li>
<li>Wikipedia should be accessible to everyone, regardless of instruction level and academic background. Thus, simple examples using common household items such as cookies are very useful to explain advanced mathematical concepts such as Bayes' Theorem.</li>
<li>There has been so far no compelling reasons given to delete the cookie example. Making the page more complicated for the sake of making it more complicated doesn't count. The fact you don't like part of the phrase "from which bowl is the cookie" is a reason to fix that phrase, not to delete the entire example. The fact it's not a standard textbook example doesn't count, because Wikipedia is anything but a standard math textbook.</li>
</ol>
<p>And after all that, Metacomet beat me to the fun of restoring the example. Dammit. -- <a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 18:48, 4 December 2005 (UTC)</p>
<dl>
<dd>(1) and (2) apply as well to the medical test. (3) and (4) are true, but that's because the cookies example has zero motivation, while the medical test is strongly motivated. (5) is false; there are plenty of articles which are not accessible to everyone. That said, the medical test is just as comprehensible as the cookies. About (6), I've already spelled it out. In summary, the medical test example is no more complicated, and much more compelling. Incidentally, the fact that the medical test is a standard example of Bayes' theorem shows that many people (not just me) consider it a useful illustration. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 03:34, 5 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>(1) may apply to the medical test, but (2) does not. Even if it applied to both examples, it wouldn't on its own constitute a reason to delete one of them, much less a reason to delete the cookie example and keep the medical example. I'm glad you agree that (3) and (4) are true, because they're also very important. In regard to the cookie thing having "zero motivation", well I'll grant you that in real life, people don't care what bowl they took a cookie from, but that's besides the point. I think it's safe to assume that the motivation of someone reading the Wikipedia entry on Bayes' Theorem is to <i>learn about Bayes' Theorem</i>, and the cookie example fulfills this perfectly. And since you brought up the topic of motivation, what makes you think people reading about Bayes' theorem are also motivated to learn about medical diagnostics and polling? (5) is true. Wikipedia is meant to be accessible to everyone. <a href="../../../m/a/k/Wikipedia%7EMake_technical_articles_accessible_9f90.html" title="Wikipedia:Make technical articles accessible">It's one of the guidelines.</a> Allow me to quote: "Articles in Wikipedia should be <b>accessible to the widest possible audience</b>. For most articles, this means <b>accessible to a <i>general</i> audience</b>. <i>Every attempt</i> should be made to ensure that material is presented in the most widely accessible manner possible. If an article is written in a highly technical manner, but the material permits a more accessible explanation, then editors are strongly encouraged to rewrite it." The bolding and italics is from the Wikipedia guideline by the way, not from me. As for (6), I'll reiterate that I haven't seen a single good reason to remove the example. I'm sorry if you feel you've made the point clearly, but you haven't. Since we've gone through the trouble of giving you a clear numbered list of reasons to keep it, perhaps you'd care to return the favour? --<a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 03:55, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>And another thing. You (Heresiarch) keep going on and on about how the medical example is a standard textbook example of Bayes' Theorem. Do you actually mean you read it in a math textbook and copied it here? Because you're not allowed to do that. Books are protected by copyright laws (as someone of your unparalleled intelligence probably knows). You don’t have the right to just copy a page from it and post it on a free website for the world to see, unless you have a written legal authorisation to do so. If you just copied the example from a math textbook, we’ll have to delete it, no matter how great you think it is. --<a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 16:18, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p><a name="More_Arguments" id="More_Arguments"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: More Arguments">edit</a>]</span> <span class="mw-headline">More Arguments</span></h3>
<p>Ritchy -- I apologize for stealing your thunder. On the other hand, as they say, great minds think alike. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 18:54, 4 December 2005 (UTC)</p>
<p>Wily -- I agree 100 percent with the arguments made by Ritchy above. I would also reiterate some of the arguments that I have already mentioned in prior discussions:</p>
<ol>
<li>The cookies example is somewhat fun and whimsical. A little bit of humor every now and then is useful and entertaining.</li>
<li>The medical example is <b>not</b> a good example for illustrating the basic concepts related to Bayes' theorem because the main point of the medical example is to discuss a common logical fallacy in probability theory.</li>
</ol>
<p>-- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 18:55, 4 December 2005 (UTC)</p>
<dl>
<dd>The reason the cookies example is unhelpful is that each bowl has the same probability of being chosen. This means that somebody who thinks Bayes theroem in general might be <img class='tex' src="../../../math/f/f/d/ffdb2f32ea9663d324efbd0cf560b1fe.png" alt="\Pr(A|B) = \frac{\Pr(B | A) }{ \Pr(B | A) + \Pr(B | A^C) }" /> will get <img class='tex' src="../../../math/5/8/8/5886b27f9510a26004e3761f7a6db2ba.png" alt="\frac{0.75}{1.25} = 0.6" />, the right answer for the wrong reason. They then may think they understand, which they will not. So it is a poor example of the use of prior probabilities in Bayes's theorem. --<a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a> 02:55, 5 December 2005 (UTC)
<dl>
<dd>Good point. --<a href="../../../m/a/r/User%7EMarkSweep_b58d.html" title="User:MarkSweep">MarkSweep</a>&#160;<small><a href="../../../m/a/r/User_talk%7EMarkSweep_9d72.html" title="User talk:MarkSweep">(call me collect)</a></small> 04:04, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>I think the only people who might possibly be confused by this <i>red herring</i> you've cooked up are those who have <i>not</i> read this article. I think the article spells out the theorem, and the link to <a href="../../../c/o/n/Conditional_probability.html" title="Conditional probability">conditional probability</a> provides a very clear definition and explanation of the related concepts. Furthermore, the cookies example takes the reader by the hand and walks through the calculation.</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Your argument is equivalent to saying that we should not mention to people that two times two is four, because they might be confused by the fact that two to the second power is also four. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 04:53, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Actually it is the same as saying that 16/64 is a bad example for illustrating simplifying factions because some people might cancel the 6s to get 1<strike>6</strike>&#160;/&#160;<strike>6</strike>4&#160;=&#160;1/4. But uninformed some people do this. Another bad example would be calculating the derivative of <i>e</i><sup><i>x</i></sup> at <i>x</i>&#160;=&#160;<i>e</i> as some people would get <i>x</i>&#160;<i>e</i><sup><i>x</i>−1</sup>&#160;=&#160;<i>e</i><sup><i>e</i></sup>. --<a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a> 10:25, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>I'm with Metacomet here. Sure, there are other ways of mixing the numbers of the cookie example and getting the right answer. If we just provided the problem statement and the correct answer it would lead to confusion. But we don't. We give every step of the reasoning, and lay out the correct equation as <img class='tex' src="../../../math/e/8/8/e88e092cb83c6550acdeddaba93b5af5.png" alt="\Pr(A|B) = \frac{\Pr(B | A) \Pr(A)}{\Pr(B)} = \frac{0.75 \times 0.5}{0.625} = 0.6." />. I just don't see how anyone who reads the example could mess up the equation to the extent you described in your post. --<a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 16:26, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Agreed w/ Henrygb on this point. The medical test has interesting and relevant prior information; the cookies example doesn't. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 06:41, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>I'm sure I could mix and match the numbers of the medical example in a way to get the right answer in a completely wrong way, like MarkSweep did for the cookie example. The medical example isn't superior on that point. [snide remarks deleted] --<a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 16:26, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>The equal prior probabilities of the two bowls makes the cookies example susceptible to the error mentioned by Henrygb. The prior probabilities in the medical test example aren't equal. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 02:35, 6 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>For what it's worth, I've taught Bayesian inference to incoming Freshmen in the University of Texas' Plan II honors program five times. I find the students much more receptive to real examples (like the medical example) than to the artificial ones (like the cookie example, but I use chocolates). The "hook" is that people do get medical exams, and many of my students have personal experience, if not in their own life, then in the lives of close relatives. So my experience leads me to prefer the medical example to the cookie example.</p>
<p>I do <i>not</i> agree that "the main point of the medical example is to discuss a common logical fallacy in probability theory." That's not how I use it. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 18:16, 5 December 2005 (UTC)</p>
<dl>
<dd>
<dl>
<dd>For the record, I was talking about the medical example as it is written here in Wikipedia (refer to the article), and <i>not</i> the medical example as a general class of examples. As I have said, in order to use the medical example as a simple illustration of the basic concepts of conditional probability and Bayes' Theorem, I believe that it would need to be re-written with that purpose in mind. I still maintain, that in its current form, it is useful in illustrating the fallacy related to false positives, because that is what the writer has chosen to emphasize. Unfortunately, it does not, in my opinion, emphasize the basic calculations and definitions related to Bayes' Theorem. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 02:03, 6 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>For the record, I don't object to keeping both the cookie example and the medical example. While I personally prefer the cookie one, I recognise that the medical one also has merit, and both can be useful in helping people understand Bayes' Theorem. In fact, I'd consider it preferable to keep both examples; in my experience, there's no such thing as giving too many examples to illustrate a mathematical theorem. Most of the current debate stems from Heresiarch's fanatical devotion to deleting one of the examples. Given the choice (or rather, being forced to choose), I'll go with the cookie example. But my first preference would be to keep both. --<a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a> 18:37, 5 December 2005 (UTC)</dd>
</dl>
<p>I have no objection to including both. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a></p>
<dl>
<dd>To set the record straight, if you look back at the history, you will see that I did <b>not</b> delete your signature on your posting. You forgot to include your identity when you originally made the posting. But I am glad that you have now identified it as yours. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 19:56, 7 December 2005 (UTC)</dd>
</dl>
<p>Actually, what happened was that I had a two paragraph entry, and you split it when you added the new section. Purely unintentionally I am sure. I don't blame you, but it left my first paragraph orphaned without the signature that I had put at the end of the second paragraph. Go check the history, you'll see that this is what happened. No problem, I just went back and put my sig on the first paragraph when I realized what had happened, so people would know that I wrote it. It's a lesson to all of us to be careful when we edit. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 22:52, 7 December 2005 (UTC)</p>
<p><a name="Using_actual_data_in_the_medical_example" id="Using_actual_data_in_the_medical_example"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Using actual data in the medical example">edit</a>]</span> <span class="mw-headline">Using actual data in the medical example</span></h2>
<p>As a matter of pedagogy, I would prefer that the numbers in the medical example correctly correspond to an actual disease. For example, for colorectal cancer, the prior is that 0.3% of individuals have undiagnosed colorectal cancer. The hemoccult test will come up positive 50% of the time for patients that have the cancer and 3% of the time for patients that do not have the cancer. (Data from Gerd Gigerenzer, <i>Calculated Risks.</i>) Other examples could be found easily. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 19:09, 5 December 2005 (UTC)</p>
<dl>
<dd>I think this is an excellent idea, worthy of further consideration. Putting your data into the same notation as the current example:</dd>
</dl>
<dl>
<dd>
<dl>
<dd><img class='tex' src="../../../math/7/a/f/7af9001bf653005c492f281ab90332d0.png" alt="P(D) \ = \ 0.003" /></dd>
<dd><img class='tex' src="../../../math/a/c/e/ace362869ccccdc57160bca76ab415ac.png" alt="P(D^C) \ = \ 0.997" /></dd>
<dd><img class='tex' src="../../../math/e/8/2/e8283429ea4f0155f905995bd3c720ff.png" alt="P(T|D)  \ = \ 0.500" /></dd>
<dd><img class='tex' src="../../../math/4/4/f/44f2d52fae15c920b814f9c712d9ea0b.png" alt="P(T|D^C) \ = \ 0.03" /></dd>
</dl>
</dd>
</dl>
<dl>
<dd>where event <i>D</i> is having the disease and event <i>T</i> is testing positive for the disease.</dd>
</dl>
<dl>
<dd>So, using Bayes' Theorem, we have</dd>
</dl>
<dl>
<dd>
<dl>
<dd><img class='tex' src="../../../math/3/6/2/362f45a302e2bdcdfad19cad318b712e.png" alt="P(D|T) \ = \ \frac{P(T|D)\,P(D)}{P(T|D)\,P(D) + P(T|D^C)\,P(D^C)}" /></dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd><img class='tex' src="../../../math/1/1/b/11bab92a584dbda931f16f8db96b0384.png" alt="= \  0.04776" /></dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p><br /></p>
<dl>
<dd>or about 4.8 percent (if I did the math correctly). So the rate of <i>false positives</i> is approximately 95.2 percent.</dd>
</dl>
<dl>
<dd>On the other hand, what is also really scary is that the rate of <i>false negatives</i> is 50 percent!</dd>
</dl>
<p><br /></p>
<dl>
<dd>-- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 02:20, 6 December 2005 (UTC)</dd>
</dl>
<p>Yes, but the probability that one has the condition, given that you test negative, is 0.2%. The test is still useful in that it will detect about half the cancers in the general population. And (my medical spies tell me) the next year when you go in to take the test, the data will be nearly independent of what you had the year before. So about half the cancers that were missed the first time around will be detected the next year. Ditto for the next year. The fortunate thing is that these cancers are generally slow-growing, so regular testing will turn up a significant fraction of them. I have been told that at my age (I am on medicare) I need have the "gold standard" colonoscopy only once in ten years, and take the hemoccult test once a year. This gives a very significant margin of safety with little risk (the risk of colonoscopy is of the order of a percent or so...perforated bowel, bleeding, other complications). As with all invasive medical tests, one has to balance various different risks as well as costs. All of this makes deciding whether to take a test a matter of <a href="../../../d/e/c/Decision_theory.html" title="Decision theory">decision theory</a>, not just of statistics. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 03:12, 6 December 2005 (UTC)</p>
<p><a name="Text_of_the_Cookies_Example" id="Text_of_the_Cookies_Example"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Text of the Cookies Example">edit</a>]</span> <span class="mw-headline">Text of the Cookies Example</span></h2>
<p><a name="Example_.231:__Conditional_probabilities" id="Example_.231:__Conditional_probabilities"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Example #1:  Conditional probabilities">edit</a>]</span> <span class="mw-headline">Example #1: Conditional probabilities</span></h3>
<p>To illustrate, suppose there are two bowls full of cookies. Bowl #1 has 10 chocolate chip cookies and 30 plain cookies, while bowl #2 has 20 of each. Our friend Fred picks a bowl at random, and then picks a cookie at random. We may assume there is no reason to believe Fred treats one bowl differently from another, likewise for the cookies. The cookie turns out to be a plain one. How probable is it that Fred picked it out of bowl #1?</p>
<p>Intuitively, it seems clear that the answer should be more than a half, since there are more plain cookies in bowl #1. The precise answer is given by Bayes' theorem. But first, we can clarify the situation by rephrasing the question to "what’s the probability that Fred picked bowl #1, given that he has a plain cookie?” Thus, to relate to our previous explanation, the event <i>A</i> is that Fred picked bowl #1, and the event <i>B</i> is that Fred picked a plain cookie. To compute Pr(<i>A</i>|<i>B</i>), we first need to know:</p>
<ul>
<li>Pr(<i>A</i>), or the probability that Fred picked bowl #1 regardless of any other information. Since Fred is treating both bowls equally, it is 0.5.</li>
<li>Pr(<i>B</i>), or the probability of getting a plain cookie regardless of any information on the bowls. In other words, this is the probability of getting a plain cookie from each of the bowls. It is computed as the sum of the probability of getting a plain cookie from a bowl multiplied by the probability of selecting this bowl. We know from the problem statement that the probability of getting a plain cookie from bowl #1 is 0.75, and the probability of getting one from bowl #2 is 0.5, and since Fred is treating both bowls equally the probability of selecting any one of them is 0.5. Thus, the probability of getting a plain cookie overall is 0.75×0.5&#160;+&#160;0.5×0.5 = 0.625.</li>
<li>Pr(<i>B</i>|<i>A</i>), or the probability of getting a plain cookie given that Fred has selected bowl #1. From the problem statement, we know this is 0.75, since 30 out of 40 cookies in bowl #1 are plain.</li>
</ul>
<p>Given all this information, we can compute the probability of Fred having selected bowl #1 given that he got a plain cookie, as such:</p>
<dl>
<dd><img class='tex' src="../../../math/e/8/8/e88e092cb83c6550acdeddaba93b5af5.png" alt="\Pr(A|B) = \frac{\Pr(B | A) \Pr(A)}{\Pr(B)} = \frac{0.75 \times 0.5}{0.625} = 0.6." /></dd>
</dl>
<p>As we expected, it is more than half.</p>
<p><a name="Tables_of_occurences_and_relative_frequencies" id="Tables_of_occurences_and_relative_frequencies"></a></p>
<h4><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Tables of occurences and relative frequencies">edit</a>]</span> <span class="mw-headline">Tables of occurences and relative frequencies</span></h4>
<p>It is often helpful when calculating conditional probabilities to create a simple table containing the number of occurences of each outcome, or the <a href="../../../r/e/l/Relative_frequency.html" title="Relative frequency">relative frequencies</a> of each outcome, for each of the independent variables. The tables below illustrate the use of this method for the cookies:</p>
<table>
<tr>
<th>Number of cookies in each bowl<br />
by type of cookie</th>
<th>&#160; &#160; &#160; &#160; &#160;</th>
<th>Relative frequency of cookies in each bowl<br />
by type of cookie</th>
</tr>
<tr>
<td>
<table border="1" cellspacing="0" cellpadding="8">
<tr>
<th></th>
<th>Bowl #1</th>
<th>Bowl #2</th>
<th>Totals</th>
</tr>
<tr>
<td>Chocolate Chip</td>
<td>
<center>10</center>
</td>
<td>
<center>20</center>
</td>
<td>
<center>30</center>
</td>
</tr>
<tr>
<td>Plain</td>
<td>
<center>30</center>
</td>
<td>
<center>20</center>
</td>
<td>
<center>50</center>
</td>
</tr>
<tr>
<td>Totals</td>
<td>
<center>40</center>
</td>
<td>
<center>40</center>
</td>
<td>
<center>80</center>
</td>
</tr>
</table>
</td>
<td></td>
<td>
<table border="1" cellspacing="0" cellpadding="8">
<tr>
<th></th>
<th>Bowl #1</th>
<th>Bowl #2</th>
<th>Totals</th>
</tr>
<tr>
<td>Chocolate Chip</td>
<td>
<center>0.125</center>
</td>
<td>
<center>0.250</center>
</td>
<td>
<center>0.375</center>
</td>
</tr>
<tr>
<td>Plain</td>
<td>
<center>0.375</center>
</td>
<td>
<center>0.250</center>
</td>
<td>
<center>0.625</center>
</td>
</tr>
<tr>
<td>Totals</td>
<td>
<center>0.500</center>
</td>
<td>
<center>0.500</center>
</td>
<td>
<center>1.000</center>
</td>
</tr>
</table>
</td>
</tr>
</table>
<p>The table on the right is derived from the table on the left by dividing each entry by the total number of cookies under consideration, or 80 cookies.</p>
<p><a name="Another_poor_teaching_example" id="Another_poor_teaching_example"></a></p>
<h5><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Another poor teaching example">edit</a>]</span> <span class="mw-headline">Another poor teaching example</span></h5>
<p>What happens to the tables if Bowl #2 has 30 Chocolate Chip cookies and 30 plain cookies, so there are 100 cookies in total?</p>
<table>
<tr>
<th>Number of cookies in each bowl<br />
by type of cookie</th>
<th>&#160; &#160; &#160; &#160; &#160;</th>
<th>Relative frequency of cookies in each bowl<br />
by type of cookie</th>
</tr>
<tr>
<td>
<table border="1" cellspacing="0" cellpadding="8">
<tr>
<th></th>
<th>Bowl #1</th>
<th>Bowl #2</th>
<th>Totals</th>
</tr>
<tr>
<td>Chocolate Chip</td>
<td>
<center>10</center>
</td>
<td>
<center>30</center>
</td>
<td>
<center>40</center>
</td>
</tr>
<tr>
<td>Plain</td>
<td>
<center>30</center>
</td>
<td>
<center>30</center>
</td>
<td>
<center>60</center>
</td>
</tr>
<tr>
<td>Totals</td>
<td>
<center>40</center>
</td>
<td>
<center>60</center>
</td>
<td>
<center>100</center>
</td>
</tr>
</table>
</td>
<td></td>
<td>
<table border="1" cellspacing="0" cellpadding="8">
<tr>
<th></th>
<th>Bowl #1</th>
<th>Bowl #2</th>
<th>Totals</th>
</tr>
<tr>
<td>Chocolate Chip</td>
<td>
<center>0.1</center>
</td>
<td>
<center>0.3</center>
</td>
<td>
<center>0.4</center>
</td>
</tr>
<tr>
<td>Plain</td>
<td>
<center>0.3</center>
</td>
<td>
<center>0.3</center>
</td>
<td>
<center>0.6</center>
</td>
</tr>
<tr>
<td>Totals</td>
<td>
<center>0.4</center>
</td>
<td>
<center>0.6</center>
</td>
<td>
<center>1.0</center>
</td>
</tr>
</table>
</td>
</tr>
</table>
<p>So this suggests the answer of 0.3/0.6=0.5, which is wrong for this question (though might work if the cookies were chosen at random without the plates being chosen first). So greater evidence of a bad example. --<a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a> 20:00, 5 December 2005 (UTC)</p>
<dl>
<dd>As Ritchy already pointed out, anyone can generate numbers for the cookies example so that it becomes ambiguous and not appropriate as a teaching example. That's easy. The challenge is to come up with numbers so that it is a <i>good</i> example for teaching and illustrating. Remember, the whole idea here is to try to help people understand this stuff. Oh yeah, I almost forgot. Any idiot could do the same thing for the medical example as for the cookies example. It has <i>nothing</i> to do with whether you use cookies or medical testing. It has to do with whether you <i>want</i> to make it work or you <i>want</i> to make it fail. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 04:33, 11 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>What I don't get is why you are spending so much time and energy trying to devise <i>inappropriate</i> examples for illustrating this theorem instead of investing your time and energy into something positive and useful, like trying to improve the medical example for instance, or trying to improve the cookies example instead of attacking it. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 04:35, 11 December 2005 (UTC)</dd>
</dl>
<p><a name="Muggles_and_witches" id="Muggles_and_witches"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Muggles and witches">edit</a>]</span> <span class="mw-headline">Muggles and witches</span></h2>
<p>As I stated during this discussion of the cookie example, I think that the medical example is more compelling, but do not object to having both. But I do object to eliminating the medical example in favor of the cookie example.</p>
<p>While reading the <a href="../../../n/e/w/New_York_Times_d49e.html" title="New York Times">New York Times</a> today, my attention was drawn to an article on <a href="http://www.nytimes.com/2005/12/11/magazine/11ideas_section2-3.html?emc=eta1" class="external text" title="http://www.nytimes.com/2005/12/11/magazine/11ideas_section2-3.html?emc=eta1" rel="nofollow">The Genetic Theory of Harry Potter</a>, which discusses questions about (according to the article) a recessive gene <i>w</i> for wizardry that is an <a href="../../../a/l/l/Allele.html" title="Allele">allele</a> that is normally represented by the dominant gene <i>M</i> for a muggle. That is, to be a wizard, one has to have two of the <i>w</i> allele, one from the father and one from the mother; if one has one <i>w</i> and one <i>M</i>, one is a muggle, but may possibly have children that are wizards, depending upon the alleles that ones spouse may have.</p>
<p>This made me think of a possibly more compelling way of presenting the ideas that were present in the cookie example. One can ask the question, for example, given that in the general population, a certain percentage of individuals are witches (that is, <i>ww</i>, <a href="../../../h/o/m/Homozygous.html" title="Homozygous">homozygous</a> for the <i>w</i> allele), assuming random mating (<a href="../../../h/a/r/Hardy-Weinberg_equilibrium_96b3.html" title="Hardy-Weinberg equilibrium">Hardy-Weinberg equilibrium</a>, how does one calculate the percentage of individuals that are <a href="../../../h/e/t/Heterozygous.html" title="Heterozygous">heterozygous</a> (that is, <i>Mw</i> or <i>wM</i>, where the first letter indicates the allele inherited from the father and the second the allele inherited from the mother), and the percentage that are homozygous for <i>M</i>? I pass on the question about whether random mating is a reasonable assumption for people who are witches or who know that they are descended from witches; this is a reasonable question, but beyond the scope of my comments.</p>
<p>The paragraph above allows us to compute the prior on the three (four if one distinguishes <i>Mw</i> and <i>wM</i>) cases. Since the frequency of <i>ww</i> is under our control (as <a href="../../../p/e/d/Pedagogue.html" title="Pedagogue">pedagogues</a>), we can manufacture any example we wish.</p>
<p>Now one can pose questions like: Suppose a couple has three children, all muggles. What is the probability that neither parent has the <i>w</i> allele? What is the probability that both parents have <a href="../../../g/e/n/Genotype.html" title="Genotype">genotype</a> <i>Mw</i>? What is the probability that one parent has genotype <i>Mw</i> and the other is <i>MM</i>? What is the probability that both have genotype <i>ww</i> (zero, but one can calculate this formally from Bayes' theorem).</p>
<p>Or, same questions, except that the couple has three children, one wizard and two muggles? Or if they have three children, all wizards?</p>
<p>As you can see, the questions one may ask are quite varied and all illustrate both the idea of setting a prior, and the idea of how to turn a prior into a posterior, given data.</p>
<p>Now, I am not wedded to the muggles-wizards thing here, although I think that many young people just getting to college may have grown up with Harry Potter and may find this an interesting and compelling example. It could just as well be an example with (say) the sickle cell trait, or some other actual biological example. But I am thinking of using it in my own teaching. So, I put it out here for your consideration. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 00:14, 12 December 2005 (UTC)</p>
<dl>
<dd>Sounds interesting. Maybe you could write a rough draft on your own User page, and then when you think you have something that is ready for prime time, you could present it as a proposed example for the Bayes' Theorem page and then we could discuss it here on this page if you wanted some outside feedback. It's entirely up to you of course. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 01:47, 12 December 2005 (UTC)</dd>
</dl>
<p>OK, give me a few days; semester is ending and I have things that have priority. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 02:49, 12 December 2005 (UTC)</p>
<p><a name="A_surprising_example" id="A_surprising_example"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: A surprising example">edit</a>]</span> <span class="mw-headline">A surprising example</span></h2>
<p>A friend sent me this surprising example. Suppose there is a test for detecting whether an unborn child is a boy or a girl. If the child is a boy, the test is "perfect": P(Test B|B)=1; if the child is a girl, it is not so good: P(Test G|G)=0.7. Bayes' theorem readily gives the result that P(B|Test B)=10/13, whereas P(G|Test G)=1. The surprising thing is that the "perfection" of the test is transferred from boys to girls when the conditioning is reversed. My friend notes that this can be considered a version of the <a href="../../../p/r/o/Prosecutor%27s_fallacy.html" title="Prosecutor's fallacy">prosecutor's fallacy</a>, AKA the Harvard Medical School fallacy.</p>
<p>I don't know if this could be used as an example in this article or whether it should appear in the prosecutor's fallacy article. In any case, it is rather counterintuitive and deserves mention somewhere.</p>
<p>I'll mention this on the talk page of the prosecutor's fallacy article. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 21:32, 16 December 2005 (UTC)</p>
<dl>
<dd>I can never figure these examples out without setting up my trusty 3 x 3 table of joint probability. I worked it out for this example using the numbers you provided and the definition of conditional probability:</dd>
</dl>
<dl>
<dd>
<table border="1" cellspacing="0" cellpadding="8">
<tr>
<th></th>
<th>Test = B</th>
<th>Test = G</th>
<th>Totals</th>
</tr>
<tr>
<td>Actual = B</td>
<td>
<center>0.50</center>
</td>
<td>
<center>0.00</center>
</td>
<td>
<center>0.50</center>
</td>
</tr>
<tr>
<td>Actual = G</td>
<td>
<center>0.15</center>
</td>
<td>
<center>0.35</center>
</td>
<td>
<center>0.50</center>
</td>
</tr>
<tr>
<td>Totals</td>
<td>
<center>0.65</center>
</td>
<td>
<center>0.35</center>
</td>
<td>
<center>1.00</center>
</td>
</tr>
</table>
</dd>
</dl>
<dl>
<dd>It was not obvious to me, maybe it was to some others, but the key to the surprising result is the zero joint probability for the test finding a girl when the actual is a boy, and the non-zero joint probability for the test finding a boy when the actual is a girl (the dual case). Anyway, it <i>is</i> an intriguing example. Bill, thanks for posting it here. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 22:36, 16 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>This actually caused confusion at the <a href="../../../r/p/_/RP_%28complexity%29_07ff.html" title="RP (complexity)">RP</a> article. An RP machine has the property that:
<ul>
<li>If the answer is NO, it always returns NO.</li>
<li>If it ever returns YES, the answer is YES.</li>
</ul>
</dd>
<dd>We ended up having to explain both carefully to avoid any further confusion. <a href="../../../d/e/c/User%7EDeco_20f6.html" title="User:Deco">Deco</a> 04:07, 17 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>This is only "surprising" because of the misleading phraseology used when describing the problem. If the problem is stated in a less colloquial manner, the result is not at all surprising:
<dl>
<dd>There is a single test, denoted by the random variable T, which is used to determine the sex of an unborn child. The test can produce two results: either T=boy or T=girl. When the child is a boy, it is known that P(T=boy)=1. When the child is a girl, it is known that P(T=girl)=0.7. This means that the test can only be incorrect when it reports that T=boy. This obviously makes the test less reliable when this result is observed and immediately leads to P(boy|T=boy) &lt; P(girl|T=girl).</dd>
</dl>
</dd>
<dd>No use of Bayes' theorem is necessary. One could speculate that the reason why this was thought to be surprising is the complete absence of logic as a subject in its own right from the modern school curriculum. However, times and fashions change. Lukestuts 14:46, 22 December 2005 (GMT)</dd>
</dl>
</dd>
</dl>
<p>Unborn children do not generally have sex. Usually they wait until after they are born, and then for at least 12 years or so. They do, however, have a <i>gender</i>. -- 24.218.218.28 16:00, 22 December 2005 (UTC)</p>
<p>I agree that the confusion comes from imprecise language. Epidemiologists and statisticians who work with screening application like the one above refer to four test characteristics that characterize the performance of a test. These are the four conditional probabilities (with apologies for apparent gender bias):</p>
<dl>
<dd>1. Predictive value positive ==&gt; P(B|Test B)</dd>
<dd>2. Predictive value negative ==&gt; P(G|Test G)</dd>
<dd>3. Specificity ==&gt; P(Test B|B)</dd>
<dd>4. Sensitivity ==&gt; P(Test G|G)</dd>
</dl>
<p>So in the example, the specificity is 1, the sensitivity is 0.7, the PVP is 10/13 and the PVN = 1. I think the confusion comes from thinking about the <i>test</i> as being 'perfect'. - <a href="../../../k/e/n/User%7EKenkleinman_8981.html" title="User:Kenkleinman">Ken K</a> 21:21, 1 March 2006 (UTC)</p>
<p><a name="No.2C_you_don.27t_need_non-zero_probabilities_to_have_well-defined_conditionals" id="No.2C_you_don.27t_need_non-zero_probabilities_to_have_well-defined_conditionals"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: No, you don't need non-zero probabilities to have well-defined conditionals">edit</a>]</span> <span class="mw-headline">No, you don't need non-zero probabilities to have well-defined conditionals</span></h2>
<p>[snide remarks deleted]</p>
<p>It is commonplace to say, for example, that the conditional distribution of <i>Y</i> given <i>X</i> is <a href="../../../n/o/r/Normal_distribution.html" title="Normal distribution">normal</a> with expectation <i>X</i> and variance 1, and <i>X</i> itself is normal with expectation 0 and variance 1. In that case, one is obviously conditioning on an event of probability zero. There's nothing wrong with that. It does mean, however, that the identity Pr(<i>A</i>|<i>B</i>) = Pr(<i>A</i>&#160;&amp;&#160;<i>B</i>)/Pr(<i>B</i>) would not apply. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 23:41, 4 December 2005 (UTC)</p>
<dl>
<dd>
<dl>
<dd>I am bit confused by your explanation. You have said that <i>X</i> is normal with expectation 0 and variance 1, and then you say that we are conditioning on an event of probability zero. Are you talking about event <i>X</i>&#160;? If so, is it true that the probability is zero? The pdf (scratch that, make it the CDF) of <i>X</i>, call it <i>f</i>(<i>X</i>), is greater than zero and monotonically non-decreasing for all non-infinite <i>X</i>. So then, <i>P</i>( <i>a</i> &lt; <i>X</i> &lt; <i>b</i>) = <i>f</i>(<i>b</i>) – <i>f</i>(<i>a</i>) &gt; 0 (in general, although could be = 0 in special cases) for all <i>a</i> and <i>b</i> where <i>b</i> &gt; <i>a</i>. So in what sense is the probability of <i>X</i> equal to zero?</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd><i>X</i> is not an event; <i>X</i> is a random variable. The event on which one is conditioning here is the event that <i>X</i> has a particular value. That is an event of probability 0, because <i>X</i> is a <i>continuous</i> random variable. The pdf of <i>X</i> is certainly NOT non-decreasing; it's the "bell curve" that increases and then decreases (maybe you meant the cdf rather than the pdf?). OK, I've looked closely at your next sentence. Apparently you <i>did</i> mean the cdf. There's no such thing as the probability of <i>X</i>, since <i>X</i> is not an event. The probability that <i>X</i> has a particular value is an event of probability 0. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 00:04, 11 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Sorry, you are right, I did mean the <i>CDF</i> and not the <i>pdf</i>. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 00:30, 11 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>So if we define Event <i>A</i> as the event where the continuous random variable <i>X</i> is equal to a specific value, for instance <i>X</i> = <i>a</i>, then of course <i>P</i>(<i>A</i>) = 0 as you have said. But, for a different event, say Event <i>B</i> such that <i>b</i> &lt; <i>X</i> &lt; <i>c</i>, then the probability of this event is not zero, <i>P</i>(<i>B</i>) &gt; 0. But that means that even though <i>X</i> is a continuous random variable, we are now talking about discrete events <i>A</i> and <i>B</i> defined in terms of <i>X</i>. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 00:30, 11 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Please note, I am asking these question purely in good faith. I have no agenda other than that I am confused and I would like to understand. I am not trying to bust anyone's chops or to forward any particular point of view. I would greatly appreciate your help in understanding this example. Thanks. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 18:16, 10 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p><br />
Michael Hardy's point is that in the particular case he considered, the probability of observing a particular value of a continuously distributed quantity (such as a quantity that is normally distributed) is zero. This is not a problem for Bayes' theorem, because in the case of continuously distributed quantities the correct approach is to go over to the probability <i>density</i> for x, which is not zero for any given x. The probability <i>density</i> in his example is given by the standard <a href="../../../n/o/r/Normal_distribution.html" title="Normal distribution">normal distribution</a>. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 22:18, 5 December 2005 (UTC)</p>
<dl>
<dd>Isn't this what <a href="../../../b/a/y/Bayes%27_theorem.html#Bayes.27_theorem_for_probability_densities" title="Bayes' theorem">Bayes.27_theorem_for_probability_densities</a> says? --<a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a> 23:03, 5 December 2005 (UTC)</dd>
</dl>
<p>I will repeat my question again. For two discrete random variables <i>A</i> and <i>B</i>, if the probability of <i>B</i> is zero, then what meaning is there in trying to determine the conditional probability of <i>A</i> given <i>B</i>&#160;? In fact, is it not the case that if P(B) = 0, then in fact P(A|B) is completely indeterminant, and can take on any value whatsoever? If P(B) = 0, then B cannot occur, so how can we talk about the probability of A contigent on B, an event that never happens?</p>
<p>Mathematically, if P(B) = 0, then it follows that P(A&amp;B) = 0. Since P(A|B) is the ratio of P(A&amp;B) divided by P(B), it then follows that P(A|B) is zero divided by zero, which can take on any value, including values less than zero and greater than one. Of course, it would be absurd for a probability to take on these values, but nevertheless, there it is. So my conclusion is, that in order to have a meaningful value for P(A|B), then P(B) cannot equal zero. Could someone please tell me if that is correct or incorrrect, and if not, why not. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 00:38, 6 December 2005 (UTC)</p>
<dl>
<dd>For <i>discrete</i> random variables, your point is valid, but you'll notice I spoke of <i>normally distributed</i> random variables, so they're not discrete. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 01:25, 6 December 2005 (UTC)</dd>
</dl>
<p>Thank you. In most cases where this issue came up, I was in general talking about discrete random variables, although I did not always make that assumption explicit. I understand that Bayes' theorem can be applied to continuous random variables (as the article points out), and I understand the difference between probability and probability density functions. I appreciate your willingness to help me understand the issue involving marginal probabilities that are equal to zero. I need to spend some more time trying to understand the continuous case, and how it differs from the discrete case. Thanks again. Regards, -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 01:41, 6 December 2005 (UTC)</p>
<p><a name="Bottom-line" id="Bottom-line"></a></p>
<h3><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Bottom-line">edit</a>]</span> <span class="mw-headline">Bottom-line</span></h3>
<p>So what's the bottom-line? It seems to me that my original point was in fact correct. If we have two discrete random events, <i>A</i> and <i>B</i>, then in order to have <i>meaningful</i> conditional probabilities, P(A|B) and P(B|A), we must have non-zero marginal probabilities:</p>
<dl>
<dd><img class='tex' src="../../../math/a/6/1/a6136ebc57a4241e51ae98633312bab5.png" alt="P(A) \ne 0" /></dd>
</dl>
<p>and</p>
<dl>
<dd><img class='tex' src="../../../math/a/8/2/a821704e23afb920c7c3b4d266a96890.png" alt="P(B) \ne 0" /></dd>
</dl>
<p>Otherwise, the conditional probabilities become zero divided by zero, which is completely indeterminant, as I discussed above.</p>
<p>Furthermore, even if we are dealing with a <i>continuous</i> random variable <i>X</i>, we still end up defining discrete events <i>A</i> and <i>B</i> in terms of <i>X</i>, in which case once again, in order to have <i>meaningful</i> conditional probabilities, the marginal probabilties cannot equal zero.</p>
<p>-- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 16:55, 22 December 2005 (UTC)</p>
<p><a name="Good_example_of_a_flame-out" id="Good_example_of_a_flame-out"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Good example of a flame-out">edit</a>]</span> <span class="mw-headline">Good example of a flame-out</span></h2>
<p>[snide remarks deleted]</p>
<p>[snide remarks deleted]</p>
<dl>
<dd>The reason I am editing this page is because it desperately <i>needed</i> improvement. One of the biggest problems, which was not identified by me but rather by others, was that it was written in a way that was way too technical for a general audience to understand. Oh, and look, that is exactly at the heart of our disagreement over the cookies example. You <i>still</i> have made no credible attempt to identify <i>any</i> valid reasons for deleting the cookies example. What are you afraid of? Why are you totally opposed to helping people understand technical concepts? Or is it more fun to obfuscate ideas with obscure terminology? -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 04:45, 5 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>More straw men. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 05:59, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Good answer.</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>OK, I'm going to get to this article soon, when I'm feeling energetic. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 03:21, 5 December 2005 (UTC)</p>
<dl>
<dd>So, is it worth discussing here under what circumstances the identity applies, or is that sufficiently covered under <a href="../../../c/o/n/Conditional_probability.html" title="Conditional probability">conditional probability</a>? --<a href="../../../m/a/r/User%7EMarkSweep_b58d.html" title="User:MarkSweep">MarkSweep</a>&#160;<small><a href="../../../m/a/r/User_talk%7EMarkSweep_9d72.html" title="User talk:MarkSweep">(call me collect)</a></small> 04:00, 5 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I'm inclined to steer around the difficulty in this article and leave interesting details to <a href="../../../c/o/n/Conditional_probability.html" title="Conditional probability">conditional probability</a>. But it could go the other way too; if we had some alternative texts in front of us, it might be easier to choose. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 06:04, 5 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p>In all seriousness, tell me what I am missing. If P(B) = 0, then from P(A&amp;B) = P(A|B) P(B) two things are clear: (1) P(A&amp;B) = 0, and (2) P(A|B) is an <a href="../../../i/n/d/Indeterminate_%28variable%29.html" title="Indeterminate (variable)">indeterminate quantity</a> (okay, not undefined, but indeterminate). Is that correct?</p>
<p>On the other hand, in the <i>real</i> world, if P(B) = 0, then why would I care what P(A|B) is? If event B never happens, then trying to find P(A|B) is completely meaningless. Who would even want to ask such a question? -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 05:29, 5 December 2005 (UTC)</p>
<dl>
<dd>"I don't understand what's going on here, but I'll tell you what to do anyway" is a weak position to argue from, but you don't let that slow you down. I'm accustomed to arguing with people who know what they're talking about; I really don't know how to deal with you. <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a> 05:59, 5 December 2005 (UTC)</dd>
</dl>
<p>[snide remarks deleted]</p>
<p>It is interesting to note that rather than answering my (legitimate) question, you chose to attack me personally. This is not about me. It is about trying <i>in good faith</i> to improve Wikipedia in general and this article in particular. Or maybe for you it is about something else.... -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 13:56, 5 December 2005 (UTC)</p>
<dl>
<dd>No response....</dd>
</dl>
<p>Also, it was Michael Hardy who claimed that it is not necessary for the marginal probabilities to be nonzero. I am not convinced. That doesn't mean I don't know what is going on, that means that he made a statement that I do not understand. I have asked for an explanation, but so far none has been forthcoming. If I am wrong, then I will be the <i>first</i> to admit it (unlike some other people). I am not so fragile that I cannot admit when I do not understand something or when I make a mistake. Grow up! -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 14:00, 5 December 2005 (UTC)</p>
<dl>
<dd>No response...</dd>
</dl>
<p>I am accustomed to dealing with people who are interested in learning and growing, not people who need to feed their own ego by showing how much smarter they are than everyone else. -- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 14:02, 5 December 2005 (UTC)</p>
<dl>
<dd>No response...</dd>
</dl>
<p>Two more points:</p>
<ol>
<li>At least I have an open mind, and I am willing to consider a point of view different from mine.</li>
<li>Where I come from, asking a question when I don't understand something is not a sign of weakness; it's a sign of strength. The weak person is the one who pretends to understand even when he doesn't.</li>
</ol>
<p>-- <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a> 15:22, 5 December 2005 (UTC)</p>
<dl>
<dd>No response...</dd>
</dl>
<p><a name="Simplified_explanation_on_top.3F" id="Simplified_explanation_on_top.3F"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Simplified explanation on top?">edit</a>]</span> <span class="mw-headline">Simplified explanation on top?</span></h2>
<p>I am proposing putting something like the following into the article:</p>
<dl>
<dd>If I flip a double-headed coin, the probability of getting a head is 1. However, if I flip a coin and get a head, what is the probability that the coin was double-headed? This is an example where Bayes' theorem will apply.</dd>
</dl>
<p><a href="../../../x/4/2/User%7EX42bn6_9d4f.html" title="User:X42bn6"><span style="font-family: Tahoma; font-size: 8pt; font-weight: bold;">x42bn6</span></a> <a href="../../../x/4/2/User_talk%7EX42bn6_bd12.html" title="User talk:X42bn6"><span style="font-family: Tahoma; font-size: 8pt;">Talk</span></a> 07:00, 5 December 2005 (UTC)</p>
<p><br /></p>
<p><a name="Possible_plagarism" id="Possible_plagarism"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Possible plagarism">edit</a>]</span> <span class="mw-headline">Possible plagarism</span></h2>
<p>The 'false positivies in a medical test' is lifted directly from "A First Course in Probability" 6th. ed, by Sheldon Ross. <a href="../../../b/o/o/Special%7EBooksources_ed7b.html" class="internal">ISBN 0-13-033851-6</a>.</p>
<dl>
<dd>Is it lifted word for word, including the same numbers, or is it just the same example? The medical test example is very common. <a href="../../../d/e/c/User%7EDeco_20f6.html" title="User:Deco">Deco</a> 04:11, 17 December 2005 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>We could change it to an actual disease with actual figures, which would be better pedagogically anyway. See above for one possibility. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 20:41, 17 December 2005 (UTC)</dd>
</dl>
</dd>
</dl>
<p><a name="Bayes_theorem_requires_a_key_assumption" id="Bayes_theorem_requires_a_key_assumption"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Bayes theorem requires a key assumption">edit</a>]</span> <span class="mw-headline">Bayes theorem requires a key assumption</span></h2>
<p>I just wanted to point out that the bayes' theorem is only useful IF there is no correlation between the frequency with which the information given is given, and the outcome regardless of your awareness of such a correlation. If there is such a correlation, an adjustment needs to be made.</p>
<p>To demonstrate this, just look at the <a href="../../../m/o/n/Monty_Hall_problem_4d49.html" title="Monty Hall problem">Monty Hall problem</a>. If you were not told how the host in this problem was choosing doors to open, you would simply use Bayes' theorem along with the given information that you did not choose the goat he shows you. This calculation would lead you to a 1/2 chance to have chosen a goat or the car, given you didn't choose the goat he shows you. But empyrical results would show a 1/3 chance for you to get the car by staying and a 2/3 chance to get the car by switching. This is because there was a correlation between how often you were given the information you were given and the outcome... whether or not you knew it.</p>
<p>Perhaps one can simply adjust by using this formula in place of Bayes' theorem when such a correlation is known:</p>
<p>Prob(A|B) = (Prob(B|A)*Prob(A)*Prob(B was given|A))/(Prob(B)) / ((Prob(B|A)*Prob(A)*Prob(B was given|A))/(Prob(B)) + (Prob(B|A)*Prob(A)*Prob(B was given|A compliment))/(Prob(B))</p>
<p>Any time such a correlation exists, whether you know it or not, Bayes' theorem would lead you to an incorrect answer. - T. Z. K.</p>
<dl>
<dd>I have deleted this sentence, because the theorem as stated is correct and because the sentence is incomprehensible without explanation:</dd>
</dl>
<dl>
<dd>
<dl>
<dd>Bayes' theorem depends on the assumption that there is no correlation between the frequency with which information is given and the outcome.</dd>
</dl>
</dd>
</dl>
<dl>
<dd>Although I have not digested what is written above, I think that if there's an error, it is an erroneous way of applying the theorem, rather than an error in the way the theorem was stated. It says "you would simply use Bayes' theorem along with the given information that you did not choose the goat he shows you". But I think that if there is additional information to be used, it should have been included within "B" in the expression P(A|B). I don't know what "B is given" means above. The comments above are really not written clearly. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 22:08, 9 March 2006 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>I agree that if you know the correlation between the frequency with which information is given to you and the outcome, then you could manipulate the events to incorporate this. But this is irrelevant for 2 reasons. 1) You don't always know whether or not such a correlation exists, in which case using bayes' theorem would just give you the wrong answer. If you don't know about this assumption then you wouldn't know why you got the wrong answer. 2) For any given B this statement is always true.</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Oh -- one other thing: "compliment" and "complement" are two different words that mean two different things. You wrote the former where you clearly meant the latter. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 22:39, 9 March 2006 (UTC)</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>
<dl>
<dd>Merely a typo. If you have an ulterior motive in pointing this out, let it be known that you are not here to help people arrive at a better understanding of things.</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>Correlation isn't the right word, in any case. In statistics, 'correlation' has a specific meaning. What is meant is 'independence'. Things can be uncorrelated, but still dependent. And, in the Monty Hall example above, the mistake is failure to write down the correct likelihood function, assuming independence when it doesn't hold. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 02:41, 10 March 2006 (UTC)</p>
<dl>
<dd>What is meant is correlated. If it is uncorrelated, but dependent, it doesn't matter. But thanks for trying to tell me what I meant rather than asking... Also, the fact that you can consider the given information to be that monty reveals a goat rather than simply that you didn't choose the revealed goat, doesn't change the fact that you are also given the information that you did not choose the shown goat. If you were not told of monty's strategy then this would be all the information you would have, yet using bayes' theorem with it would give you the wrong answer.</dd>
</dl>
<p><a name="Ludicrously_overtechnical_and_hard_to_read" id="Ludicrously_overtechnical_and_hard_to_read"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Ludicrously overtechnical and hard to read">edit</a>]</span> <span class="mw-headline">Ludicrously overtechnical and hard to read</span></h2>
<p>I understood the introduction. So far, so good. Then I went to "Statement..." expecting a clear statement of what the theorem actually is in plain English. Oh dear. This article is <i>absolutely useless</i> to the layperson. I daresay I could walk away with an understanding of Bayes' theorem if I waded through all the symbols but why would I bother? I'm sure I can find a straightforward explanation of it somewhere else. And I can't sofixit. I have no idea what it should say; I only know it isn't saying it.-- Grace Note</p>
<dl>
<dd>Specifically, at which point does the difficulty begin for you? In "plain English" I would say that Bayes' theorem says: multiply the prior probability distribution by the likelihood function and then normalize, to get the posterior probability distribution. But before that could be understood, I would first have to explain the terms. This article begins with a formula that doesn't require such knowledge, but only a secondary-school-level grasp of what is meant by such things as Pr(<i>A</i>|<i>B</i>), etc. If you want it to be comprehensible to "laypersons" who don't even know that much, you're asking too much, I think. Could you be specific about which is the first thing you couldn't understand? <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 23:51, 3 April 2006 (UTC)</dd>
</dl>
<dl>
<dd>
<dl>
<dd>PS: Don't take the above to be any sort of complete endorsement of the way the article is now written. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 23:52, 3 April 2006 (UTC)</dd>
</dl>
</dd>
</dl>
<p>Hello, we have an actual application of Bayes' theorem and we're discussing it here, hopefully in a way that the average lay person can understand: <a href="http://www.thebroth.com/blog/118/bayesian-rating" class="external free" title="http://www.thebroth.com/blog/118/bayesian-rating" rel="nofollow">http://www.thebroth.com/blog/118/bayesian-rating</a></p>
<p>The text is about how to use Bayes' theorem for online rating facilites - anything where you can rate or vote. Is that something that should go into External Links or does it have value as an application example somewhere in the actual text? Wyxel 10:56, 20 April 2006 (UTC)</p>
<dl>
<dd>I don't see how your rating system actually applies Bayes' theorem. --<a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a> 21:42, 20 April 2006 (UTC)</dd>
</dl>
<p><a name="Innumeracy" id="Innumeracy"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Innumeracy">edit</a>]</span> <span class="mw-headline">Innumeracy</span></h2>
<p>Should we mention or link to <a href="../../../m/a/t/Innumeracy%7E_Mathematical_Illiteracy_and_its_Consequences_8a27.html" title="Innumeracy: Mathematical Illiteracy and its Consequences">Innumeracy: Mathematical Illiteracy and its Consequences</a>? The book discusses cognitive difficulties in, and proposes some solutions to, the interpretation of Bayes' rule. Thanks! --<a href="../../../6/3/2E/User%7E63.138.93.195.html" title="User:63.138.93.195">63.138.93.195</a> 02:32, 23 April 2006 (UTC)</p>
<p><a name="Definition_of_Likelihood" id="Definition_of_Likelihood"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Definition of Likelihood">edit</a>]</span> <span class="mw-headline">Definition of Likelihood</span></h2>
<p>I have reverted a recent edit that incorrectly wrote the sampling distribution P(B|A) as proportional to the likelihood L(B|A). This is contrary to customary notation, which writes P(B|A) as proportional to L(A|B). See the article on <a href="../../../l/i/k/Likelihood.html" title="Likelihood">likelihood</a>.</p>
<p>The reason is that the sampling distribution P(B|A) is an actual, normalized probability, with A fixed (given) and B stochastic. But the likelihood L(A|B) is considered as a function of A, with B fixed (given) and A stochastic (or unknown). The likelihood is not normalized and is not a probability. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 00:41, 22 May 2006 (UTC)</p>
<p><a name="Medical_test" id="Medical_test"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Medical test">edit</a>]</span> <span class="mw-headline">Medical test</span></h2>
<p>Why was the medical test example removed? --<i>best, kevin</i> <b>[</b><a href="../../../k/z/o/User%7EKzollman_a660.html" title="User:Kzollman">kzollman</a><b>][</b><a href="../../../k/z/o/User_talk%7EKzollman_107b.html" title="User talk:Kzollman">talk</a><b>]</b> 21:37, 28 September 2006 (UTC)</p>
<p><a name="Graphical_explanation" id="Graphical_explanation"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Graphical explanation">edit</a>]</span> <span class="mw-headline">Graphical explanation</span></h2>
<p>There is a nice graphical explanation <a href="http://www.ams.org/notices/200601/rev-faris.pdf" class="external text" title="http://www.ams.org/notices/200601/rev-faris.pdf" rel="nofollow">here</a> (p. 34). Maybe it could be included in the article. --<a href="../../../t/g/r/User%7ETgr_c760.html" title="User:Tgr">Tgr</a> 08:26, 29 September 2006 (UTC)</p>
<p><br /></p>
<p><a name="Wording_of_the_question" id="Wording_of_the_question"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Wording of the question">edit</a>]</span> <span class="mw-headline">Wording of the question</span></h2>
<p>The question "what’s the probability that Fred picked bowl #1, given that he has a plain cookie?” is not worded properly. The probability that Fred picked bowl #1 is 0.5, regardless of what cookies we see afterwards. We can't recompute probability of an event that already happened (The probability that a coin landed on "tails" when I flipped it ten years ago is still 0.5 today) and wording questions that attempt this is one of the most common sources of confusion students have in probability theory classes. The proper wording of the question is "What's our belief that Fred picked bowl #1, given that we saw him draw a plain cookie?". That's the posterior, the prior is: "What's our belief that Fred picked bowl #1 before we saw any cookies?". Please revise the example to address this issue.</p>
<dl>
<dd>
<dl>
<dd>I think you're misunderstanding that this is about <a href="../../../c/o/n/Conditional_probability.html" title="Conditional probability">conditional probability</a>. "The probability of A given B" is a conditional probability. <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a> 21:18, 6 October 2006 (UTC)</dd>
</dl>
</dd>
</dl>
<p><a name="Reworking_the_equation" id="Reworking_the_equation"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Reworking the equation">edit</a>]</span> <span class="mw-headline">Reworking the equation</span></h2>
<p>Looking at the equation for <a href="../../../b/a/y/Bayes%27_Theorem_e36d.html" title="Bayes' Theorem">Bayes' Theorem</a>.</p>
<dl>
<dd><img class='tex' src="../../../math/1/a/0/1a0a4568537f9b9ee459408ae2e7dcd1.png" alt="\Pr(A|B) = \frac{\Pr(B | A)\, \Pr(A)}{\Pr(B|A)\Pr(A) + \Pr(B|A^')\Pr(A^')}  \!" /></dd>
</dl>
<p>Assume that <img class='tex' src="../../../math/4/d/4/4d422c109bca2176519bd0144a9e73f6.png" alt="\Pr(A^') = 1 - \Pr(A)" /></p>
<dl>
<dd><img class='tex' src="../../../math/1/f/c/1fc6d726362f1256bd0c261e4e8b35c8.png" alt="\Pr(A|B) = \frac{\Pr(B | A)\, \Pr(A)}{\Pr(B|A)\Pr(A) + \Pr(B|A^') - \Pr(B|A^')\Pr(A)}  \!" /></dd>
<dd><img class='tex' src="../../../math/4/2/f/42f4ac9a26f75eda6a7716993026a6c8.png" alt="\downarrow" /></dd>
<dd><img class='tex' src="../../../math/4/0/6/406437252164170272bb2f0fb9bb3d70.png" alt="\Pr(A|B) = \frac{\Pr(B | A)\, \Pr(A)}{(\Pr(B|A) - \Pr(B|A^')) \Pr(A) + \Pr(B|A^') } \!" /></dd>
<dd><img class='tex' src="../../../math/4/2/f/42f4ac9a26f75eda6a7716993026a6c8.png" alt="\downarrow" /></dd>
<dd><img class='tex' src="../../../math/b/d/d/bdd76a6757e2b45dae8ef605c29f5cf9.png" alt="\frac{\Pr(A|B)}{\Pr(B | A)\, \Pr(A)} = \frac{1}{(\Pr(B|A) - \Pr(B|A^')) \Pr(A) + \Pr(B|A^') } \!" /></dd>
<dd><img class='tex' src="../../../math/4/2/f/42f4ac9a26f75eda6a7716993026a6c8.png" alt="\downarrow" /></dd>
<dd><img class='tex' src="../../../math/3/5/7/357e3e98e683f7a031c0e84f97ef99f6.png" alt="\frac{\Pr(B | A)\, \Pr(A)}{\Pr(A|B)} = (\Pr(B|A) - \Pr(B|A^')) \Pr(A) + \Pr(B|A^')  \!" /></dd>
<dd><img class='tex' src="../../../math/4/2/f/42f4ac9a26f75eda6a7716993026a6c8.png" alt="\downarrow" /></dd>
<dd><img class='tex' src="../../../math/1/9/d/19d4d39bcc37d7520da5cba19ca924b8.png" alt="\Pr(A) \left [ \frac{\Pr(B | A)}{\Pr(A|B)} - (\Pr(B|A) - \Pr(B|A^')) \right ] = \Pr(B|A^')  \!" /></dd>
<dd><img class='tex' src="../../../math/4/2/f/42f4ac9a26f75eda6a7716993026a6c8.png" alt="\downarrow" /></dd>
<dd><img class='tex' src="../../../math/3/d/f/3dffda18747576aa29d27cd72dab5ad3.png" alt="\Pr(A) = \frac{\Pr(B|A^')}{\frac{\Pr(B | A)}{\Pr(A|B)} - (\Pr(B|A) - \Pr(B|A^'))}\!" /></dd>
</dl>
<p>Now assume that a positive integer number X (between 1 and 1 million) is picked at random.</p>
<p>let <img class='tex' src="../../../math/7/b/8/7b80ebccd4420d9579e7d488396b7f5c.png" alt="A \," /> be "X is divisible by 2"</p>
<p>and</p>
<p>let <img class='tex' src="../../../math/d/5/7/d5742827d055e40cd568fd71271f4681.png" alt="B \," /> be "X is divisible by 4"</p>
<p>We have</p>
<dl>
<dd><img class='tex' src="../../../math/1/4/9/1495a1c6a6b5cf36a96224e130573d4d.png" alt="\Pr(B|A^') = 0" /></dd>
</dl>
<p>Thus</p>
<dl>
<dd><img class='tex' src="../../../math/9/9/5/995478e3ff37d4f3339492323845c35e.png" alt="\Pr(A) = \frac{0}{\frac{\Pr(B | A)}{\Pr(A|B)} - (\Pr(B|A) - \Pr(B|A^'))}\!" /></dd>
<dd><img class='tex' src="../../../math/4/2/f/42f4ac9a26f75eda6a7716993026a6c8.png" alt="\downarrow" /></dd>
<dd><img class='tex' src="../../../math/8/4/4/844a0c10dda8299f7a6f8183167ba0d5.png" alt="\Pr(A) = 0 \!" /></dd>
</dl>
<p>Therefore if we pick a positive integer between 1 and 1 million at random, the number we pick will not be an even number.</p>
<p>This is of course WRONG! But I can't see where the mistake is. 202.168.50.40 22:59, 28 November 2006 (UTC)</p>
<dl>
<dd>Of course, when you have non-zero = <img class='tex' src="../../../math/0/9/2/092c80eec90a1d3bd5ce15cf880b3624.png" alt="\frac {0} {something}\," />, and you think this is weird, the reason is that something is zero, because 0/0 can be anything.</dd>
</dl>
<dl>
<dd>
<dl>
<dd><img class='tex' src="../../../math/1/2/0/1209a29c1ad5c8130d9a11b009fd5492.png" alt="Pr(B|A) = 1/2, Pr(A|B) = 1, Pr(B|A^') = 0\," />,</dd>
</dl>
</dd>
</dl>
<dl>
<dd>so</dd>
</dl>
<dl>
<dd>
<dl>
<dd><img class='tex' src="../../../math/9/9/6/996fcce2caacf278cb9c59a9c5404534.png" alt="\frac{\Pr(B | A)}{\Pr(A|B)} - (\Pr(B|A) - \Pr(B|A^')) = 1/2 - 1/2 = 0\," /></dd>
</dl>
</dd>
</dl>
<dl>
<dd>Albmont 03:36, 15 January 2007 (UTC)</dd>
</dl>
<p><a name="Bayes.27_theorem_or_Bayes.27s_theorem.3F" id="Bayes.27_theorem_or_Bayes.27s_theorem.3F"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Bayes' theorem or Bayes's theorem?">edit</a>]</span> <span class="mw-headline">Bayes' theorem or Bayes's theorem?</span></h2>
<p>I am not a native English speaker, but should the title of this article be <b>Bayes's theorem</b> instead of <b>Bayes' theorem</b>? I think Bayes' theorem would be correct if there were a Baye Sr. and a Baye Jr. and theorem would honour two or more Bayes&#160;:-) Albmont 03:38, 15 January 2007 (UTC)</p>
<dl>
<dd>That might make some kind of sense. But habits vary. Compare <a href="../../../s/t/_/St_James%27s_Park_2cad.html" title="St James's Park">St James's Park</a> with <a href="../../../s/t/_/St_James%27_Park_ec57.html" title="St James' Park">St James' Park</a> and <a href="../../../s/t/_/St_James_Park_8080.html" title="St James Park">St James Park</a>. I would prefer "Bayes theorem" as most people say, but Wikipedia puts in an apostrophe. <a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a> 09:25, 15 January 2007 (UTC).</dd>
</dl>
<p>Yes, Bayes's is grammatically correct. But don't change it in the body until we can get the title changed. Pianoroy 08:56, 19 January 2007 (UTC)</p>
<p>If it were a question of <i>ownership</i> this might be relevant, but in mathematics, far more often than not, the possessive is <i>not</i> used for naming theorems. Thus we have the Gauss lemma (not Gauss's lemma), the Smale theorem (not Smale's theorem), the Whitehead theorem (not Whitehead's theorem), the Wiles theorem (not Wiles's theorem), and so on... Furthermore, the more significant the result, the more likely the possessive is not used when naming or ascribing the theorem. If WikiGrammarians persist, won't we soon be seeing the King James's Version of the Bible? The article title and references to the theorem should be <i>Bayes theorem</i>. By the way, I'm a (now retired) professional academic mathematician. <a href="../../../c/h/u/User%7EChuckHG_e510.html" title="User:ChuckHG">Chuck</a> 15:24, 25 January 2007 (UTC)</p>
<dl>
<dd>Oddly, though, every instance you mention uses the article 'the' before the name of the person responsible for the theorem. But the usual context for citing Bayes' theorem doesn't use the article 'the'; similarly, I've never seen Zorn's lemma cited as "the Zorn lemma," but have often seen it cited "Zorn's lemma." I've seen Smale's theorem cited as such; as for the rest, I have no information. But I do have many other counter-examples. So my conclusion is that it is legitimate in many cases to use the construction "the X theorem" (or lemma), but it is also legitimate to use the construction "X's theorem" (or lemma). This brings it back to the realm of grammar. <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Bill Jefferys</a> 01:55, 5 March 2007 (UTC)</dd>
</dl>
<p>Thanks Chuck for the clarification. I'll switch it back to 'Bayes theorem' (title and body) when I get a chance (unless someone else is willing to oblige). Pianoroy 00:10, 30 January 2007 (UTC)</p>
<p><a name="Obvious_CONTRADICTION_in_the_theorem_itself" id="Obvious_CONTRADICTION_in_the_theorem_itself"></a></p>
<h2><span class="editsection">[<a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html" title="Edit section: Obvious CONTRADICTION in the theorem itself">edit</a>]</span> <span class="mw-headline">Obvious CONTRADICTION in the theorem itself</span></h2>
<p>The Bayesian theorem places an obstackle to itself. It shoulf define the area of results to be distinct from Pr(A). It defines the normalisation constant as dependent of the Pr(B) (the prior or marginal probability of B, and acts as a normalizing constant) of Pr(A) (the prior probability or marginal probability of A. It is "prior" in the sense that it does not take into account any information about B).</p>
<p>In fact, Bayes is wrong in the start, because he has proven his theorem BECAUSE of the interdependance of Pr(A) and Pr(B).</p>
<p>That is inadmissable:</p>
<p>See &lt;a href="<a href="http://en.wikipedia.org/wiki/Bayes%27_theorem#Derivation_from_conditional_probabilities" class="external free" title="http://en.wikipedia.org/wiki/Bayes%27_theorem#Derivation_from_conditional_probabilities" rel="nofollow">http://en.wikipedia.org/wiki/Bayes%27_theorem#Derivation_from_conditional_probabilities</a>"&gt;<i>Derivation from conditional probabilities</i>&lt;/a&gt;.</p>
<p>(Goran Arsov: arsov1978@yahoo.com)</p>
<p>Discussed thoroughly at www.MySpace.com, Groups&#160;» Philosophy of Psychology&#160;» Topics&#160;» Representational theory of mind and Jerry Fodor</p>
<p><small>—The preceding <a href="../../../s/i/g/Wikipedia%7ESign_your_posts_on_talk_pages_ee53.html" title="Wikipedia:Sign your posts on talk pages">unsigned</a> comment was added by <a href="../../../c/o/n/Special%7EContributions_62.162.223.243_d4f3.html" title="Special:Contributions/62.162.223.243">62.162.223.243</a> (talk) 12:01, 16 January 2007 (UTC).</small></p>

<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org../../../b/a/y/Talk%7EBayes%27_theorem_a302.html">http://en.wikipedia.org../../../b/a/y/Talk%7EBayes%27_theorem_a302.html</a>"</div>
	    	    <!-- end content -->
	    <div class="visualClear"></div>
	  </div>
	</div>
      </div>
      <div id="column-one">
	<div id="p-cactions" class="portlet">
	  <h5>Views</h5>
	  <ul>
	    <li id="ca-nstab-main"
	       	       ><a href="../../../b/a/y/Bayes%27_theorem.html">Article</a></li><li id="ca-talk"
	       class="selected"	       ><a href="../../../b/a/y/Talk%7EBayes%27_theorem_a302.html">Discussion</a></li><li id="ca-current"
	       	       ><a href="http://en.wikipedia.org/wiki/Talk:Bayes%27_theorem">Current revision</a></li>	  </ul>
	</div>
	<div class="portlet" id="p-logo">
	  <a style="background-image: url(../../../images/wiki-en.png);"
	    href="../../../index.html"
	    title="Main Page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class='portlet' id='p-navigation'>
	  <h5>Navigation</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-Main-page"><a href="../../../index.html">Main page</a></li>
	     	      <li id="n-Contents"><a href="../../../c/o/n/Wikipedia%7EContents_3181.html">Contents</a></li>
	     	      <li id="n-Featured-content"><a href="../../../f/e/a/Wikipedia%7EFeatured_content_24ba.html">Featured content</a></li>
	     	      <li id="n-currentevents"><a href="../../../c/u/r/Portal%7ECurrent_events_bb60.html">Current events</a></li>
	     	    </ul>
	  </div>
	</div>
		<div class='portlet' id='p-interaction'>
	  <h5>interaction</h5>
	  <div class='pBody'>
	    <ul>
	    	      <li id="n-About-Wikipedia"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html">About Wikipedia</a></li>
	     	      <li id="n-portal"><a href="../../../c/o/m/Wikipedia%7ECommunity_Portal_6a3c.html">Community portal</a></li>
	     	      <li id="n-contact"><a href="../../../c/o/n/Wikipedia%7EContact_us_afd6.html">Contact us</a></li>
	     	      <li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising">Make a donation</a></li>
	     	      <li id="n-help"><a href="../../../c/o/n/Help%7EContents_22de.html">Help</a></li>
	     	    </ul>
	  </div>
	</div>
		<div id="p-search" class="portlet">
	  <h5><label for="searchInput">Search</label></h5>
	  <div id="searchBody" class="pBody">
	    <form action="javascript:goToStatic(3)" id="searchform"><div>
	      <input id="searchInput" name="search" type="text"
	        accesskey="f" value="" />
	      <input type='submit' name="go" class="searchButton" id="searchGoButton"
	        value="Go" />
	    </div></form>
	  </div>
	</div>
	      </div><!-- end of the left (by default at least) column -->
      <div class="visualClear"></div>
      <div id="footer">
    <div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="../../../skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>	<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="../../../images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>	<ul id="f-list">
	  	  	  <li id="f-credits">This page was last modified 01:55, 5 March 2007 by Wikipedia user <a href="../../../b/i/l/User%7EBilljefferys_1728.html" title="User:Billjefferys">Billjefferys</a>. Based on work by Wikipedia user(s) <a href="../../../f/r/a/User%7EFranjesus_b68d.html" title="User:Franjesus">Franjesus</a>, <a href="../../../h/e/n/User%7EHenrygb_9b92.html" title="User:Henrygb">Henrygb</a>, Pianoroy, <a href="../../../c/h/u/User%7EChuckHG_e510.html" title="User:ChuckHG">ChuckHG</a>, <a href="../../../h/a/g/User%7EHagermanBot_d869.html" title="User:HagermanBot">HagermanBot</a>, Albmont, <a href="../../../m/i/c/User%7EMichael_Hardy_e932.html" title="User:Michael Hardy">Michael Hardy</a>, <a href="../../../t/g/r/User%7ETgr_c760.html" title="User:Tgr">Tgr</a>, <a href="../../../k/z/o/User%7EKzollman_a660.html" title="User:Kzollman">Kzollman</a>, Wyxel, <a href="../../../t/o/m/User%7EToms2866_7e19.html" title="User:Toms2866">Toms2866</a>, <a href="../../../k/e/n/User%7EKenkleinman_8981.html" title="User:Kenkleinman">Kenkleinman</a>, <a href="../../../j/o/h/User%7EJohn_wesley_6b3b.html" title="User:John wesley">John wesley</a>, <a href="../../../m/e/t/User%7EMetacomet_63d1.html" title="User:Metacomet">Metacomet</a>, Lukestuts, <a href="../../../d/c/o/User%7EDcoetzee_a2a7.html" title="User:Dcoetzee">Dcoetzee</a>, <a href="../../../w/i/l/User%7EWile_E._Heresiarch_9879.html" title="User:Wile E. Heresiarch">Wile E. Heresiarch</a>, <a href="../../../m/a/r/User%7EMarkSweep_b58d.html" title="User:MarkSweep">MarkSweep</a>, <a href="../../../r/i/t/User%7ERitchy_3c4d.html" title="User:Ritchy">Ritchy</a>, <a href="../../../x/4/2/User%7EX42bn6_9d4f.html" title="User:X42bn6">X42bn6</a>, <a href="../../../o/n/i/User%7EOniony_a775.html" title="User:Oniony">Oniony</a> and <a href="../../../b/j/c/User%7EBjcairns_871c.html" title="User:Bjcairns">Bjcairns</a> and Anonymous user(s) of Wikipedia.</li>	  <li id="f-copyright">All text is available under the terms of the <a class='internal' href="../../../t/e/x/Wikipedia%7EText_of_the_GNU_Free_Documentation_License_702a.html" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="../../../c/o/p/Wikipedia%7ECopyrights_92c4.html" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc</a>., a US-registered <a class='internal' href="../../../5/0/1/501%28c%29.html#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="../../../n/o/n/Non-profit_organization.html" title="Non-profit organization">nonprofit</a> <a href="../../../c/h/a/Charitable_organization.html" title="Charitable organization">charity</a>.<br /></li>	  <li id="f-about"><a href="../../../a/b/o/Wikipedia%7EAbout_8d82.html" title="Wikipedia:About">About Wikipedia</a></li>	  <li id="f-disclaimer"><a href="../../../g/e/n/Wikipedia%7EGeneral_disclaimer_3e44.html" title="Wikipedia:General disclaimer">Disclaimers</a></li>	  	</ul>
      </div>
    </div>
  </body>
</html>
